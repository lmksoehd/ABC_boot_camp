{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcoyMnTbWiPtvBfWx2U8PJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmksoehd/ABC_boot_camp/blob/main/06_1970%EB%85%84%EB%8C%80_%EB%B3%B4%EC%8A%A4%ED%86%A4_%EC%A7%80%EC%97%AD%EC%9D%98_%EC%A3%BC%ED%83%9D%EA%B0%80%EA%B2%A9_%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1970년대 보스턴 지역의 주택 가격을 예측하는 회귀 문제"
      ],
      "metadata": {
        "id": "oWfjSJ_J8zh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 보스턴 주택 가격 데이터셋 다운로드"
      ],
      "metadata": {
        "id": "Gnw92mxj87Fg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x9F0zXce0oRo"
      },
      "outputs": [],
      "source": [
        "from keras.datasets.boston_housing import load_data                           # no tensorflow\n",
        "\n",
        "# 데이터를 다운받습니다.(훈련셋 80%, 테스트셋 20%)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2,\n",
        "                                                 seed=777)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 형태 확인"
      ],
      "metadata": {
        "id": "xAYVGpXk9nDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train.shape,' , X_train.shape)\n",
        "print('y_train.shape,' , y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG-lkL9Q9AxH",
        "outputId": "ec5f3561-b452-4a5f-cd73-18d0d5cc9478"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape, (404, 13)\n",
            "y_train.shape, (404,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train) #13feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXGYRdcF-OFY",
        "outputId": "d38dfa39-c8dd-4cae-e11e-85015b1159d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]    # house price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq1tyEM8-hhV",
        "outputId": "dedb1134-fd5b-4d3d-d1ed-01fd2a48bbae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.5"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_test.shape,' , X_test.shape)\n",
        "print('y_test.shape,' , y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXdWq9Ky9GHb",
        "outputId": "9ac7c5ac-7296-4f01-9d1a-125d37628c33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test.shape, (102, 13)\n",
            "y_test.shape, (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리(feature) 표준화(Standardzation)\n",
        "\n",
        "*   회귀 모델에서는 y값( 여기선 집값)을 건들지 않는다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SQWigIut-AjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# (데이터-전체평균)/표준편차\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "\n",
        "#(X_train-mean)/std"
      ],
      "metadata": {
        "id": "HrlvDN9q9GD_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리(X_train, X_test) 둘 다 처리\n",
        "\n",
        "X_train = (X_train-mean)/std\n",
        "X_test = (X_test-mean)/std\n",
        "\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYfTySINBP2S",
        "outputId": "79594dac-6493-406a-b777-c38aca2aad7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.40102395 -0.48033655 -0.12089418 -0.28828791 -0.58254176 -0.68137272\n",
            "  0.11117586  0.26484408 -0.65187119 -0.80249043  0.0756568   0.37366783\n",
            "  0.69211835]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검증 데이터셋 생성"
      ],
      "metadata": {
        "id": "0OpQA9gqB-D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.33, random_state=777)\n",
        "\n",
        "print(X_train.shape, X_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hh3CVZy9GBp",
        "outputId": "0e31aa58-3af0-411f-a383-236e50f04342"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(270, 13) (134, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성하기"
      ],
      "metadata": {
        "id": "ZPcrbtbkGljz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation='relu', input_shape=(13,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))   # activation = linear\n",
        "\n"
      ],
      "metadata": {
        "id": "9mJlmGK-9F_Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 설정하기"
      ],
      "metadata": {
        "id": "Q8BXEcF3HYqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mse', metrics=['mae','mse']) #mae 정확한 에러\n",
        "# 각 에러 사용법 알아두"
      ],
      "metadata": {
        "id": "D1BZ7yyi9F8b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습하기"
      ],
      "metadata": {
        "id": "5b7nv-_hJIgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs = 300,\n",
        "                    validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvRLeiw99F5z",
        "outputId": "d7d8595d-0ced-4917-a8d8-00d84ff2f66a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 5s 77ms/step - loss: 522.8083 - mae: 21.1980 - mse: 522.8083 - val_loss: 573.1421 - val_mae: 21.7511 - val_mse: 573.1421\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 496.5090 - mae: 20.5898 - mse: 496.5090 - val_loss: 541.9935 - val_mae: 21.0762 - val_mse: 541.9935\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 464.6110 - mae: 19.8400 - mse: 464.6110 - val_loss: 503.0213 - val_mae: 20.2020 - val_mse: 503.0213\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 424.2578 - mae: 18.8643 - mse: 424.2578 - val_loss: 454.4506 - val_mae: 19.0680 - val_mse: 454.4506\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 376.1425 - mae: 17.6332 - mse: 376.1425 - val_loss: 396.1726 - val_mae: 17.6222 - val_mse: 396.1726\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 319.4977 - mae: 16.1043 - mse: 319.4977 - val_loss: 327.9403 - val_mae: 15.7642 - val_mse: 327.9403\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 253.6282 - mae: 14.2089 - mse: 253.6282 - val_loss: 255.9874 - val_mae: 13.6055 - val_mse: 255.9874\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 186.1882 - mae: 11.9183 - mse: 186.1882 - val_loss: 186.3037 - val_mae: 11.2783 - val_mse: 186.3037\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 128.4428 - mae: 9.5837 - mse: 128.4428 - val_loss: 129.1325 - val_mae: 9.1424 - val_mse: 129.1325\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 84.3627 - mae: 7.4838 - mse: 84.3627 - val_loss: 92.7395 - val_mae: 7.5876 - val_mse: 92.7395\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 60.2608 - mae: 6.1755 - mse: 60.2608 - val_loss: 73.5703 - val_mae: 6.4872 - val_mse: 73.5703\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 48.7718 - mae: 5.3858 - mse: 48.7718 - val_loss: 62.4016 - val_mae: 5.8031 - val_mse: 62.4016\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 41.4460 - mae: 4.8401 - mse: 41.4460 - val_loss: 53.4970 - val_mae: 5.3137 - val_mse: 53.4970\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 35.2294 - mae: 4.3884 - mse: 35.2294 - val_loss: 46.7771 - val_mae: 4.9301 - val_mse: 46.7771\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 30.8738 - mae: 4.0834 - mse: 30.8738 - val_loss: 42.0420 - val_mae: 4.6674 - val_mse: 42.0420\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 27.7527 - mae: 3.8167 - mse: 27.7527 - val_loss: 38.6614 - val_mae: 4.4692 - val_mse: 38.6614\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25.7772 - mae: 3.6338 - mse: 25.7772 - val_loss: 36.0392 - val_mae: 4.3007 - val_mse: 36.0392\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 24.2285 - mae: 3.4664 - mse: 24.2285 - val_loss: 33.7927 - val_mae: 4.1298 - val_mse: 33.7927\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 23.1032 - mae: 3.3564 - mse: 23.1032 - val_loss: 32.2959 - val_mae: 4.0064 - val_mse: 32.2959\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 22.3152 - mae: 3.2850 - mse: 22.3152 - val_loss: 31.1555 - val_mae: 3.9388 - val_mse: 31.1555\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 21.6875 - mae: 3.2439 - mse: 21.6875 - val_loss: 30.0680 - val_mae: 3.8973 - val_mse: 30.0680\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 20.9816 - mae: 3.2047 - mse: 20.9816 - val_loss: 29.2364 - val_mae: 3.8461 - val_mse: 29.2364\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 20.5047 - mae: 3.1598 - mse: 20.5047 - val_loss: 28.6357 - val_mae: 3.8031 - val_mse: 28.6357\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 19.9164 - mae: 3.0870 - mse: 19.9164 - val_loss: 28.1459 - val_mae: 3.7354 - val_mse: 28.1459\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 19.4897 - mae: 3.0379 - mse: 19.4897 - val_loss: 27.3227 - val_mae: 3.6757 - val_mse: 27.3227\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 19.0396 - mae: 3.0046 - mse: 19.0396 - val_loss: 26.8187 - val_mae: 3.6211 - val_mse: 26.8187\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 18.5758 - mae: 2.9555 - mse: 18.5758 - val_loss: 26.4146 - val_mae: 3.5770 - val_mse: 26.4146\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 18.3236 - mae: 2.9216 - mse: 18.3236 - val_loss: 26.0122 - val_mae: 3.5290 - val_mse: 26.0122\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 18.1183 - mae: 2.9064 - mse: 18.1183 - val_loss: 25.7606 - val_mae: 3.5543 - val_mse: 25.7606\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 17.5309 - mae: 2.8694 - mse: 17.5309 - val_loss: 25.2312 - val_mae: 3.5159 - val_mse: 25.2312\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 17.2615 - mae: 2.8523 - mse: 17.2615 - val_loss: 24.7530 - val_mae: 3.4898 - val_mse: 24.7530\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 16.8981 - mae: 2.8128 - mse: 16.8981 - val_loss: 24.5783 - val_mae: 3.4519 - val_mse: 24.5783\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 16.5952 - mae: 2.7791 - mse: 16.5952 - val_loss: 24.1297 - val_mae: 3.4221 - val_mse: 24.1297\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 16.2615 - mae: 2.7507 - mse: 16.2615 - val_loss: 23.7598 - val_mae: 3.3859 - val_mse: 23.7598\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.9907 - mae: 2.7178 - mse: 15.9907 - val_loss: 23.4130 - val_mae: 3.3606 - val_mse: 23.4130\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 15.6777 - mae: 2.6936 - mse: 15.6777 - val_loss: 23.0056 - val_mae: 3.3354 - val_mse: 23.0056\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 15.4040 - mae: 2.6876 - mse: 15.4040 - val_loss: 22.4658 - val_mae: 3.3322 - val_mse: 22.4658\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 15.1423 - mae: 2.6681 - mse: 15.1423 - val_loss: 21.9603 - val_mae: 3.2708 - val_mse: 21.9603\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.8786 - mae: 2.6444 - mse: 14.8786 - val_loss: 21.5424 - val_mae: 3.2373 - val_mse: 21.5424\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 14.6766 - mae: 2.6258 - mse: 14.6766 - val_loss: 21.4489 - val_mae: 3.2177 - val_mse: 21.4489\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 14.4798 - mae: 2.6039 - mse: 14.4798 - val_loss: 21.1831 - val_mae: 3.1890 - val_mse: 21.1831\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 14.4052 - mae: 2.5989 - mse: 14.4052 - val_loss: 20.8228 - val_mae: 3.2068 - val_mse: 20.8228\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 14.0749 - mae: 2.5633 - mse: 14.0749 - val_loss: 20.7701 - val_mae: 3.1707 - val_mse: 20.7701\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 13.9030 - mae: 2.5479 - mse: 13.9030 - val_loss: 20.3370 - val_mae: 3.1347 - val_mse: 20.3370\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.7089 - mae: 2.5332 - mse: 13.7089 - val_loss: 20.1741 - val_mae: 3.1324 - val_mse: 20.1741\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 13.5592 - mae: 2.5253 - mse: 13.5592 - val_loss: 20.1222 - val_mae: 3.1033 - val_mse: 20.1222\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 13.3978 - mae: 2.5064 - mse: 13.3978 - val_loss: 19.8438 - val_mae: 3.0865 - val_mse: 19.8438\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 13.2747 - mae: 2.4828 - mse: 13.2747 - val_loss: 19.9950 - val_mae: 3.0987 - val_mse: 19.9950\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 13.1512 - mae: 2.4698 - mse: 13.1512 - val_loss: 19.3863 - val_mae: 3.0519 - val_mse: 19.3863\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 13.0352 - mae: 2.4615 - mse: 13.0352 - val_loss: 18.9274 - val_mae: 3.0073 - val_mse: 18.9274\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.8446 - mae: 2.4364 - mse: 12.8446 - val_loss: 18.9936 - val_mae: 2.9991 - val_mse: 18.9936\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.7587 - mae: 2.4250 - mse: 12.7587 - val_loss: 19.1450 - val_mae: 3.0365 - val_mse: 19.1450\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 12.6529 - mae: 2.4273 - mse: 12.6529 - val_loss: 18.5494 - val_mae: 2.9865 - val_mse: 18.5494\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.4823 - mae: 2.4146 - mse: 12.4823 - val_loss: 18.4278 - val_mae: 2.9564 - val_mse: 18.4278\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 12.3292 - mae: 2.3976 - mse: 12.3292 - val_loss: 18.4065 - val_mae: 2.9726 - val_mse: 18.4065\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 12.3049 - mae: 2.4034 - mse: 12.3049 - val_loss: 18.4727 - val_mae: 3.0066 - val_mse: 18.4727\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.1743 - mae: 2.3762 - mse: 12.1743 - val_loss: 18.1236 - val_mae: 2.9444 - val_mse: 18.1236\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 12.1043 - mae: 2.3618 - mse: 12.1043 - val_loss: 18.2328 - val_mae: 2.9494 - val_mse: 18.2328\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.8253 - mae: 2.3529 - mse: 11.8253 - val_loss: 17.8210 - val_mae: 2.9740 - val_mse: 17.8210\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.9049 - mae: 2.3897 - mse: 11.9049 - val_loss: 17.6873 - val_mae: 2.9955 - val_mse: 17.6873\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 11.7836 - mae: 2.3843 - mse: 11.7836 - val_loss: 17.5572 - val_mae: 2.9586 - val_mse: 17.5572\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.6517 - mae: 2.3444 - mse: 11.6517 - val_loss: 17.3082 - val_mae: 2.8980 - val_mse: 17.3082\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 11.6878 - mae: 2.3269 - mse: 11.6878 - val_loss: 17.7024 - val_mae: 2.9173 - val_mse: 17.7024\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 11.4941 - mae: 2.3076 - mse: 11.4941 - val_loss: 17.2488 - val_mae: 2.8898 - val_mse: 17.2488\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 11.4240 - mae: 2.3203 - mse: 11.4240 - val_loss: 17.2367 - val_mae: 2.9192 - val_mse: 17.2367\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.3409 - mae: 2.3212 - mse: 11.3409 - val_loss: 17.1677 - val_mae: 2.9132 - val_mse: 17.1677\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.2594 - mae: 2.3084 - mse: 11.2594 - val_loss: 17.1328 - val_mae: 2.9033 - val_mse: 17.1328\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 11.2051 - mae: 2.2950 - mse: 11.2051 - val_loss: 17.2509 - val_mae: 2.8946 - val_mse: 17.2509\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.1637 - mae: 2.2881 - mse: 11.1637 - val_loss: 17.0314 - val_mae: 2.8969 - val_mse: 17.0314\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.1027 - mae: 2.2858 - mse: 11.1027 - val_loss: 16.7710 - val_mae: 2.8711 - val_mse: 16.7710\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 10.9628 - mae: 2.2681 - mse: 10.9628 - val_loss: 16.8631 - val_mae: 2.8570 - val_mse: 16.8631\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.9549 - mae: 2.2552 - mse: 10.9549 - val_loss: 16.7914 - val_mae: 2.8474 - val_mse: 16.7914\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.8528 - mae: 2.2517 - mse: 10.8528 - val_loss: 16.6735 - val_mae: 2.8532 - val_mse: 16.6735\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 10.8434 - mae: 2.2656 - mse: 10.8434 - val_loss: 16.4864 - val_mae: 2.8623 - val_mse: 16.4864\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 10.7553 - mae: 2.2526 - mse: 10.7553 - val_loss: 16.8701 - val_mae: 2.8702 - val_mse: 16.8701\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.7649 - mae: 2.2362 - mse: 10.7649 - val_loss: 16.7506 - val_mae: 2.8359 - val_mse: 16.7506\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.5479 - mae: 2.2254 - mse: 10.5479 - val_loss: 15.9916 - val_mae: 2.8314 - val_mse: 15.9916\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 10.6350 - mae: 2.2727 - mse: 10.6350 - val_loss: 16.0198 - val_mae: 2.8632 - val_mse: 16.0198\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 10.6036 - mae: 2.2503 - mse: 10.6036 - val_loss: 16.3527 - val_mae: 2.8214 - val_mse: 16.3527\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 10.4211 - mae: 2.2105 - mse: 10.4211 - val_loss: 16.1044 - val_mae: 2.7967 - val_mse: 16.1044\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 10.3623 - mae: 2.2066 - mse: 10.3623 - val_loss: 15.9121 - val_mae: 2.8175 - val_mse: 15.9121\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 10.3041 - mae: 2.2187 - mse: 10.3041 - val_loss: 15.9814 - val_mae: 2.8218 - val_mse: 15.9814\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.2448 - mae: 2.2065 - mse: 10.2448 - val_loss: 15.9844 - val_mae: 2.8220 - val_mse: 15.9844\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 10.2242 - mae: 2.1965 - mse: 10.2242 - val_loss: 16.1319 - val_mae: 2.8315 - val_mse: 16.1319\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 10.2392 - mae: 2.2059 - mse: 10.2392 - val_loss: 15.6387 - val_mae: 2.7560 - val_mse: 15.6387\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0749 - mae: 2.1932 - mse: 10.0749 - val_loss: 15.7512 - val_mae: 2.7856 - val_mse: 15.7512\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0336 - mae: 2.1875 - mse: 10.0336 - val_loss: 15.8017 - val_mae: 2.7987 - val_mse: 15.8017\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 9.9643 - mae: 2.1759 - mse: 9.9643 - val_loss: 15.6157 - val_mae: 2.7767 - val_mse: 15.6157\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.9920 - mae: 2.1680 - mse: 9.9920 - val_loss: 15.5992 - val_mae: 2.7426 - val_mse: 15.5992\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8345 - mae: 2.1593 - mse: 9.8345 - val_loss: 15.5000 - val_mae: 2.7854 - val_mse: 15.5000\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.8602 - mae: 2.1816 - mse: 9.8602 - val_loss: 15.6288 - val_mae: 2.8268 - val_mse: 15.6288\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.8372 - mae: 2.1741 - mse: 9.8372 - val_loss: 15.4059 - val_mae: 2.7534 - val_mse: 15.4059\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 9.7120 - mae: 2.1646 - mse: 9.7120 - val_loss: 15.4027 - val_mae: 2.7747 - val_mse: 15.4027\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 9.6850 - mae: 2.1579 - mse: 9.6850 - val_loss: 15.5595 - val_mae: 2.7854 - val_mse: 15.5595\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.6321 - mae: 2.1595 - mse: 9.6321 - val_loss: 15.2856 - val_mae: 2.7590 - val_mse: 15.2856\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 9.6153 - mae: 2.1495 - mse: 9.6153 - val_loss: 15.3498 - val_mae: 2.7705 - val_mse: 15.3498\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4696 - mae: 2.1214 - mse: 9.4696 - val_loss: 15.1233 - val_mae: 2.7541 - val_mse: 15.1233\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.4699 - mae: 2.1222 - mse: 9.4699 - val_loss: 15.1244 - val_mae: 2.7291 - val_mse: 15.1244\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4027 - mae: 2.1072 - mse: 9.4027 - val_loss: 15.1716 - val_mae: 2.7376 - val_mse: 15.1716\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.3630 - mae: 2.1177 - mse: 9.3630 - val_loss: 15.0988 - val_mae: 2.7547 - val_mse: 15.0988\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3548 - mae: 2.1123 - mse: 9.3548 - val_loss: 15.2250 - val_mae: 2.7382 - val_mse: 15.2250\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2651 - mae: 2.1090 - mse: 9.2651 - val_loss: 15.1496 - val_mae: 2.7458 - val_mse: 15.1496\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2552 - mae: 2.1030 - mse: 9.2552 - val_loss: 15.4843 - val_mae: 2.7501 - val_mse: 15.4843\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 9.2161 - mae: 2.0973 - mse: 9.2161 - val_loss: 14.9936 - val_mae: 2.7227 - val_mse: 14.9936\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 9.1491 - mae: 2.0942 - mse: 9.1491 - val_loss: 14.7975 - val_mae: 2.7118 - val_mse: 14.7975\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0847 - mae: 2.0807 - mse: 9.0847 - val_loss: 15.0821 - val_mae: 2.7178 - val_mse: 15.0821\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0539 - mae: 2.0697 - mse: 9.0539 - val_loss: 14.9343 - val_mae: 2.7019 - val_mse: 14.9343\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0117 - mae: 2.0820 - mse: 9.0117 - val_loss: 15.0257 - val_mae: 2.7410 - val_mse: 15.0257\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.0392 - mae: 2.0940 - mse: 9.0392 - val_loss: 14.7015 - val_mae: 2.6985 - val_mse: 14.7015\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8849 - mae: 2.0655 - mse: 8.8849 - val_loss: 15.0626 - val_mae: 2.7431 - val_mse: 15.0626\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9059 - mae: 2.0620 - mse: 8.9059 - val_loss: 14.9704 - val_mae: 2.7351 - val_mse: 14.9704\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.8537 - mae: 2.0562 - mse: 8.8537 - val_loss: 15.0934 - val_mae: 2.7369 - val_mse: 15.0934\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7960 - mae: 2.0548 - mse: 8.7960 - val_loss: 14.9151 - val_mae: 2.7170 - val_mse: 14.9151\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7728 - mae: 2.0415 - mse: 8.7728 - val_loss: 14.9807 - val_mae: 2.7081 - val_mse: 14.9807\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7039 - mae: 2.0381 - mse: 8.7039 - val_loss: 14.6573 - val_mae: 2.6971 - val_mse: 14.6573\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6656 - mae: 2.0394 - mse: 8.6656 - val_loss: 14.7460 - val_mae: 2.7037 - val_mse: 14.7460\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 8.6175 - mae: 2.0354 - mse: 8.6175 - val_loss: 14.8314 - val_mae: 2.7222 - val_mse: 14.8314\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.6109 - mae: 2.0292 - mse: 8.6109 - val_loss: 14.7754 - val_mae: 2.6970 - val_mse: 14.7754\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.5820 - mae: 2.0263 - mse: 8.5820 - val_loss: 14.5863 - val_mae: 2.7172 - val_mse: 14.5863\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5610 - mae: 2.0259 - mse: 8.5610 - val_loss: 14.7307 - val_mae: 2.6978 - val_mse: 14.7307\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.5799 - mae: 2.0300 - mse: 8.5799 - val_loss: 14.7238 - val_mae: 2.7049 - val_mse: 14.7238\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.4322 - mae: 2.0146 - mse: 8.4322 - val_loss: 14.6529 - val_mae: 2.6643 - val_mse: 14.6529\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4158 - mae: 2.0074 - mse: 8.4158 - val_loss: 14.7121 - val_mae: 2.6883 - val_mse: 14.7121\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5556 - mae: 2.0349 - mse: 8.5556 - val_loss: 14.6184 - val_mae: 2.7157 - val_mse: 14.6184\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.5043 - mae: 2.0220 - mse: 8.5043 - val_loss: 14.9640 - val_mae: 2.6947 - val_mse: 14.9640\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.2860 - mae: 1.9893 - mse: 8.2860 - val_loss: 14.6102 - val_mae: 2.7169 - val_mse: 14.6102\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.2998 - mae: 2.0094 - mse: 8.2998 - val_loss: 14.4751 - val_mae: 2.7155 - val_mse: 14.4751\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 8.2671 - mae: 2.0155 - mse: 8.2671 - val_loss: 14.1829 - val_mae: 2.6827 - val_mse: 14.1829\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1708 - mae: 1.9900 - mse: 8.1708 - val_loss: 14.4816 - val_mae: 2.6670 - val_mse: 14.4816\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.1776 - mae: 1.9795 - mse: 8.1776 - val_loss: 14.5526 - val_mae: 2.6933 - val_mse: 14.5526\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 8.0952 - mae: 1.9868 - mse: 8.0952 - val_loss: 14.4400 - val_mae: 2.6928 - val_mse: 14.4400\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.0770 - mae: 1.9923 - mse: 8.0770 - val_loss: 14.3661 - val_mae: 2.6884 - val_mse: 14.3661\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0221 - mae: 1.9808 - mse: 8.0221 - val_loss: 14.4117 - val_mae: 2.6838 - val_mse: 14.4117\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0088 - mae: 1.9693 - mse: 8.0088 - val_loss: 14.5207 - val_mae: 2.6770 - val_mse: 14.5207\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 7.9770 - mae: 1.9626 - mse: 7.9770 - val_loss: 14.3661 - val_mae: 2.6968 - val_mse: 14.3661\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9075 - mae: 1.9567 - mse: 7.9075 - val_loss: 14.3763 - val_mae: 2.6827 - val_mse: 14.3763\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.8752 - mae: 1.9548 - mse: 7.8752 - val_loss: 14.3758 - val_mae: 2.6907 - val_mse: 14.3758\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.8383 - mae: 1.9555 - mse: 7.8383 - val_loss: 14.3255 - val_mae: 2.7032 - val_mse: 14.3255\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 7.8161 - mae: 1.9560 - mse: 7.8161 - val_loss: 14.1541 - val_mae: 2.6635 - val_mse: 14.1541\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8034 - mae: 1.9512 - mse: 7.8034 - val_loss: 14.1358 - val_mae: 2.6650 - val_mse: 14.1358\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.7597 - mae: 1.9350 - mse: 7.7597 - val_loss: 14.1000 - val_mae: 2.6537 - val_mse: 14.1000\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.7015 - mae: 1.9373 - mse: 7.7015 - val_loss: 14.0647 - val_mae: 2.6757 - val_mse: 14.0647\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 7.6983 - mae: 1.9481 - mse: 7.6983 - val_loss: 14.0864 - val_mae: 2.6700 - val_mse: 14.0864\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6545 - mae: 1.9398 - mse: 7.6545 - val_loss: 14.3368 - val_mae: 2.6717 - val_mse: 14.3368\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6036 - mae: 1.9225 - mse: 7.6036 - val_loss: 14.1731 - val_mae: 2.6563 - val_mse: 14.1731\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 7.6047 - mae: 1.9347 - mse: 7.6047 - val_loss: 14.0960 - val_mae: 2.6666 - val_mse: 14.0960\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7.5591 - mae: 1.9126 - mse: 7.5591 - val_loss: 14.2313 - val_mae: 2.6596 - val_mse: 14.2313\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.5109 - mae: 1.9109 - mse: 7.5109 - val_loss: 14.1875 - val_mae: 2.6800 - val_mse: 14.1875\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.5318 - mae: 1.9009 - mse: 7.5318 - val_loss: 14.3276 - val_mae: 2.6609 - val_mse: 14.3276\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.4908 - mae: 1.9016 - mse: 7.4908 - val_loss: 14.0833 - val_mae: 2.6797 - val_mse: 14.0833\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7.4524 - mae: 1.9182 - mse: 7.4524 - val_loss: 14.1975 - val_mae: 2.6765 - val_mse: 14.1975\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 7.6092 - mae: 1.8976 - mse: 7.6092 - val_loss: 14.6761 - val_mae: 2.6787 - val_mse: 14.6761\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.3684 - mae: 1.8992 - mse: 7.3684 - val_loss: 13.7836 - val_mae: 2.6703 - val_mse: 13.7836\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.3779 - mae: 1.9159 - mse: 7.3779 - val_loss: 13.6860 - val_mae: 2.6444 - val_mse: 13.6860\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 7.3150 - mae: 1.8978 - mse: 7.3150 - val_loss: 14.0277 - val_mae: 2.6663 - val_mse: 14.0277\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.3706 - mae: 1.8835 - mse: 7.3706 - val_loss: 13.8705 - val_mae: 2.6072 - val_mse: 13.8705\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.4811 - mae: 1.9236 - mse: 7.4811 - val_loss: 14.0286 - val_mae: 2.6959 - val_mse: 14.0286\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2161 - mae: 1.8975 - mse: 7.2161 - val_loss: 14.1785 - val_mae: 2.6664 - val_mse: 14.1785\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.1297 - mae: 1.8729 - mse: 7.1297 - val_loss: 13.9701 - val_mae: 2.6243 - val_mse: 13.9701\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 7.1821 - mae: 1.8792 - mse: 7.1821 - val_loss: 13.9974 - val_mae: 2.6394 - val_mse: 13.9974\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.1162 - mae: 1.8775 - mse: 7.1162 - val_loss: 14.2067 - val_mae: 2.7093 - val_mse: 14.2067\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 7.0876 - mae: 1.8744 - mse: 7.0876 - val_loss: 13.6514 - val_mae: 2.6280 - val_mse: 13.6514\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1228 - mae: 1.8667 - mse: 7.1228 - val_loss: 13.8344 - val_mae: 2.6149 - val_mse: 13.8344\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.0605 - mae: 1.8602 - mse: 7.0605 - val_loss: 13.6566 - val_mae: 2.6262 - val_mse: 13.6566\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.0998 - mae: 1.8895 - mse: 7.0998 - val_loss: 13.5347 - val_mae: 2.6235 - val_mse: 13.5347\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.0427 - mae: 1.8624 - mse: 7.0427 - val_loss: 13.9460 - val_mae: 2.6209 - val_mse: 13.9460\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0248 - mae: 1.8657 - mse: 7.0248 - val_loss: 13.7663 - val_mae: 2.6382 - val_mse: 13.7663\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9229 - mae: 1.8511 - mse: 6.9229 - val_loss: 13.7836 - val_mae: 2.6334 - val_mse: 13.7836\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 6.8888 - mae: 1.8438 - mse: 6.8888 - val_loss: 13.6869 - val_mae: 2.6310 - val_mse: 13.6869\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8676 - mae: 1.8511 - mse: 6.8676 - val_loss: 13.8900 - val_mae: 2.6319 - val_mse: 13.8900\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.8361 - mae: 1.8428 - mse: 6.8361 - val_loss: 13.9479 - val_mae: 2.6467 - val_mse: 13.9479\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 6.8208 - mae: 1.8403 - mse: 6.8208 - val_loss: 13.6889 - val_mae: 2.6326 - val_mse: 13.6889\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.8497 - mae: 1.8558 - mse: 6.8497 - val_loss: 13.3405 - val_mae: 2.5964 - val_mse: 13.3405\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.7934 - mae: 1.8401 - mse: 6.7934 - val_loss: 13.8550 - val_mae: 2.6448 - val_mse: 13.8550\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.7539 - mae: 1.8251 - mse: 6.7539 - val_loss: 13.8105 - val_mae: 2.6290 - val_mse: 13.8105\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.7559 - mae: 1.8344 - mse: 6.7559 - val_loss: 13.7576 - val_mae: 2.6217 - val_mse: 13.7576\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 6.7157 - mae: 1.8323 - mse: 6.7157 - val_loss: 13.8782 - val_mae: 2.6536 - val_mse: 13.8782\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 6.6936 - mae: 1.8282 - mse: 6.6936 - val_loss: 13.7647 - val_mae: 2.6265 - val_mse: 13.7647\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6955 - mae: 1.8339 - mse: 6.6955 - val_loss: 13.6597 - val_mae: 2.6120 - val_mse: 13.6597\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.7394 - mae: 1.8320 - mse: 6.7394 - val_loss: 13.8755 - val_mae: 2.6176 - val_mse: 13.8755\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.5744 - mae: 1.8152 - mse: 6.5744 - val_loss: 13.5946 - val_mae: 2.6403 - val_mse: 13.5946\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 6.5892 - mae: 1.8247 - mse: 6.5892 - val_loss: 13.5416 - val_mae: 2.6157 - val_mse: 13.5416\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.5962 - mae: 1.8195 - mse: 6.5962 - val_loss: 13.6189 - val_mae: 2.6196 - val_mse: 13.6189\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.6077 - mae: 1.8290 - mse: 6.6077 - val_loss: 13.4633 - val_mae: 2.6128 - val_mse: 13.4633\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6.4863 - mae: 1.8017 - mse: 6.4863 - val_loss: 13.7113 - val_mae: 2.6196 - val_mse: 13.7113\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4632 - mae: 1.7979 - mse: 6.4632 - val_loss: 13.6564 - val_mae: 2.6017 - val_mse: 13.6564\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5134 - mae: 1.8180 - mse: 6.5134 - val_loss: 13.4899 - val_mae: 2.6040 - val_mse: 13.4899\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.5603 - mae: 1.8151 - mse: 6.5603 - val_loss: 13.9550 - val_mae: 2.6597 - val_mse: 13.9550\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4641 - mae: 1.7945 - mse: 6.4641 - val_loss: 13.4553 - val_mae: 2.5836 - val_mse: 13.4553\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4451 - mae: 1.8030 - mse: 6.4451 - val_loss: 13.4833 - val_mae: 2.6104 - val_mse: 13.4833\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 6.3852 - mae: 1.7855 - mse: 6.3852 - val_loss: 13.8561 - val_mae: 2.6257 - val_mse: 13.8561\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3817 - mae: 1.7872 - mse: 6.3817 - val_loss: 13.6506 - val_mae: 2.5973 - val_mse: 13.6506\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3469 - mae: 1.7826 - mse: 6.3469 - val_loss: 13.8420 - val_mae: 2.6387 - val_mse: 13.8420\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3527 - mae: 1.7898 - mse: 6.3527 - val_loss: 13.9475 - val_mae: 2.6327 - val_mse: 13.9475\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.3644 - mae: 1.7892 - mse: 6.3644 - val_loss: 13.4415 - val_mae: 2.5718 - val_mse: 13.4415\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.3947 - mae: 1.7898 - mse: 6.3947 - val_loss: 13.9975 - val_mae: 2.6705 - val_mse: 13.9975\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2426 - mae: 1.7733 - mse: 6.2426 - val_loss: 13.3763 - val_mae: 2.5934 - val_mse: 13.3763\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2811 - mae: 1.7714 - mse: 6.2811 - val_loss: 13.4667 - val_mae: 2.5930 - val_mse: 13.4667\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2331 - mae: 1.7742 - mse: 6.2331 - val_loss: 13.4773 - val_mae: 2.6555 - val_mse: 13.4773\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2555 - mae: 1.7700 - mse: 6.2555 - val_loss: 13.2594 - val_mae: 2.5705 - val_mse: 13.2594\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.1806 - mae: 1.7664 - mse: 6.1806 - val_loss: 13.4315 - val_mae: 2.6125 - val_mse: 13.4315\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1172 - mae: 1.7611 - mse: 6.1172 - val_loss: 13.4883 - val_mae: 2.5964 - val_mse: 13.4883\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1388 - mae: 1.7668 - mse: 6.1388 - val_loss: 13.6593 - val_mae: 2.6224 - val_mse: 13.6593\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1070 - mae: 1.7651 - mse: 6.1070 - val_loss: 13.3096 - val_mae: 2.6104 - val_mse: 13.3096\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.0528 - mae: 1.7375 - mse: 6.0528 - val_loss: 13.5321 - val_mae: 2.5902 - val_mse: 13.5321\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 6.0695 - mae: 1.7402 - mse: 6.0695 - val_loss: 13.5508 - val_mae: 2.5977 - val_mse: 13.5508\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9827 - mae: 1.7338 - mse: 5.9827 - val_loss: 13.2877 - val_mae: 2.5986 - val_mse: 13.2877\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2112 - mae: 1.7851 - mse: 6.2112 - val_loss: 13.4553 - val_mae: 2.6284 - val_mse: 13.4553\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.9336 - mae: 1.7393 - mse: 5.9336 - val_loss: 13.5042 - val_mae: 2.5806 - val_mse: 13.5042\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.0222 - mae: 1.7385 - mse: 6.0222 - val_loss: 13.2782 - val_mae: 2.5645 - val_mse: 13.2782\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.9405 - mae: 1.7300 - mse: 5.9405 - val_loss: 13.2717 - val_mae: 2.5908 - val_mse: 13.2717\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 5.9409 - mae: 1.7327 - mse: 5.9409 - val_loss: 13.3498 - val_mae: 2.6013 - val_mse: 13.3498\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5.9739 - mae: 1.7310 - mse: 5.9739 - val_loss: 13.1919 - val_mae: 2.5911 - val_mse: 13.1919\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 5.9408 - mae: 1.7201 - mse: 5.9408 - val_loss: 13.3824 - val_mae: 2.5904 - val_mse: 13.3824\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 5.8633 - mae: 1.7102 - mse: 5.8633 - val_loss: 13.2958 - val_mae: 2.6121 - val_mse: 13.2958\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 5.8805 - mae: 1.7262 - mse: 5.8805 - val_loss: 13.0345 - val_mae: 2.5712 - val_mse: 13.0345\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 5.9308 - mae: 1.7381 - mse: 5.9308 - val_loss: 13.6609 - val_mae: 2.6091 - val_mse: 13.6609\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.8117 - mae: 1.7103 - mse: 5.8117 - val_loss: 13.3223 - val_mae: 2.5900 - val_mse: 13.3223\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7782 - mae: 1.7135 - mse: 5.7782 - val_loss: 13.4494 - val_mae: 2.6127 - val_mse: 13.4494\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.7886 - mae: 1.7165 - mse: 5.7886 - val_loss: 13.1102 - val_mae: 2.5968 - val_mse: 13.1102\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.7740 - mae: 1.7236 - mse: 5.7740 - val_loss: 13.2555 - val_mae: 2.6022 - val_mse: 13.2555\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.7984 - mae: 1.7217 - mse: 5.7984 - val_loss: 13.3382 - val_mae: 2.5914 - val_mse: 13.3382\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5.8498 - mae: 1.7211 - mse: 5.8498 - val_loss: 13.1973 - val_mae: 2.5667 - val_mse: 13.1973\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.7947 - mae: 1.7147 - mse: 5.7947 - val_loss: 13.4229 - val_mae: 2.6388 - val_mse: 13.4229\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 5.8030 - mae: 1.7168 - mse: 5.8030 - val_loss: 12.9874 - val_mae: 2.5540 - val_mse: 12.9874\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 5.6770 - mae: 1.6872 - mse: 5.6770 - val_loss: 13.6141 - val_mae: 2.6268 - val_mse: 13.6141\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 5.6850 - mae: 1.6979 - mse: 5.6850 - val_loss: 13.1044 - val_mae: 2.6010 - val_mse: 13.1044\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.6067 - mae: 1.6920 - mse: 5.6067 - val_loss: 13.1999 - val_mae: 2.5715 - val_mse: 13.1999\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 5.5944 - mae: 1.6842 - mse: 5.5944 - val_loss: 13.3076 - val_mae: 2.5893 - val_mse: 13.3076\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.6772 - mae: 1.7099 - mse: 5.6772 - val_loss: 13.3144 - val_mae: 2.6109 - val_mse: 13.3144\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 5.5376 - mae: 1.6835 - mse: 5.5376 - val_loss: 13.2742 - val_mae: 2.5763 - val_mse: 13.2742\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 5.6542 - mae: 1.6952 - mse: 5.6542 - val_loss: 13.1473 - val_mae: 2.5411 - val_mse: 13.1473\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.5553 - mae: 1.6688 - mse: 5.5553 - val_loss: 13.4428 - val_mae: 2.6333 - val_mse: 13.4428\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.5016 - mae: 1.6776 - mse: 5.5016 - val_loss: 13.2398 - val_mae: 2.6002 - val_mse: 13.2398\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.5036 - mae: 1.6733 - mse: 5.5036 - val_loss: 13.3372 - val_mae: 2.5888 - val_mse: 13.3372\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.4890 - mae: 1.6668 - mse: 5.4890 - val_loss: 13.1781 - val_mae: 2.5899 - val_mse: 13.1781\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.4466 - mae: 1.6637 - mse: 5.4466 - val_loss: 13.4652 - val_mae: 2.6438 - val_mse: 13.4652\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 5.4624 - mae: 1.6667 - mse: 5.4624 - val_loss: 13.4157 - val_mae: 2.6162 - val_mse: 13.4157\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 5.4604 - mae: 1.6722 - mse: 5.4604 - val_loss: 13.1718 - val_mae: 2.5738 - val_mse: 13.1718\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.5019 - mae: 1.6801 - mse: 5.5019 - val_loss: 13.0836 - val_mae: 2.5762 - val_mse: 13.0836\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4664 - mae: 1.6667 - mse: 5.4664 - val_loss: 13.3900 - val_mae: 2.5988 - val_mse: 13.3900\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4153 - mae: 1.6698 - mse: 5.4153 - val_loss: 12.9706 - val_mae: 2.5870 - val_mse: 12.9706\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3715 - mae: 1.6449 - mse: 5.3715 - val_loss: 13.4391 - val_mae: 2.5872 - val_mse: 13.4391\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3176 - mae: 1.6460 - mse: 5.3176 - val_loss: 13.2337 - val_mae: 2.6398 - val_mse: 13.2337\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3487 - mae: 1.6632 - mse: 5.3487 - val_loss: 13.1100 - val_mae: 2.5979 - val_mse: 13.1100\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3361 - mae: 1.6567 - mse: 5.3361 - val_loss: 13.0272 - val_mae: 2.5392 - val_mse: 13.0272\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2843 - mae: 1.6407 - mse: 5.2843 - val_loss: 13.1062 - val_mae: 2.5943 - val_mse: 13.1062\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2436 - mae: 1.6466 - mse: 5.2436 - val_loss: 13.4203 - val_mae: 2.6257 - val_mse: 13.4203\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2426 - mae: 1.6414 - mse: 5.2426 - val_loss: 13.2619 - val_mae: 2.5768 - val_mse: 13.2619\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4263 - mae: 1.6427 - mse: 5.4263 - val_loss: 13.4224 - val_mae: 2.5875 - val_mse: 13.4224\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2422 - mae: 1.6392 - mse: 5.2422 - val_loss: 13.0870 - val_mae: 2.6444 - val_mse: 13.0870\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2335 - mae: 1.6317 - mse: 5.2335 - val_loss: 13.3093 - val_mae: 2.5741 - val_mse: 13.3093\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1692 - mae: 1.6128 - mse: 5.1692 - val_loss: 13.2427 - val_mae: 2.6108 - val_mse: 13.2427\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2232 - mae: 1.6423 - mse: 5.2232 - val_loss: 13.3608 - val_mae: 2.6346 - val_mse: 13.3608\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1160 - mae: 1.6119 - mse: 5.1160 - val_loss: 13.1805 - val_mae: 2.5512 - val_mse: 13.1805\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1041 - mae: 1.6049 - mse: 5.1041 - val_loss: 12.9238 - val_mae: 2.5857 - val_mse: 12.9238\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.0783 - mae: 1.6231 - mse: 5.0783 - val_loss: 13.2480 - val_mae: 2.6230 - val_mse: 13.2480\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0954 - mae: 1.6091 - mse: 5.0954 - val_loss: 13.2719 - val_mae: 2.5935 - val_mse: 13.2719\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0731 - mae: 1.6055 - mse: 5.0731 - val_loss: 13.1920 - val_mae: 2.6101 - val_mse: 13.1920\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0330 - mae: 1.6062 - mse: 5.0330 - val_loss: 13.0858 - val_mae: 2.6014 - val_mse: 13.0858\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0239 - mae: 1.5982 - mse: 5.0239 - val_loss: 13.0121 - val_mae: 2.5899 - val_mse: 13.0121\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9971 - mae: 1.6035 - mse: 4.9971 - val_loss: 13.3535 - val_mae: 2.6207 - val_mse: 13.3535\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0041 - mae: 1.6073 - mse: 5.0041 - val_loss: 13.1337 - val_mae: 2.6112 - val_mse: 13.1337\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9790 - mae: 1.6033 - mse: 4.9790 - val_loss: 12.9895 - val_mae: 2.5779 - val_mse: 12.9895\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9534 - mae: 1.5887 - mse: 4.9534 - val_loss: 13.3724 - val_mae: 2.6082 - val_mse: 13.3724\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.9945 - mae: 1.5835 - mse: 4.9945 - val_loss: 13.3336 - val_mae: 2.6144 - val_mse: 13.3336\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9067 - mae: 1.5876 - mse: 4.9067 - val_loss: 13.8019 - val_mae: 2.6875 - val_mse: 13.8019\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5.0034 - mae: 1.6043 - mse: 5.0034 - val_loss: 13.1910 - val_mae: 2.6277 - val_mse: 13.1910\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.8871 - mae: 1.5947 - mse: 4.8871 - val_loss: 13.0545 - val_mae: 2.5953 - val_mse: 13.0545\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.8571 - mae: 1.5696 - mse: 4.8571 - val_loss: 13.1123 - val_mae: 2.5790 - val_mse: 13.1123\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.9136 - mae: 1.5985 - mse: 4.9136 - val_loss: 13.1722 - val_mae: 2.6192 - val_mse: 13.1722\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.8020 - mae: 1.5715 - mse: 4.8020 - val_loss: 13.1286 - val_mae: 2.5847 - val_mse: 13.1286\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.8389 - mae: 1.5730 - mse: 4.8389 - val_loss: 13.2119 - val_mae: 2.5972 - val_mse: 13.2119\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.8241 - mae: 1.5715 - mse: 4.8241 - val_loss: 13.3227 - val_mae: 2.6378 - val_mse: 13.3227\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.8128 - mae: 1.5647 - mse: 4.8128 - val_loss: 13.0351 - val_mae: 2.6066 - val_mse: 13.0351\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.7723 - mae: 1.5601 - mse: 4.7723 - val_loss: 12.9867 - val_mae: 2.6076 - val_mse: 12.9867\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.8697 - mae: 1.5737 - mse: 4.8697 - val_loss: 13.5109 - val_mae: 2.6308 - val_mse: 13.5109\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.7886 - mae: 1.5744 - mse: 4.7886 - val_loss: 13.4463 - val_mae: 2.6437 - val_mse: 13.4463\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.7579 - mae: 1.5754 - mse: 4.7579 - val_loss: 12.9120 - val_mae: 2.5982 - val_mse: 12.9120\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.7072 - mae: 1.5489 - mse: 4.7072 - val_loss: 13.3275 - val_mae: 2.6108 - val_mse: 13.3275\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.7386 - mae: 1.5410 - mse: 4.7386 - val_loss: 13.2456 - val_mae: 2.6417 - val_mse: 13.2456\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.7129 - mae: 1.5463 - mse: 4.7129 - val_loss: 13.2174 - val_mae: 2.5822 - val_mse: 13.2174\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.6324 - mae: 1.5442 - mse: 4.6324 - val_loss: 13.1749 - val_mae: 2.6400 - val_mse: 13.1749\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.6367 - mae: 1.5469 - mse: 4.6367 - val_loss: 12.9977 - val_mae: 2.5973 - val_mse: 12.9977\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.7591 - mae: 1.5369 - mse: 4.7591 - val_loss: 13.5416 - val_mae: 2.6071 - val_mse: 13.5416\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.5535 - mae: 1.5159 - mse: 4.5535 - val_loss: 13.2249 - val_mae: 2.6642 - val_mse: 13.2249\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.6692 - mae: 1.5587 - mse: 4.6692 - val_loss: 12.9116 - val_mae: 2.5850 - val_mse: 12.9116\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.6152 - mae: 1.5487 - mse: 4.6152 - val_loss: 13.5130 - val_mae: 2.6560 - val_mse: 13.5130\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.5319 - mae: 1.5328 - mse: 4.5319 - val_loss: 13.3471 - val_mae: 2.6480 - val_mse: 13.3471\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.5272 - mae: 1.5276 - mse: 4.5272 - val_loss: 13.4121 - val_mae: 2.6613 - val_mse: 13.4121\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.5394 - mae: 1.5154 - mse: 4.5394 - val_loss: 13.4041 - val_mae: 2.6257 - val_mse: 13.4041\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.4651 - mae: 1.5199 - mse: 4.4651 - val_loss: 13.2506 - val_mae: 2.6313 - val_mse: 13.2506\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.4938 - mae: 1.5342 - mse: 4.4938 - val_loss: 13.1285 - val_mae: 2.6263 - val_mse: 13.1285\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5370 - mae: 1.5307 - mse: 4.5370 - val_loss: 13.3428 - val_mae: 2.5974 - val_mse: 13.3428\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.5997 - mae: 1.5405 - mse: 4.5997 - val_loss: 13.5857 - val_mae: 2.7155 - val_mse: 13.5857\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.5060 - mae: 1.5163 - mse: 4.5060 - val_loss: 13.3040 - val_mae: 2.5833 - val_mse: 13.3040\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.4586 - mae: 1.5040 - mse: 4.4586 - val_loss: 13.0778 - val_mae: 2.6291 - val_mse: 13.0778\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.4952 - mae: 1.5377 - mse: 4.4952 - val_loss: 13.1546 - val_mae: 2.6062 - val_mse: 13.1546\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4078 - mae: 1.4941 - mse: 4.4078 - val_loss: 13.4513 - val_mae: 2.6497 - val_mse: 13.4513\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3550 - mae: 1.4938 - mse: 4.3550 - val_loss: 13.3783 - val_mae: 2.6498 - val_mse: 13.3783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 결과 분석"
      ],
      "metadata": {
        "id": "bHzXPEaXJ_n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "his_dict = history.history\n",
        "mse = his_dict['mse']\n",
        "val_mse = his_dict['val_mse'] # 검증 데이터가 있는 경우 ‘val_’ 수식어가 붙습니다.\n",
        "\n",
        "epochs = range(1, len(mse) + 1)\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "\n",
        "# 훈련 및 검증 손실 그리기\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(epochs, mse, color = 'blue', label = 'train_mse')\n",
        "ax1.plot(epochs, val_mse, color = 'orange', label = 'val_mse')\n",
        "ax1.set_title('train and val mse')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('mse')\n",
        "ax1.legend()\n",
        "\n",
        "mae = his_dict['mae']\n",
        "val_mae = his_dict['val_mae']\n",
        "\n",
        "# 훈련 및 검증 정확도 그리기\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(epochs, mae, color = 'blue', label = 'train_mae')\n",
        "ax2.plot(epochs, val_mae, color = 'orange', label = 'val_mae')\n",
        "ax2.set_title('train and val mae')\n",
        "ax2.set_xlabel('epochs')\n",
        "ax2.set_ylabel('mae')\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "p_KtNrEQ9F0E",
        "outputId": "117a4097-41c5-4c53-a755-895f865d2e15"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가하기"
      ],
      "metadata": {
        "id": "sZyB9ETOLf8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test) # 2.2 -> 실제 집값과 2,200 달러 정도 차이로 집값 예측"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rGRIMaRKIjr",
        "outputId": "bbc95b1d-6086-4dfe-b7af-04dee11ec6fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 9.8896 - mae: 2.2471 - mse: 9.8896\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.889628410339355, 2.2470757961273193, 9.889628410339355]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 예측-> 차트 그리기"
      ],
      "metadata": {
        "id": "xLTtA0rRMFBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(X_test).flatten()\n",
        "\n",
        "plt.scatter(y_test, test_predictions)\n",
        "plt.xlabel('True Values [Price]')\n",
        "plt.ylabel('Predictions [Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "OL2Oxwtt9FxH",
        "outputId": "a6ada2f6-6569-4774-fa5d-25ad5f54870e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K- FOLD 사용하여 모델 학습하기\n",
        "\n",
        "*   학습 데이터 부족으로 성능이 낮은 경우 적용 가능\n",
        "*   검증 데이터셋을 k-fold를 사용하여 학습 데이터 확보"
      ],
      "metadata": {
        "id": "HpQWrTADNg1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-fold를 위한 데이터 준비하기"
      ],
      "metadata": {
        "id": "E7m8xpWDN7Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data                           # no tensorflow\n",
        "\n",
        "# 데이터를 다운받습니다.(훈련셋 80%, 테스트셋 20%)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2,\n",
        "                                                 seed=777)"
      ],
      "metadata": {
        "id": "wm83rEdn9FuS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 데이터 표준화\n",
        "mean = np.mean(X_train, axis = 0)\n",
        "std = np.std(X_train, axis = 0)\n",
        "# 여기까진 전부 동일합니다.\n",
        "x_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std"
      ],
      "metadata": {
        "id": "Vmk0GrJg9FrO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-FOLD 를 사용한 모델 학습"
      ],
      "metadata": {
        "id": "5zrtPrVkOU7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# 3-fold 로 나눠서 검증데이터셋 사용하여 학습\n",
        "k =3\n",
        "\n",
        "kfold = KFold(n_splits=k)\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation='relu', input_shape=(13,)))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(1))   # activation = linear\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 각 모델의 평가 정보 담는 리스트 선언\n",
        "mae_list = []\n",
        "\n",
        "# k번 학습 및 평가\n",
        "# k번 진행합니다.\n",
        "for train_index, val_index in kfold.split(x_train):\n",
        "    # 해당 인덱스는 무작위로 생성됩니다.\n",
        "    # 무작위로 생성해주는 것은 과대적합을 피할 수 있는 좋은 방법입니다.\n",
        "    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # 모델을 불러옵니다.\n",
        "    model = get_model()\n",
        "\n",
        "    model.fit(x_train_fold, y_train_fold, epochs = 300, validation_data = (x_val_fold, y_val_fold))\n",
        "\n",
        "    _, test_mae = model.evaluate(X_test, y_test)\n",
        "    mae_list.append(test_mae)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWppLh7g9Foo",
        "outputId": "d6dab739-7729-423a-e96a-455eb74f59d1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 38ms/step - loss: 587.7433 - mae: 22.3121 - val_loss: 557.9016 - val_mae: 21.7265\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 564.2549 - mae: 21.7908 - val_loss: 537.1339 - val_mae: 21.2388\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 541.1297 - mae: 21.2677 - val_loss: 515.3892 - val_mae: 20.7141\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 515.4985 - mae: 20.6714 - val_loss: 489.4986 - val_mae: 20.0729\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 484.0773 - mae: 19.9117 - val_loss: 455.9772 - val_mae: 19.2381\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 444.5518 - mae: 18.9433 - val_loss: 413.2702 - val_mae: 18.1621\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 394.8471 - mae: 17.6959 - val_loss: 361.3117 - val_mae: 16.8052\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 336.7594 - mae: 16.2080 - val_loss: 300.9206 - val_mae: 15.1232\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 270.6151 - mae: 14.3597 - val_loss: 237.5583 - val_mae: 13.1515\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 205.2671 - mae: 12.1674 - val_loss: 176.8268 - val_mae: 11.0127\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 149.7035 - mae: 9.9638 - val_loss: 127.2683 - val_mae: 9.0383\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 110.7673 - mae: 8.2162 - val_loss: 92.8606 - val_mae: 7.5988\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 83.9513 - mae: 7.1044 - val_loss: 72.8068 - val_mae: 6.6572\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 69.9916 - mae: 6.4623 - val_loss: 59.6147 - val_mae: 5.9460\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 59.2556 - mae: 5.9661 - val_loss: 49.6408 - val_mae: 5.3619\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 50.3515 - mae: 5.4816 - val_loss: 41.7587 - val_mae: 4.8601\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 42.7103 - mae: 5.0421 - val_loss: 36.1838 - val_mae: 4.4389\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 37.3995 - mae: 4.6914 - val_loss: 31.5796 - val_mae: 4.1478\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 33.1192 - mae: 4.3892 - val_loss: 28.2786 - val_mae: 3.9098\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 30.0163 - mae: 4.1085 - val_loss: 25.8803 - val_mae: 3.7342\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 27.8854 - mae: 3.8895 - val_loss: 24.2296 - val_mae: 3.5875\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 25.9865 - mae: 3.6917 - val_loss: 23.1545 - val_mae: 3.5009\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 24.6608 - mae: 3.5612 - val_loss: 22.3971 - val_mae: 3.4387\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 23.5158 - mae: 3.4507 - val_loss: 21.7789 - val_mae: 3.3848\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 22.5561 - mae: 3.3472 - val_loss: 21.3377 - val_mae: 3.3323\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.7503 - mae: 3.2442 - val_loss: 21.0145 - val_mae: 3.3026\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 20.9754 - mae: 3.1630 - val_loss: 20.6490 - val_mae: 3.2823\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 20.3184 - mae: 3.1047 - val_loss: 20.3220 - val_mae: 3.2636\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.8050 - mae: 3.0399 - val_loss: 20.1255 - val_mae: 3.2335\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.2434 - mae: 2.9962 - val_loss: 19.7842 - val_mae: 3.2257\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.6208 - mae: 2.9350 - val_loss: 19.5597 - val_mae: 3.2107\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.1774 - mae: 2.8897 - val_loss: 19.4013 - val_mae: 3.1915\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.6670 - mae: 2.8370 - val_loss: 19.1624 - val_mae: 3.1763\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 17.2194 - mae: 2.8022 - val_loss: 18.9053 - val_mae: 3.1677\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.8368 - mae: 2.7765 - val_loss: 18.7156 - val_mae: 3.1597\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.4927 - mae: 2.7488 - val_loss: 18.5589 - val_mae: 3.1513\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.1312 - mae: 2.7045 - val_loss: 18.4686 - val_mae: 3.1315\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.8321 - mae: 2.6584 - val_loss: 18.2050 - val_mae: 3.0992\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.5195 - mae: 2.6229 - val_loss: 17.9950 - val_mae: 3.0945\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.1718 - mae: 2.6002 - val_loss: 17.8574 - val_mae: 3.0883\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.9573 - mae: 2.5935 - val_loss: 17.8006 - val_mae: 3.0913\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6591 - mae: 2.5670 - val_loss: 17.6839 - val_mae: 3.0848\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.4203 - mae: 2.5383 - val_loss: 17.6390 - val_mae: 3.0734\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.1671 - mae: 2.5120 - val_loss: 17.5233 - val_mae: 3.0644\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.9423 - mae: 2.5001 - val_loss: 17.4121 - val_mae: 3.0562\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.8144 - mae: 2.4956 - val_loss: 17.3468 - val_mae: 3.0576\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.5157 - mae: 2.4693 - val_loss: 17.2364 - val_mae: 3.0480\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.3532 - mae: 2.4505 - val_loss: 17.1715 - val_mae: 3.0462\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2656 - mae: 2.4368 - val_loss: 17.2058 - val_mae: 3.0354\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.0194 - mae: 2.4164 - val_loss: 17.1180 - val_mae: 3.0322\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.8786 - mae: 2.4180 - val_loss: 17.0168 - val_mae: 3.0347\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.6311 - mae: 2.4038 - val_loss: 16.8473 - val_mae: 3.0269\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.5290 - mae: 2.4011 - val_loss: 16.8108 - val_mae: 3.0260\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3621 - mae: 2.3818 - val_loss: 16.6938 - val_mae: 3.0173\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.1971 - mae: 2.3592 - val_loss: 16.7665 - val_mae: 3.0060\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.0994 - mae: 2.3486 - val_loss: 16.6583 - val_mae: 2.9978\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.9782 - mae: 2.3553 - val_loss: 16.6490 - val_mae: 3.0111\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.8094 - mae: 2.3478 - val_loss: 16.6373 - val_mae: 3.0124\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.6851 - mae: 2.3326 - val_loss: 16.4736 - val_mae: 3.0026\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.6155 - mae: 2.3405 - val_loss: 16.3974 - val_mae: 3.0006\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.4487 - mae: 2.3209 - val_loss: 16.3840 - val_mae: 2.9957\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.4075 - mae: 2.3138 - val_loss: 16.3988 - val_mae: 2.9950\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.3752 - mae: 2.3207 - val_loss: 16.2952 - val_mae: 3.0044\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.1356 - mae: 2.3120 - val_loss: 16.3060 - val_mae: 2.9982\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.1325 - mae: 2.2983 - val_loss: 16.2155 - val_mae: 2.9867\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.9755 - mae: 2.2819 - val_loss: 16.1521 - val_mae: 2.9740\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.9209 - mae: 2.2783 - val_loss: 16.1529 - val_mae: 2.9818\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.9073 - mae: 2.2875 - val_loss: 16.2217 - val_mae: 2.9787\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.8148 - mae: 2.2857 - val_loss: 16.1324 - val_mae: 2.9794\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.6111 - mae: 2.2838 - val_loss: 15.9743 - val_mae: 2.9748\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.5596 - mae: 2.2808 - val_loss: 15.9876 - val_mae: 2.9760\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.5222 - mae: 2.2824 - val_loss: 16.0604 - val_mae: 2.9894\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.4274 - mae: 2.2759 - val_loss: 16.0673 - val_mae: 2.9887\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3444 - mae: 2.2559 - val_loss: 16.1101 - val_mae: 2.9878\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.2409 - mae: 2.2469 - val_loss: 16.0246 - val_mae: 2.9867\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.3285 - mae: 2.2632 - val_loss: 15.8589 - val_mae: 2.9819\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.2988 - mae: 2.2463 - val_loss: 15.9851 - val_mae: 2.9609\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.1214 - mae: 2.2286 - val_loss: 15.8584 - val_mae: 2.9603\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9819 - mae: 2.2311 - val_loss: 15.7497 - val_mae: 2.9572\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.9430 - mae: 2.2347 - val_loss: 15.7161 - val_mae: 2.9612\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8601 - mae: 2.2243 - val_loss: 15.7461 - val_mae: 2.9638\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.7916 - mae: 2.2122 - val_loss: 15.7229 - val_mae: 2.9650\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.6995 - mae: 2.2030 - val_loss: 15.7304 - val_mae: 2.9640\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6483 - mae: 2.1983 - val_loss: 15.7686 - val_mae: 2.9657\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6127 - mae: 2.1989 - val_loss: 15.6988 - val_mae: 2.9660\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5274 - mae: 2.1954 - val_loss: 15.6213 - val_mae: 2.9583\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4681 - mae: 2.1893 - val_loss: 15.5623 - val_mae: 2.9545\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4143 - mae: 2.1831 - val_loss: 15.5340 - val_mae: 2.9391\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3777 - mae: 2.1731 - val_loss: 15.4762 - val_mae: 2.9425\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2676 - mae: 2.1642 - val_loss: 15.4310 - val_mae: 2.9365\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2455 - mae: 2.1635 - val_loss: 15.3648 - val_mae: 2.9307\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1687 - mae: 2.1600 - val_loss: 15.3469 - val_mae: 2.9332\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1241 - mae: 2.1602 - val_loss: 15.3561 - val_mae: 2.9488\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0608 - mae: 2.1563 - val_loss: 15.2562 - val_mae: 2.9243\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0576 - mae: 2.1572 - val_loss: 15.3062 - val_mae: 2.9398\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9595 - mae: 2.1447 - val_loss: 15.4369 - val_mae: 2.9513\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9236 - mae: 2.1308 - val_loss: 15.3761 - val_mae: 2.9370\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.8672 - mae: 2.1331 - val_loss: 15.3044 - val_mae: 2.9494\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7981 - mae: 2.1292 - val_loss: 15.4122 - val_mae: 2.9484\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7594 - mae: 2.1127 - val_loss: 15.4568 - val_mae: 2.9474\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7489 - mae: 2.1200 - val_loss: 15.3241 - val_mae: 2.9592\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6382 - mae: 2.1191 - val_loss: 15.3281 - val_mae: 2.9558\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6649 - mae: 2.1258 - val_loss: 15.3798 - val_mae: 2.9602\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5181 - mae: 2.0957 - val_loss: 15.2035 - val_mae: 2.9188\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5738 - mae: 2.0920 - val_loss: 15.1148 - val_mae: 2.9134\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5094 - mae: 2.0958 - val_loss: 15.1737 - val_mae: 2.9332\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4327 - mae: 2.0975 - val_loss: 15.0487 - val_mae: 2.9245\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3606 - mae: 2.0910 - val_loss: 15.0197 - val_mae: 2.9208\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.3139 - mae: 2.0811 - val_loss: 15.0223 - val_mae: 2.9220\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.2797 - mae: 2.0722 - val_loss: 15.0851 - val_mae: 2.9233\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2271 - mae: 2.0690 - val_loss: 15.0533 - val_mae: 2.9281\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.2040 - mae: 2.0756 - val_loss: 15.0929 - val_mae: 2.9312\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1734 - mae: 2.0589 - val_loss: 15.0931 - val_mae: 2.9190\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1162 - mae: 2.0467 - val_loss: 15.0301 - val_mae: 2.9216\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.0510 - mae: 2.0486 - val_loss: 14.9710 - val_mae: 2.9114\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0596 - mae: 2.0477 - val_loss: 14.9327 - val_mae: 2.8959\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0531 - mae: 2.0582 - val_loss: 14.9128 - val_mae: 2.8998\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.9619 - mae: 2.0509 - val_loss: 14.9983 - val_mae: 2.9052\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.9060 - mae: 2.0298 - val_loss: 14.8803 - val_mae: 2.8841\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.9037 - mae: 2.0261 - val_loss: 14.7878 - val_mae: 2.8688\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.8256 - mae: 2.0195 - val_loss: 14.8925 - val_mae: 2.9077\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8012 - mae: 2.0318 - val_loss: 14.8015 - val_mae: 2.8982\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7728 - mae: 2.0190 - val_loss: 14.7558 - val_mae: 2.8831\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7120 - mae: 2.0053 - val_loss: 14.6613 - val_mae: 2.8712\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7534 - mae: 2.0124 - val_loss: 14.7593 - val_mae: 2.8849\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6216 - mae: 2.0063 - val_loss: 14.7007 - val_mae: 2.8847\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5488 - mae: 1.9992 - val_loss: 14.6304 - val_mae: 2.8819\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5324 - mae: 1.9935 - val_loss: 14.5952 - val_mae: 2.8732\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.5032 - mae: 1.9925 - val_loss: 14.6332 - val_mae: 2.8708\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5093 - mae: 2.0013 - val_loss: 14.6572 - val_mae: 2.8881\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.4206 - mae: 1.9841 - val_loss: 14.5880 - val_mae: 2.8658\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.4138 - mae: 1.9732 - val_loss: 14.6418 - val_mae: 2.8609\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.3875 - mae: 1.9730 - val_loss: 14.6676 - val_mae: 2.8782\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.3267 - mae: 1.9748 - val_loss: 14.7252 - val_mae: 2.8843\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2666 - mae: 1.9643 - val_loss: 14.7549 - val_mae: 2.8975\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2423 - mae: 1.9635 - val_loss: 14.7048 - val_mae: 2.8809\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1808 - mae: 1.9496 - val_loss: 14.6111 - val_mae: 2.8594\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.1680 - mae: 1.9433 - val_loss: 14.6147 - val_mae: 2.8655\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1241 - mae: 1.9521 - val_loss: 14.5598 - val_mae: 2.8636\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0820 - mae: 1.9407 - val_loss: 14.4129 - val_mae: 2.8522\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.0667 - mae: 1.9429 - val_loss: 14.4727 - val_mae: 2.8629\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.0770 - mae: 1.9350 - val_loss: 14.5485 - val_mae: 2.8546\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9616 - mae: 1.9179 - val_loss: 14.4799 - val_mae: 2.8542\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9292 - mae: 1.9242 - val_loss: 14.4853 - val_mae: 2.8562\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9442 - mae: 1.9281 - val_loss: 14.5945 - val_mae: 2.8692\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8296 - mae: 1.9089 - val_loss: 14.5900 - val_mae: 2.8649\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8509 - mae: 1.9105 - val_loss: 14.5709 - val_mae: 2.8656\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9010 - mae: 1.9151 - val_loss: 14.5551 - val_mae: 2.8616\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7740 - mae: 1.8999 - val_loss: 14.3673 - val_mae: 2.8569\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7419 - mae: 1.8910 - val_loss: 14.3504 - val_mae: 2.8515\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7400 - mae: 1.8918 - val_loss: 14.6658 - val_mae: 2.8842\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6759 - mae: 1.8807 - val_loss: 14.4865 - val_mae: 2.8460\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6811 - mae: 1.8768 - val_loss: 14.4425 - val_mae: 2.8508\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5845 - mae: 1.8857 - val_loss: 14.6653 - val_mae: 2.8883\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5791 - mae: 1.8805 - val_loss: 14.5243 - val_mae: 2.8572\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4497 - mae: 1.8565 - val_loss: 14.4743 - val_mae: 2.8543\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4834 - mae: 1.8616 - val_loss: 14.4700 - val_mae: 2.8553\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4406 - mae: 1.8496 - val_loss: 14.3971 - val_mae: 2.8442\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4140 - mae: 1.8570 - val_loss: 14.4405 - val_mae: 2.8531\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3836 - mae: 1.8482 - val_loss: 14.2487 - val_mae: 2.8297\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3441 - mae: 1.8391 - val_loss: 14.2878 - val_mae: 2.8368\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3119 - mae: 1.8364 - val_loss: 14.2929 - val_mae: 2.8357\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3174 - mae: 1.8445 - val_loss: 14.2931 - val_mae: 2.8322\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2555 - mae: 1.8306 - val_loss: 14.2426 - val_mae: 2.8240\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2503 - mae: 1.8228 - val_loss: 14.2331 - val_mae: 2.8226\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2507 - mae: 1.8381 - val_loss: 14.4335 - val_mae: 2.8511\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1646 - mae: 1.8258 - val_loss: 14.2600 - val_mae: 2.8302\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1317 - mae: 1.8069 - val_loss: 14.2092 - val_mae: 2.8201\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1050 - mae: 1.7949 - val_loss: 14.2613 - val_mae: 2.8256\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0478 - mae: 1.7950 - val_loss: 14.2793 - val_mae: 2.8343\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0534 - mae: 1.8011 - val_loss: 14.4049 - val_mae: 2.8525\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9933 - mae: 1.7852 - val_loss: 14.2843 - val_mae: 2.8231\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9696 - mae: 1.7751 - val_loss: 14.2917 - val_mae: 2.8273\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9340 - mae: 1.7752 - val_loss: 14.3326 - val_mae: 2.8389\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0185 - mae: 1.7972 - val_loss: 14.4235 - val_mae: 2.8556\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8917 - mae: 1.7779 - val_loss: 14.1174 - val_mae: 2.8066\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9437 - mae: 1.7655 - val_loss: 14.1256 - val_mae: 2.8023\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.9613 - mae: 1.7852 - val_loss: 14.2682 - val_mae: 2.8342\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8294 - mae: 1.7691 - val_loss: 14.1080 - val_mae: 2.8092\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8466 - mae: 1.7577 - val_loss: 14.2105 - val_mae: 2.8119\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7500 - mae: 1.7382 - val_loss: 14.1865 - val_mae: 2.8206\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7666 - mae: 1.7579 - val_loss: 14.2452 - val_mae: 2.8302\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7126 - mae: 1.7410 - val_loss: 14.1901 - val_mae: 2.8186\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6576 - mae: 1.7329 - val_loss: 14.2151 - val_mae: 2.8144\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6676 - mae: 1.7300 - val_loss: 14.2256 - val_mae: 2.8092\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6548 - mae: 1.7213 - val_loss: 14.1510 - val_mae: 2.8072\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6468 - mae: 1.7454 - val_loss: 14.3784 - val_mae: 2.8384\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5947 - mae: 1.7276 - val_loss: 14.2073 - val_mae: 2.8124\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5730 - mae: 1.7111 - val_loss: 14.0298 - val_mae: 2.7967\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5319 - mae: 1.7022 - val_loss: 14.1752 - val_mae: 2.8150\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5136 - mae: 1.7074 - val_loss: 14.1963 - val_mae: 2.8134\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4918 - mae: 1.7047 - val_loss: 14.1549 - val_mae: 2.8081\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4648 - mae: 1.7028 - val_loss: 14.2613 - val_mae: 2.8178\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4759 - mae: 1.7185 - val_loss: 14.3885 - val_mae: 2.8425\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4128 - mae: 1.6873 - val_loss: 14.1514 - val_mae: 2.8112\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3997 - mae: 1.6867 - val_loss: 14.1429 - val_mae: 2.8134\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3976 - mae: 1.6963 - val_loss: 14.2544 - val_mae: 2.8201\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3104 - mae: 1.6729 - val_loss: 14.0220 - val_mae: 2.7929\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4267 - mae: 1.6953 - val_loss: 14.0531 - val_mae: 2.7988\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.3307 - mae: 1.6656 - val_loss: 14.1594 - val_mae: 2.7977\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3671 - mae: 1.6851 - val_loss: 14.2357 - val_mae: 2.8112\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3357 - mae: 1.6859 - val_loss: 14.1659 - val_mae: 2.7978\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2514 - mae: 1.6698 - val_loss: 14.3344 - val_mae: 2.8212\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2818 - mae: 1.6530 - val_loss: 14.2035 - val_mae: 2.7990\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2008 - mae: 1.6523 - val_loss: 14.3401 - val_mae: 2.8237\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.1629 - mae: 1.6554 - val_loss: 14.2799 - val_mae: 2.8141\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.0982 - mae: 1.6441 - val_loss: 14.1650 - val_mae: 2.7992\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1497 - mae: 1.6343 - val_loss: 14.0148 - val_mae: 2.7806\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0632 - mae: 1.6201 - val_loss: 14.1237 - val_mae: 2.7985\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1461 - mae: 1.6465 - val_loss: 14.4163 - val_mae: 2.8387\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1084 - mae: 1.6334 - val_loss: 14.1895 - val_mae: 2.7984\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0919 - mae: 1.6257 - val_loss: 14.3437 - val_mae: 2.8152\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9984 - mae: 1.6176 - val_loss: 14.2285 - val_mae: 2.8007\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9816 - mae: 1.6197 - val_loss: 14.2342 - val_mae: 2.8025\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0064 - mae: 1.6178 - val_loss: 14.0626 - val_mae: 2.7808\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9318 - mae: 1.5938 - val_loss: 14.1831 - val_mae: 2.7983\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.9309 - mae: 1.6046 - val_loss: 14.2111 - val_mae: 2.7984\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9108 - mae: 1.5974 - val_loss: 14.1867 - val_mae: 2.7931\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8713 - mae: 1.5920 - val_loss: 14.1800 - val_mae: 2.7921\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8507 - mae: 1.5887 - val_loss: 14.2444 - val_mae: 2.7929\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8354 - mae: 1.5771 - val_loss: 14.1774 - val_mae: 2.7815\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7598 - mae: 1.5702 - val_loss: 14.1028 - val_mae: 2.7761\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8380 - mae: 1.5852 - val_loss: 14.2564 - val_mae: 2.7964\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7876 - mae: 1.5755 - val_loss: 14.1518 - val_mae: 2.7777\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7479 - mae: 1.5750 - val_loss: 14.2599 - val_mae: 2.7872\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8092 - mae: 1.5834 - val_loss: 14.3314 - val_mae: 2.7994\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7666 - mae: 1.5809 - val_loss: 14.3012 - val_mae: 2.7926\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6723 - mae: 1.5566 - val_loss: 14.1218 - val_mae: 2.7712\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6648 - mae: 1.5508 - val_loss: 14.0018 - val_mae: 2.7559\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6671 - mae: 1.5552 - val_loss: 14.1151 - val_mae: 2.7721\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6642 - mae: 1.5530 - val_loss: 14.0342 - val_mae: 2.7606\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7252 - mae: 1.5777 - val_loss: 14.3725 - val_mae: 2.8002\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6901 - mae: 1.5723 - val_loss: 14.2007 - val_mae: 2.7785\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6182 - mae: 1.5570 - val_loss: 14.5829 - val_mae: 2.8233\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5476 - mae: 1.5480 - val_loss: 14.3158 - val_mae: 2.7873\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6012 - mae: 1.5423 - val_loss: 14.2345 - val_mae: 2.7773\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5255 - mae: 1.5349 - val_loss: 14.2845 - val_mae: 2.7804\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5344 - mae: 1.5200 - val_loss: 14.3116 - val_mae: 2.7855\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5073 - mae: 1.5280 - val_loss: 14.3726 - val_mae: 2.7940\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4867 - mae: 1.5187 - val_loss: 14.1837 - val_mae: 2.7761\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4826 - mae: 1.5123 - val_loss: 14.2838 - val_mae: 2.7869\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4652 - mae: 1.5250 - val_loss: 14.3595 - val_mae: 2.7883\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4176 - mae: 1.5077 - val_loss: 14.2095 - val_mae: 2.7682\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4082 - mae: 1.4993 - val_loss: 14.1960 - val_mae: 2.7712\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4484 - mae: 1.5092 - val_loss: 14.2393 - val_mae: 2.7717\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4070 - mae: 1.5048 - val_loss: 14.2550 - val_mae: 2.7693\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4142 - mae: 1.5188 - val_loss: 14.5650 - val_mae: 2.7991\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4137 - mae: 1.5114 - val_loss: 14.5732 - val_mae: 2.8080\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3649 - mae: 1.4923 - val_loss: 14.4036 - val_mae: 2.7851\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3429 - mae: 1.4869 - val_loss: 14.3135 - val_mae: 2.7763\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3703 - mae: 1.4881 - val_loss: 14.1717 - val_mae: 2.7565\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3463 - mae: 1.4817 - val_loss: 14.4076 - val_mae: 2.7849\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2912 - mae: 1.4874 - val_loss: 14.2133 - val_mae: 2.7548\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2755 - mae: 1.4779 - val_loss: 14.1873 - val_mae: 2.7518\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2630 - mae: 1.4809 - val_loss: 14.2608 - val_mae: 2.7637\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2174 - mae: 1.4638 - val_loss: 14.1677 - val_mae: 2.7487\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2352 - mae: 1.4699 - val_loss: 14.3163 - val_mae: 2.7673\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2587 - mae: 1.4858 - val_loss: 14.1847 - val_mae: 2.7539\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2638 - mae: 1.4826 - val_loss: 14.4482 - val_mae: 2.7849\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2041 - mae: 1.4663 - val_loss: 14.1480 - val_mae: 2.7484\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1581 - mae: 1.4463 - val_loss: 14.3503 - val_mae: 2.7627\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1849 - mae: 1.4590 - val_loss: 14.3143 - val_mae: 2.7622\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1745 - mae: 1.4670 - val_loss: 14.5110 - val_mae: 2.7891\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1205 - mae: 1.4452 - val_loss: 14.2663 - val_mae: 2.7568\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2263 - mae: 1.4567 - val_loss: 14.2394 - val_mae: 2.7462\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0995 - mae: 1.4477 - val_loss: 14.5118 - val_mae: 2.7800\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0863 - mae: 1.4490 - val_loss: 14.2885 - val_mae: 2.7586\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0889 - mae: 1.4345 - val_loss: 14.2284 - val_mae: 2.7515\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0487 - mae: 1.4315 - val_loss: 14.3825 - val_mae: 2.7651\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0363 - mae: 1.4293 - val_loss: 14.1223 - val_mae: 2.7336\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0508 - mae: 1.4295 - val_loss: 14.3447 - val_mae: 2.7607\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0320 - mae: 1.4320 - val_loss: 14.4154 - val_mae: 2.7616\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0376 - mae: 1.4382 - val_loss: 14.3287 - val_mae: 2.7581\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0047 - mae: 1.4359 - val_loss: 14.5722 - val_mae: 2.7859\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.9736 - mae: 1.4323 - val_loss: 14.5174 - val_mae: 2.7787\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.9416 - mae: 1.4129 - val_loss: 14.4154 - val_mae: 2.7616\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0085 - mae: 1.4238 - val_loss: 14.2005 - val_mae: 2.7423\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.9499 - mae: 1.4185 - val_loss: 14.2209 - val_mae: 2.7421\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.9008 - mae: 1.4187 - val_loss: 14.1455 - val_mae: 2.7337\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.8844 - mae: 1.3933 - val_loss: 14.2819 - val_mae: 2.7464\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.8722 - mae: 1.3894 - val_loss: 14.1995 - val_mae: 2.7390\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.9342 - mae: 1.4035 - val_loss: 14.2141 - val_mae: 2.7355\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.8830 - mae: 1.4159 - val_loss: 14.3246 - val_mae: 2.7410\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.8408 - mae: 1.3961 - val_loss: 14.3374 - val_mae: 2.7514\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.8072 - mae: 1.3931 - val_loss: 14.3363 - val_mae: 2.7457\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.7924 - mae: 1.3823 - val_loss: 14.3054 - val_mae: 2.7374\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.7359 - mae: 1.3610 - val_loss: 14.3123 - val_mae: 2.7352\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7937 - mae: 1.3818 - val_loss: 14.5002 - val_mae: 2.7614\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7256 - mae: 1.3732 - val_loss: 14.3395 - val_mae: 2.7457\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.7086 - mae: 1.3632 - val_loss: 14.4627 - val_mae: 2.7549\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.6835 - mae: 1.3591 - val_loss: 14.4048 - val_mae: 2.7455\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7113 - mae: 1.3623 - val_loss: 14.4879 - val_mae: 2.7484\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.6701 - mae: 1.3627 - val_loss: 14.5213 - val_mae: 2.7565\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.6660 - mae: 1.3570 - val_loss: 14.2768 - val_mae: 2.7288\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.6065 - mae: 1.3399 - val_loss: 14.3223 - val_mae: 2.7329\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.6199 - mae: 1.3495 - val_loss: 14.2724 - val_mae: 2.7283\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.5591 - mae: 1.3324 - val_loss: 14.2541 - val_mae: 2.7189\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.5737 - mae: 1.3300 - val_loss: 14.2077 - val_mae: 2.7189\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5844 - mae: 1.3395 - val_loss: 14.3840 - val_mae: 2.7373\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.5317 - mae: 1.3161 - val_loss: 14.3116 - val_mae: 2.7243\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 8.8209 - mae: 2.0645\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 28ms/step - loss: 541.2047 - mae: 21.5463 - val_loss: 629.0416 - val_mae: 23.2195\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 515.2125 - mae: 20.9045 - val_loss: 600.9684 - val_mae: 22.6074\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 490.7834 - mae: 20.3018 - val_loss: 572.9807 - val_mae: 21.9894\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 465.7171 - mae: 19.6545 - val_loss: 539.8138 - val_mae: 21.2510\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 435.0168 - mae: 18.8736 - val_loss: 500.0237 - val_mae: 20.3499\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 397.7406 - mae: 17.9105 - val_loss: 451.3434 - val_mae: 19.2096\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 354.9832 - mae: 16.7199 - val_loss: 392.9864 - val_mae: 17.7674\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 304.2557 - mae: 15.2493 - val_loss: 328.1843 - val_mae: 16.0334\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 248.0829 - mae: 13.5156 - val_loss: 261.4841 - val_mae: 14.0019\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 193.1218 - mae: 11.6442 - val_loss: 198.4581 - val_mae: 11.7874\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 142.8917 - mae: 9.7253 - val_loss: 146.5239 - val_mae: 9.6302\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 105.3536 - mae: 8.1529 - val_loss: 109.6961 - val_mae: 7.9593\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 78.8309 - mae: 6.8869 - val_loss: 88.5770 - val_mae: 6.8917\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.3619 - mae: 6.0493 - val_loss: 75.7377 - val_mae: 6.2595\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 52.8132 - mae: 5.4003 - val_loss: 65.7004 - val_mae: 5.7361\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 45.3126 - mae: 4.9531 - val_loss: 57.5561 - val_mae: 5.2560\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 38.8411 - mae: 4.5514 - val_loss: 51.5385 - val_mae: 4.8747\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 34.3901 - mae: 4.2815 - val_loss: 46.5590 - val_mae: 4.5689\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 30.9453 - mae: 4.0588 - val_loss: 42.8873 - val_mae: 4.3360\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 28.2671 - mae: 3.8777 - val_loss: 39.9041 - val_mae: 4.1636\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26.3921 - mae: 3.7424 - val_loss: 37.6996 - val_mae: 4.0194\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 24.9184 - mae: 3.6308 - val_loss: 35.5920 - val_mae: 3.8810\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 23.5424 - mae: 3.5268 - val_loss: 34.1983 - val_mae: 3.7673\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 22.7117 - mae: 3.4603 - val_loss: 32.6854 - val_mae: 3.6690\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 21.7816 - mae: 3.3939 - val_loss: 31.6397 - val_mae: 3.6088\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 21.0011 - mae: 3.3363 - val_loss: 30.7208 - val_mae: 3.5442\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 20.3736 - mae: 3.2933 - val_loss: 29.6953 - val_mae: 3.4806\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 19.8051 - mae: 3.2549 - val_loss: 28.9072 - val_mae: 3.4308\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 19.3083 - mae: 3.2121 - val_loss: 28.3454 - val_mae: 3.3843\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 18.7826 - mae: 3.1612 - val_loss: 27.8214 - val_mae: 3.3355\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.4041 - mae: 3.1276 - val_loss: 27.2712 - val_mae: 3.3015\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 18.0210 - mae: 3.1037 - val_loss: 26.7844 - val_mae: 3.2695\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 17.7608 - mae: 3.0916 - val_loss: 26.3117 - val_mae: 3.2499\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.2636 - mae: 3.0358 - val_loss: 26.0608 - val_mae: 3.2051\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.9561 - mae: 2.9880 - val_loss: 25.7945 - val_mae: 3.1806\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.6350 - mae: 2.9627 - val_loss: 25.3565 - val_mae: 3.1680\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 16.3344 - mae: 2.9460 - val_loss: 24.9723 - val_mae: 3.1449\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 16.0738 - mae: 2.9235 - val_loss: 24.7096 - val_mae: 3.1367\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.7721 - mae: 2.8905 - val_loss: 24.4896 - val_mae: 3.1072\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.5488 - mae: 2.8556 - val_loss: 24.2699 - val_mae: 3.0861\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 15.2678 - mae: 2.8325 - val_loss: 23.9405 - val_mae: 3.0780\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.0207 - mae: 2.8215 - val_loss: 23.6480 - val_mae: 3.0712\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.8016 - mae: 2.8059 - val_loss: 23.3913 - val_mae: 3.0679\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.6529 - mae: 2.8080 - val_loss: 23.0651 - val_mae: 3.0505\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.3913 - mae: 2.7716 - val_loss: 22.9240 - val_mae: 3.0299\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.1537 - mae: 2.7453 - val_loss: 22.8100 - val_mae: 3.0203\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.9967 - mae: 2.7315 - val_loss: 22.5872 - val_mae: 3.0150\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.7579 - mae: 2.7120 - val_loss: 22.3839 - val_mae: 2.9940\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.5175 - mae: 2.6742 - val_loss: 22.2815 - val_mae: 2.9566\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.4012 - mae: 2.6511 - val_loss: 22.1483 - val_mae: 2.9371\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.2085 - mae: 2.6362 - val_loss: 21.9858 - val_mae: 2.9388\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.9607 - mae: 2.6239 - val_loss: 21.7952 - val_mae: 2.9394\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.7906 - mae: 2.6244 - val_loss: 21.5863 - val_mae: 2.9426\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6318 - mae: 2.6098 - val_loss: 21.4674 - val_mae: 2.9256\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.4556 - mae: 2.5869 - val_loss: 21.3832 - val_mae: 2.9020\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3115 - mae: 2.5694 - val_loss: 21.2226 - val_mae: 2.8926\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.1595 - mae: 2.5538 - val_loss: 21.0840 - val_mae: 2.8797\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.0391 - mae: 2.5419 - val_loss: 20.9565 - val_mae: 2.8795\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.8690 - mae: 2.5236 - val_loss: 20.8241 - val_mae: 2.8663\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.7313 - mae: 2.5035 - val_loss: 20.7162 - val_mae: 2.8614\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.5984 - mae: 2.4825 - val_loss: 20.6434 - val_mae: 2.8445\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.4701 - mae: 2.4662 - val_loss: 20.6440 - val_mae: 2.8452\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.3473 - mae: 2.4551 - val_loss: 20.5369 - val_mae: 2.8296\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.2443 - mae: 2.4351 - val_loss: 20.5594 - val_mae: 2.8233\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.1276 - mae: 2.4236 - val_loss: 20.4477 - val_mae: 2.8236\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.0285 - mae: 2.4195 - val_loss: 20.4530 - val_mae: 2.8462\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.9195 - mae: 2.4076 - val_loss: 20.2506 - val_mae: 2.8119\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.8131 - mae: 2.3915 - val_loss: 20.2294 - val_mae: 2.7974\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.7389 - mae: 2.3722 - val_loss: 20.2099 - val_mae: 2.7940\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.8212 - mae: 2.3842 - val_loss: 20.2253 - val_mae: 2.8314\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.5779 - mae: 2.3576 - val_loss: 20.1867 - val_mae: 2.8052\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.4542 - mae: 2.3423 - val_loss: 20.0298 - val_mae: 2.7760\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.3979 - mae: 2.3431 - val_loss: 20.0779 - val_mae: 2.7863\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.3166 - mae: 2.3359 - val_loss: 19.9971 - val_mae: 2.7794\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.2328 - mae: 2.3240 - val_loss: 19.9773 - val_mae: 2.7826\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.1765 - mae: 2.3102 - val_loss: 19.9989 - val_mae: 2.7894\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1005 - mae: 2.2957 - val_loss: 19.9635 - val_mae: 2.7754\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0305 - mae: 2.2884 - val_loss: 19.8370 - val_mae: 2.7612\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9691 - mae: 2.2764 - val_loss: 19.8566 - val_mae: 2.7638\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.9405 - mae: 2.2679 - val_loss: 19.9534 - val_mae: 2.7813\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8268 - mae: 2.2526 - val_loss: 19.8753 - val_mae: 2.7734\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8230 - mae: 2.2573 - val_loss: 19.7708 - val_mae: 2.7633\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.7501 - mae: 2.2557 - val_loss: 19.8730 - val_mae: 2.8009\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6758 - mae: 2.2421 - val_loss: 19.9151 - val_mae: 2.7987\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.6680 - mae: 2.2342 - val_loss: 19.7661 - val_mae: 2.7615\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.5283 - mae: 2.2192 - val_loss: 19.8496 - val_mae: 2.7852\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.5411 - mae: 2.2149 - val_loss: 19.7360 - val_mae: 2.7499\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.4224 - mae: 2.1977 - val_loss: 19.7364 - val_mae: 2.7572\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3542 - mae: 2.1933 - val_loss: 19.7225 - val_mae: 2.7731\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3150 - mae: 2.1959 - val_loss: 19.6475 - val_mae: 2.7718\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.2649 - mae: 2.1822 - val_loss: 19.7319 - val_mae: 2.7670\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2293 - mae: 2.1667 - val_loss: 19.6712 - val_mae: 2.7559\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.2535 - mae: 2.1643 - val_loss: 19.7493 - val_mae: 2.7679\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1262 - mae: 2.1621 - val_loss: 19.6675 - val_mae: 2.7828\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1312 - mae: 2.1804 - val_loss: 19.6972 - val_mae: 2.7820\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0190 - mae: 2.1544 - val_loss: 19.6181 - val_mae: 2.7581\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.9936 - mae: 2.1381 - val_loss: 19.5940 - val_mae: 2.7438\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9557 - mae: 2.1249 - val_loss: 19.6334 - val_mae: 2.7495\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.8942 - mae: 2.1233 - val_loss: 19.4838 - val_mae: 2.7350\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.8436 - mae: 2.1229 - val_loss: 19.4993 - val_mae: 2.7460\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.8063 - mae: 2.1206 - val_loss: 19.4013 - val_mae: 2.7370\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7465 - mae: 2.1028 - val_loss: 19.4879 - val_mae: 2.7425\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.8414 - mae: 2.1168 - val_loss: 19.5369 - val_mae: 2.7650\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6837 - mae: 2.1069 - val_loss: 19.2591 - val_mae: 2.7318\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7307 - mae: 2.1016 - val_loss: 19.2490 - val_mae: 2.7150\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6372 - mae: 2.0785 - val_loss: 19.5797 - val_mae: 2.7566\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.5882 - mae: 2.0817 - val_loss: 19.4909 - val_mae: 2.7541\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5358 - mae: 2.0878 - val_loss: 19.3429 - val_mae: 2.7489\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.4875 - mae: 2.0804 - val_loss: 19.3451 - val_mae: 2.7453\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.4700 - mae: 2.0720 - val_loss: 19.4312 - val_mae: 2.7552\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.4402 - mae: 2.0657 - val_loss: 19.5937 - val_mae: 2.7677\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 8.3695 - mae: 2.0515 - val_loss: 19.3994 - val_mae: 2.7291\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.3185 - mae: 2.0425 - val_loss: 19.3527 - val_mae: 2.7207\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.3194 - mae: 2.0504 - val_loss: 19.2825 - val_mae: 2.7182\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.3243 - mae: 2.0504 - val_loss: 19.3401 - val_mae: 2.7317\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2066 - mae: 2.0308 - val_loss: 19.3083 - val_mae: 2.7362\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.1947 - mae: 2.0373 - val_loss: 19.3718 - val_mae: 2.7447\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.1283 - mae: 2.0310 - val_loss: 19.4326 - val_mae: 2.7495\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.1747 - mae: 2.0438 - val_loss: 19.4383 - val_mae: 2.7598\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.0549 - mae: 2.0297 - val_loss: 19.2588 - val_mae: 2.7208\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.0223 - mae: 2.0104 - val_loss: 19.2455 - val_mae: 2.7080\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.0343 - mae: 1.9948 - val_loss: 19.4458 - val_mae: 2.7389\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.0013 - mae: 1.9958 - val_loss: 19.3281 - val_mae: 2.7374\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.9830 - mae: 2.0144 - val_loss: 19.1882 - val_mae: 2.7172\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.9120 - mae: 1.9979 - val_loss: 19.1770 - val_mae: 2.7187\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.8907 - mae: 1.9861 - val_loss: 19.1830 - val_mae: 2.7187\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.8275 - mae: 1.9728 - val_loss: 19.2444 - val_mae: 2.7243\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.8499 - mae: 1.9876 - val_loss: 19.2356 - val_mae: 2.7352\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.7636 - mae: 1.9786 - val_loss: 19.2604 - val_mae: 2.7328\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.7822 - mae: 1.9589 - val_loss: 19.1746 - val_mae: 2.7082\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6905 - mae: 1.9536 - val_loss: 19.0774 - val_mae: 2.7228\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.7135 - mae: 1.9827 - val_loss: 19.0845 - val_mae: 2.7358\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6233 - mae: 1.9485 - val_loss: 19.0253 - val_mae: 2.7102\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.7103 - mae: 1.9321 - val_loss: 19.1165 - val_mae: 2.7004\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.6101 - mae: 1.9312 - val_loss: 19.0581 - val_mae: 2.7285\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.6309 - mae: 1.9787 - val_loss: 19.0053 - val_mae: 2.7241\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.5493 - mae: 1.9649 - val_loss: 19.0650 - val_mae: 2.7078\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.6177 - mae: 1.9296 - val_loss: 19.0466 - val_mae: 2.6865\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.4530 - mae: 1.9238 - val_loss: 19.0250 - val_mae: 2.7249\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4506 - mae: 1.9475 - val_loss: 19.0347 - val_mae: 2.7257\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.4069 - mae: 1.9430 - val_loss: 19.1054 - val_mae: 2.7363\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3870 - mae: 1.9199 - val_loss: 18.9901 - val_mae: 2.7040\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3503 - mae: 1.9077 - val_loss: 18.9424 - val_mae: 2.7069\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2960 - mae: 1.9060 - val_loss: 18.9335 - val_mae: 2.7195\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4387 - mae: 1.9531 - val_loss: 19.1886 - val_mae: 2.7734\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2935 - mae: 1.9177 - val_loss: 18.9678 - val_mae: 2.7058\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2293 - mae: 1.8910 - val_loss: 18.8966 - val_mae: 2.6974\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1912 - mae: 1.8905 - val_loss: 18.9366 - val_mae: 2.7087\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1510 - mae: 1.8897 - val_loss: 18.9281 - val_mae: 2.7097\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1512 - mae: 1.8864 - val_loss: 18.9892 - val_mae: 2.7180\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1797 - mae: 1.8808 - val_loss: 18.8336 - val_mae: 2.6771\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.0850 - mae: 1.8773 - val_loss: 18.9260 - val_mae: 2.7147\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0358 - mae: 1.8640 - val_loss: 18.8352 - val_mae: 2.6970\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0416 - mae: 1.8718 - val_loss: 18.8480 - val_mae: 2.7102\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.9677 - mae: 1.8663 - val_loss: 18.8645 - val_mae: 2.7070\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9566 - mae: 1.8514 - val_loss: 18.8296 - val_mae: 2.6923\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8727 - mae: 1.8620 - val_loss: 18.9767 - val_mae: 2.7359\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9911 - mae: 1.9010 - val_loss: 19.0085 - val_mae: 2.7438\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.9903 - mae: 1.8853 - val_loss: 18.8532 - val_mae: 2.7092\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8263 - mae: 1.8412 - val_loss: 18.8435 - val_mae: 2.7065\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8583 - mae: 1.8394 - val_loss: 18.7902 - val_mae: 2.7187\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.7723 - mae: 1.8392 - val_loss: 18.5730 - val_mae: 2.6965\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7807 - mae: 1.8349 - val_loss: 18.5840 - val_mae: 2.6942\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7249 - mae: 1.8340 - val_loss: 18.7346 - val_mae: 2.7203\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6976 - mae: 1.8253 - val_loss: 18.6622 - val_mae: 2.6956\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6383 - mae: 1.8062 - val_loss: 18.5583 - val_mae: 2.6801\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.6491 - mae: 1.8080 - val_loss: 18.5756 - val_mae: 2.6880\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7352 - mae: 1.8479 - val_loss: 18.7858 - val_mae: 2.7360\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7843 - mae: 1.8538 - val_loss: 18.4900 - val_mae: 2.6729\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5333 - mae: 1.8006 - val_loss: 18.7253 - val_mae: 2.7041\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5505 - mae: 1.8002 - val_loss: 18.7088 - val_mae: 2.7068\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4905 - mae: 1.8049 - val_loss: 18.6159 - val_mae: 2.6920\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.5152 - mae: 1.8238 - val_loss: 18.6390 - val_mae: 2.7090\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.4675 - mae: 1.8006 - val_loss: 18.4006 - val_mae: 2.6650\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3995 - mae: 1.7803 - val_loss: 18.5251 - val_mae: 2.6993\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.3740 - mae: 1.7853 - val_loss: 18.5309 - val_mae: 2.7090\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3433 - mae: 1.7843 - val_loss: 18.4263 - val_mae: 2.6739\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3186 - mae: 1.7727 - val_loss: 18.3488 - val_mae: 2.6654\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.2911 - mae: 1.7616 - val_loss: 18.4604 - val_mae: 2.6888\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.2953 - mae: 1.7524 - val_loss: 18.4957 - val_mae: 2.6955\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2740 - mae: 1.7655 - val_loss: 18.3772 - val_mae: 2.6678\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.2033 - mae: 1.7505 - val_loss: 18.4348 - val_mae: 2.6815\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1974 - mae: 1.7434 - val_loss: 18.4323 - val_mae: 2.6830\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1421 - mae: 1.7377 - val_loss: 18.3361 - val_mae: 2.6720\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1213 - mae: 1.7276 - val_loss: 18.4086 - val_mae: 2.6941\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1111 - mae: 1.7444 - val_loss: 18.3674 - val_mae: 2.6826\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0691 - mae: 1.7302 - val_loss: 18.3147 - val_mae: 2.6702\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0370 - mae: 1.7166 - val_loss: 18.3805 - val_mae: 2.6837\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0005 - mae: 1.7049 - val_loss: 18.5092 - val_mae: 2.6959\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9853 - mae: 1.7006 - val_loss: 18.4406 - val_mae: 2.6884\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9960 - mae: 1.7231 - val_loss: 18.3863 - val_mae: 2.6848\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9321 - mae: 1.7096 - val_loss: 18.3449 - val_mae: 2.6716\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9643 - mae: 1.6911 - val_loss: 18.3207 - val_mae: 2.6572\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8668 - mae: 1.6847 - val_loss: 18.4594 - val_mae: 2.7008\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8700 - mae: 1.6957 - val_loss: 18.2565 - val_mae: 2.6815\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8290 - mae: 1.6750 - val_loss: 18.3120 - val_mae: 2.6796\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8165 - mae: 1.6706 - val_loss: 18.2227 - val_mae: 2.6564\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7431 - mae: 1.6636 - val_loss: 18.3873 - val_mae: 2.7054\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7410 - mae: 1.6622 - val_loss: 18.2116 - val_mae: 2.6596\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6759 - mae: 1.6661 - val_loss: 18.2439 - val_mae: 2.6663\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7192 - mae: 1.6603 - val_loss: 18.2486 - val_mae: 2.6827\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6300 - mae: 1.6481 - val_loss: 18.2918 - val_mae: 2.6829\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6651 - mae: 1.6640 - val_loss: 18.3035 - val_mae: 2.6614\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6171 - mae: 1.6452 - val_loss: 18.3690 - val_mae: 2.6898\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.5836 - mae: 1.6356 - val_loss: 18.2017 - val_mae: 2.6600\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5307 - mae: 1.6292 - val_loss: 18.2115 - val_mae: 2.6685\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5032 - mae: 1.6205 - val_loss: 18.1839 - val_mae: 2.6532\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5005 - mae: 1.6310 - val_loss: 18.2935 - val_mae: 2.6877\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4856 - mae: 1.6414 - val_loss: 18.1453 - val_mae: 2.6703\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.4384 - mae: 1.6041 - val_loss: 18.1575 - val_mae: 2.6534\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.4247 - mae: 1.6069 - val_loss: 18.1188 - val_mae: 2.6589\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.3982 - mae: 1.6136 - val_loss: 18.1609 - val_mae: 2.6671\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.4289 - mae: 1.6178 - val_loss: 18.0383 - val_mae: 2.6506\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3215 - mae: 1.5984 - val_loss: 18.0407 - val_mae: 2.6663\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.3508 - mae: 1.5891 - val_loss: 18.0095 - val_mae: 2.6458\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.3152 - mae: 1.5959 - val_loss: 17.9966 - val_mae: 2.6530\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.3076 - mae: 1.6130 - val_loss: 17.9548 - val_mae: 2.6457\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.2907 - mae: 1.5981 - val_loss: 18.3231 - val_mae: 2.7031\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.2742 - mae: 1.5744 - val_loss: 17.9487 - val_mae: 2.6324\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.1872 - mae: 1.5790 - val_loss: 17.9760 - val_mae: 2.6497\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.2698 - mae: 1.5982 - val_loss: 18.0617 - val_mae: 2.6688\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.1601 - mae: 1.5675 - val_loss: 17.8804 - val_mae: 2.6225\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.1253 - mae: 1.5604 - val_loss: 17.9418 - val_mae: 2.6447\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0952 - mae: 1.5652 - val_loss: 18.0277 - val_mae: 2.6618\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.1241 - mae: 1.5469 - val_loss: 17.9316 - val_mae: 2.6329\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0598 - mae: 1.5466 - val_loss: 18.0091 - val_mae: 2.6609\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.9967 - mae: 1.5524 - val_loss: 17.9423 - val_mae: 2.6543\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.0339 - mae: 1.5599 - val_loss: 17.8680 - val_mae: 2.6317\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0326 - mae: 1.5381 - val_loss: 17.8747 - val_mae: 2.6318\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9416 - mae: 1.5403 - val_loss: 18.0473 - val_mae: 2.6902\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9530 - mae: 1.5480 - val_loss: 18.0798 - val_mae: 2.6819\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9485 - mae: 1.5290 - val_loss: 17.9724 - val_mae: 2.6449\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8796 - mae: 1.5259 - val_loss: 17.7166 - val_mae: 2.6112\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9084 - mae: 1.5327 - val_loss: 17.6750 - val_mae: 2.6174\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.8778 - mae: 1.5183 - val_loss: 17.7536 - val_mae: 2.6407\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9059 - mae: 1.5110 - val_loss: 17.7218 - val_mae: 2.6254\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8688 - mae: 1.5231 - val_loss: 17.8617 - val_mae: 2.6657\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8547 - mae: 1.5240 - val_loss: 17.6788 - val_mae: 2.6121\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7732 - mae: 1.4989 - val_loss: 17.9210 - val_mae: 2.6624\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7942 - mae: 1.4908 - val_loss: 17.7872 - val_mae: 2.6325\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7465 - mae: 1.5071 - val_loss: 17.8018 - val_mae: 2.6390\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7325 - mae: 1.5060 - val_loss: 17.6496 - val_mae: 2.6099\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6956 - mae: 1.4791 - val_loss: 17.7597 - val_mae: 2.6396\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6657 - mae: 1.4990 - val_loss: 17.7908 - val_mae: 2.6532\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6455 - mae: 1.4910 - val_loss: 17.6249 - val_mae: 2.6251\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.6130 - mae: 1.4810 - val_loss: 17.6340 - val_mae: 2.6293\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.6410 - mae: 1.4822 - val_loss: 17.6919 - val_mae: 2.6393\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6902 - mae: 1.4833 - val_loss: 17.8203 - val_mae: 2.6655\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5282 - mae: 1.4520 - val_loss: 17.5476 - val_mae: 2.6087\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.6217 - mae: 1.4850 - val_loss: 17.4997 - val_mae: 2.6193\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5732 - mae: 1.4491 - val_loss: 17.6213 - val_mae: 2.6410\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5595 - mae: 1.4751 - val_loss: 17.5852 - val_mae: 2.6293\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4803 - mae: 1.4636 - val_loss: 17.6265 - val_mae: 2.6353\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4594 - mae: 1.4307 - val_loss: 17.5372 - val_mae: 2.6178\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4701 - mae: 1.4459 - val_loss: 17.5097 - val_mae: 2.6326\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5520 - mae: 1.4856 - val_loss: 17.6705 - val_mae: 2.6715\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4262 - mae: 1.4605 - val_loss: 17.4735 - val_mae: 2.6111\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 4.5283 - mae: 1.4419 - val_loss: 17.4213 - val_mae: 2.6065\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.4565 - mae: 1.4494 - val_loss: 17.5495 - val_mae: 2.6574\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.3478 - mae: 1.4433 - val_loss: 17.3328 - val_mae: 2.6153\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.3517 - mae: 1.4143 - val_loss: 17.3721 - val_mae: 2.6196\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3580 - mae: 1.4385 - val_loss: 17.5352 - val_mae: 2.6484\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.3111 - mae: 1.4336 - val_loss: 17.3743 - val_mae: 2.6155\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.2805 - mae: 1.4204 - val_loss: 17.4160 - val_mae: 2.6346\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.2916 - mae: 1.4299 - val_loss: 17.4751 - val_mae: 2.6482\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 4.3135 - mae: 1.4051 - val_loss: 17.4136 - val_mae: 2.6334\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.2512 - mae: 1.4092 - val_loss: 17.6160 - val_mae: 2.6748\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.2686 - mae: 1.4147 - val_loss: 17.2973 - val_mae: 2.5994\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.1988 - mae: 1.3988 - val_loss: 17.3079 - val_mae: 2.6166\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.1973 - mae: 1.3940 - val_loss: 17.4297 - val_mae: 2.6560\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.1739 - mae: 1.3964 - val_loss: 17.2695 - val_mae: 2.6230\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.1061 - mae: 1.3827 - val_loss: 17.3116 - val_mae: 2.6381\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.1429 - mae: 1.3855 - val_loss: 17.2895 - val_mae: 2.6320\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.1498 - mae: 1.4084 - val_loss: 17.3512 - val_mae: 2.6563\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.0807 - mae: 1.3767 - val_loss: 17.1797 - val_mae: 2.6238\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.1276 - mae: 1.3776 - val_loss: 17.1053 - val_mae: 2.6165\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 4.1275 - mae: 1.3863 - val_loss: 17.4293 - val_mae: 2.6648\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.0449 - mae: 1.3604 - val_loss: 17.0675 - val_mae: 2.5985\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.0217 - mae: 1.3709 - val_loss: 16.9956 - val_mae: 2.6031\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 3.9947 - mae: 1.3570 - val_loss: 17.0855 - val_mae: 2.6290\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 3.9894 - mae: 1.3583 - val_loss: 17.1021 - val_mae: 2.6251\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.9928 - mae: 1.3563 - val_loss: 16.9752 - val_mae: 2.6094\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 3.9524 - mae: 1.3579 - val_loss: 17.1027 - val_mae: 2.6537\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 3.9842 - mae: 1.3704 - val_loss: 17.0105 - val_mae: 2.6157\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.9319 - mae: 1.3639 - val_loss: 16.8846 - val_mae: 2.6195\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.0068 - mae: 1.3509 - val_loss: 16.6789 - val_mae: 2.5892\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.8580 - mae: 1.3270 - val_loss: 16.9979 - val_mae: 2.6533\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.9428 - mae: 1.3700 - val_loss: 16.9402 - val_mae: 2.6241\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.9251 - mae: 1.3453 - val_loss: 16.6452 - val_mae: 2.5753\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.8747 - mae: 1.3548 - val_loss: 16.9441 - val_mae: 2.6461\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.8262 - mae: 1.3466 - val_loss: 16.7705 - val_mae: 2.6242\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.7838 - mae: 1.3128 - val_loss: 16.6661 - val_mae: 2.6202\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.8070 - mae: 1.3292 - val_loss: 16.6345 - val_mae: 2.6102\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.7718 - mae: 1.3262 - val_loss: 16.8023 - val_mae: 2.6508\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7655 - mae: 1.3401 - val_loss: 16.6666 - val_mae: 2.6096\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7386 - mae: 1.3140 - val_loss: 16.6863 - val_mae: 2.6274\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.7029 - mae: 1.3089 - val_loss: 16.4860 - val_mae: 2.6009\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.7132 - mae: 1.3034 - val_loss: 16.6076 - val_mae: 2.6151\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.7162 - mae: 1.3364 - val_loss: 16.6790 - val_mae: 2.6226\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.7117 - mae: 1.3157 - val_loss: 16.3230 - val_mae: 2.5834\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.6339 - mae: 2.0441\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 26ms/step - loss: 583.3568 - mae: 22.3447 - val_loss: 476.0932 - val_mae: 20.0587\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 550.3176 - mae: 21.5984 - val_loss: 445.7086 - val_mae: 19.2988\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 514.2521 - mae: 20.7637 - val_loss: 412.8394 - val_mae: 18.4511\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 475.9697 - mae: 19.8279 - val_loss: 375.7115 - val_mae: 17.4605\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 429.4129 - mae: 18.7306 - val_loss: 334.9418 - val_mae: 16.3097\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 379.8398 - mae: 17.4182 - val_loss: 287.9677 - val_mae: 14.9734\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 323.6078 - mae: 15.9084 - val_loss: 237.4420 - val_mae: 13.4519\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 260.9387 - mae: 14.1096 - val_loss: 185.9064 - val_mae: 11.7574\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 198.3940 - mae: 12.0453 - val_loss: 136.6664 - val_mae: 9.9158\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 144.4248 - mae: 9.9192 - val_loss: 94.8447 - val_mae: 8.1331\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 98.1926 - mae: 7.9127 - val_loss: 67.6972 - val_mae: 6.9120\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 70.4033 - mae: 6.4731 - val_loss: 53.0781 - val_mae: 6.0523\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 56.2286 - mae: 5.6434 - val_loss: 45.7323 - val_mae: 5.5777\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 48.7768 - mae: 5.1629 - val_loss: 39.5871 - val_mae: 5.1766\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 42.7041 - mae: 4.7725 - val_loss: 34.5685 - val_mae: 4.8033\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 37.9069 - mae: 4.4519 - val_loss: 30.7797 - val_mae: 4.4953\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 34.5235 - mae: 4.2054 - val_loss: 27.9779 - val_mae: 4.2578\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 31.9658 - mae: 4.0181 - val_loss: 26.0816 - val_mae: 4.1045\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 30.0931 - mae: 3.8833 - val_loss: 24.4682 - val_mae: 3.9640\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28.6996 - mae: 3.7671 - val_loss: 23.2812 - val_mae: 3.8544\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 27.5902 - mae: 3.6911 - val_loss: 22.4592 - val_mae: 3.7783\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26.4950 - mae: 3.6082 - val_loss: 21.6348 - val_mae: 3.6714\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 25.7524 - mae: 3.5360 - val_loss: 21.0420 - val_mae: 3.5933\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 25.0702 - mae: 3.4833 - val_loss: 20.6694 - val_mae: 3.5501\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 24.4836 - mae: 3.4500 - val_loss: 20.3256 - val_mae: 3.5203\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 23.9664 - mae: 3.3930 - val_loss: 19.9817 - val_mae: 3.4636\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 23.4410 - mae: 3.3510 - val_loss: 19.6697 - val_mae: 3.4247\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 22.9498 - mae: 3.3254 - val_loss: 19.5668 - val_mae: 3.4190\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 22.5255 - mae: 3.2958 - val_loss: 19.2664 - val_mae: 3.3737\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 22.0910 - mae: 3.2631 - val_loss: 19.0523 - val_mae: 3.3471\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 21.7831 - mae: 3.2546 - val_loss: 18.9596 - val_mae: 3.3480\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 21.3080 - mae: 3.2103 - val_loss: 18.4173 - val_mae: 3.2677\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 20.9035 - mae: 3.1694 - val_loss: 18.2557 - val_mae: 3.2449\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 20.5314 - mae: 3.1409 - val_loss: 18.0670 - val_mae: 3.2202\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 20.1902 - mae: 3.1265 - val_loss: 17.9741 - val_mae: 3.2095\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 19.8646 - mae: 3.0956 - val_loss: 17.8104 - val_mae: 3.1782\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 19.5785 - mae: 3.0739 - val_loss: 17.7045 - val_mae: 3.1660\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 19.3125 - mae: 3.0472 - val_loss: 17.3505 - val_mae: 3.1152\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 19.0150 - mae: 3.0239 - val_loss: 17.3091 - val_mae: 3.1149\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 18.6657 - mae: 3.0123 - val_loss: 17.3882 - val_mae: 3.1320\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 18.4712 - mae: 2.9979 - val_loss: 17.1614 - val_mae: 3.0957\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 18.2083 - mae: 2.9659 - val_loss: 16.8786 - val_mae: 3.0533\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 17.9649 - mae: 2.9457 - val_loss: 16.8650 - val_mae: 3.0552\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 17.6848 - mae: 2.9228 - val_loss: 16.5666 - val_mae: 3.0179\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 17.4677 - mae: 2.8924 - val_loss: 16.4414 - val_mae: 3.0057\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 17.2699 - mae: 2.8750 - val_loss: 16.4254 - val_mae: 3.0071\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 17.0751 - mae: 2.8660 - val_loss: 16.3590 - val_mae: 3.0098\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 16.8942 - mae: 2.8399 - val_loss: 16.0478 - val_mae: 2.9597\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 16.6091 - mae: 2.8207 - val_loss: 16.1230 - val_mae: 2.9826\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 16.3906 - mae: 2.8075 - val_loss: 15.8718 - val_mae: 2.9470\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 16.1894 - mae: 2.7924 - val_loss: 15.9176 - val_mae: 2.9613\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 16.0093 - mae: 2.7904 - val_loss: 15.9948 - val_mae: 2.9702\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.8223 - mae: 2.7769 - val_loss: 15.7672 - val_mae: 2.9182\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 15.7427 - mae: 2.7324 - val_loss: 15.4478 - val_mae: 2.8832\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 15.5531 - mae: 2.7288 - val_loss: 15.6951 - val_mae: 2.9131\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.3027 - mae: 2.7224 - val_loss: 15.5594 - val_mae: 2.8938\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.0918 - mae: 2.7145 - val_loss: 15.5058 - val_mae: 2.8929\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.9600 - mae: 2.6995 - val_loss: 15.3638 - val_mae: 2.8910\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.8530 - mae: 2.6879 - val_loss: 15.1236 - val_mae: 2.8661\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.7030 - mae: 2.6618 - val_loss: 14.9969 - val_mae: 2.8384\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.5880 - mae: 2.6456 - val_loss: 14.8279 - val_mae: 2.8255\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.3820 - mae: 2.6346 - val_loss: 14.9851 - val_mae: 2.8497\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.3365 - mae: 2.6682 - val_loss: 15.2826 - val_mae: 2.9031\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.2154 - mae: 2.6627 - val_loss: 14.9952 - val_mae: 2.8608\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.0117 - mae: 2.6294 - val_loss: 14.6989 - val_mae: 2.8250\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.8831 - mae: 2.6092 - val_loss: 14.6775 - val_mae: 2.8190\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.8011 - mae: 2.5956 - val_loss: 14.5613 - val_mae: 2.8067\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.6658 - mae: 2.5731 - val_loss: 14.4798 - val_mae: 2.7938\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.6429 - mae: 2.5713 - val_loss: 14.5796 - val_mae: 2.7952\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.4928 - mae: 2.5631 - val_loss: 14.5801 - val_mae: 2.8092\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.3614 - mae: 2.5633 - val_loss: 14.5124 - val_mae: 2.8133\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.2453 - mae: 2.5597 - val_loss: 14.6363 - val_mae: 2.8242\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1117 - mae: 2.5531 - val_loss: 14.5185 - val_mae: 2.8058\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.0664 - mae: 2.5398 - val_loss: 14.3014 - val_mae: 2.7745\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0275 - mae: 2.5204 - val_loss: 14.1877 - val_mae: 2.7710\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.8346 - mae: 2.5168 - val_loss: 14.2532 - val_mae: 2.7956\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.8557 - mae: 2.5087 - val_loss: 14.0189 - val_mae: 2.7589\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.6375 - mae: 2.4918 - val_loss: 14.2509 - val_mae: 2.7859\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.5914 - mae: 2.5121 - val_loss: 14.2699 - val_mae: 2.7954\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.4920 - mae: 2.4984 - val_loss: 14.2286 - val_mae: 2.7843\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.4180 - mae: 2.4875 - val_loss: 14.2269 - val_mae: 2.7710\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.3372 - mae: 2.4704 - val_loss: 13.9907 - val_mae: 2.7556\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.2584 - mae: 2.4551 - val_loss: 13.8811 - val_mae: 2.7386\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.1264 - mae: 2.4456 - val_loss: 13.9621 - val_mae: 2.7539\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.0513 - mae: 2.4475 - val_loss: 14.0039 - val_mae: 2.7605\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.9795 - mae: 2.4481 - val_loss: 14.1319 - val_mae: 2.7799\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.9076 - mae: 2.4471 - val_loss: 13.9746 - val_mae: 2.7648\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.8535 - mae: 2.4445 - val_loss: 13.9671 - val_mae: 2.7691\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.7978 - mae: 2.4282 - val_loss: 13.8888 - val_mae: 2.7455\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.7172 - mae: 2.4133 - val_loss: 13.8853 - val_mae: 2.7270\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.6903 - mae: 2.3973 - val_loss: 13.6800 - val_mae: 2.7233\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.5400 - mae: 2.3915 - val_loss: 13.8649 - val_mae: 2.7602\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 11.5442 - mae: 2.4108 - val_loss: 13.9260 - val_mae: 2.7746\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.3825 - mae: 2.3920 - val_loss: 13.9542 - val_mae: 2.7518\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.3654 - mae: 2.3815 - val_loss: 13.8439 - val_mae: 2.7272\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 11.2716 - mae: 2.3712 - val_loss: 13.8842 - val_mae: 2.7433\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.3910 - mae: 2.4063 - val_loss: 14.1641 - val_mae: 2.7894\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 11.1905 - mae: 2.3694 - val_loss: 13.5004 - val_mae: 2.7011\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.0709 - mae: 2.3446 - val_loss: 13.5830 - val_mae: 2.7176\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.0092 - mae: 2.3590 - val_loss: 13.8108 - val_mae: 2.7429\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.9216 - mae: 2.3602 - val_loss: 13.5846 - val_mae: 2.7214\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.8652 - mae: 2.3508 - val_loss: 13.6169 - val_mae: 2.7206\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.8280 - mae: 2.3397 - val_loss: 13.4082 - val_mae: 2.6919\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.7405 - mae: 2.3355 - val_loss: 13.5789 - val_mae: 2.7173\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.6843 - mae: 2.3363 - val_loss: 13.4097 - val_mae: 2.7168\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.6459 - mae: 2.3352 - val_loss: 13.4351 - val_mae: 2.7100\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.6270 - mae: 2.3146 - val_loss: 13.1477 - val_mae: 2.6738\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.4991 - mae: 2.3006 - val_loss: 13.3408 - val_mae: 2.6886\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 10.6996 - mae: 2.3419 - val_loss: 13.7225 - val_mae: 2.7312\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.4296 - mae: 2.3140 - val_loss: 13.1949 - val_mae: 2.6866\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.3523 - mae: 2.2988 - val_loss: 13.2977 - val_mae: 2.6898\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.2988 - mae: 2.2878 - val_loss: 13.0760 - val_mae: 2.6623\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.2730 - mae: 2.2671 - val_loss: 13.0434 - val_mae: 2.6345\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.2306 - mae: 2.2693 - val_loss: 13.1403 - val_mae: 2.6737\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.1616 - mae: 2.2801 - val_loss: 13.0179 - val_mae: 2.6687\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 10.0793 - mae: 2.2590 - val_loss: 12.9556 - val_mae: 2.6428\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.0565 - mae: 2.2689 - val_loss: 13.2416 - val_mae: 2.6865\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.9794 - mae: 2.2689 - val_loss: 13.0396 - val_mae: 2.6583\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.9498 - mae: 2.2544 - val_loss: 12.8660 - val_mae: 2.6457\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.9518 - mae: 2.2389 - val_loss: 12.9094 - val_mae: 2.6241\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.8318 - mae: 2.2416 - val_loss: 12.9953 - val_mae: 2.6581\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.8065 - mae: 2.2447 - val_loss: 12.8028 - val_mae: 2.6398\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.7199 - mae: 2.2343 - val_loss: 12.9160 - val_mae: 2.6364\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7160 - mae: 2.2334 - val_loss: 12.8232 - val_mae: 2.6217\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.7222 - mae: 2.2206 - val_loss: 12.6547 - val_mae: 2.6169\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.6270 - mae: 2.2001 - val_loss: 12.5762 - val_mae: 2.5900\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.6434 - mae: 2.2171 - val_loss: 12.8978 - val_mae: 2.6363\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.5680 - mae: 2.2222 - val_loss: 12.7454 - val_mae: 2.6178\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.4945 - mae: 2.2042 - val_loss: 12.3893 - val_mae: 2.5930\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.4243 - mae: 2.1852 - val_loss: 12.3984 - val_mae: 2.5829\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 9.4007 - mae: 2.1857 - val_loss: 12.3688 - val_mae: 2.5768\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.3138 - mae: 2.1780 - val_loss: 12.5277 - val_mae: 2.5890\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.4169 - mae: 2.2000 - val_loss: 12.6575 - val_mae: 2.5943\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.2481 - mae: 2.1715 - val_loss: 12.4327 - val_mae: 2.5898\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.2221 - mae: 2.1700 - val_loss: 12.3725 - val_mae: 2.5725\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.1792 - mae: 2.1591 - val_loss: 12.4783 - val_mae: 2.5825\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.1467 - mae: 2.1699 - val_loss: 12.5655 - val_mae: 2.5985\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.1368 - mae: 2.1538 - val_loss: 12.2293 - val_mae: 2.5499\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.1675 - mae: 2.1340 - val_loss: 12.0301 - val_mae: 2.5286\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.0366 - mae: 2.1521 - val_loss: 12.3337 - val_mae: 2.5928\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.9899 - mae: 2.1503 - val_loss: 12.3152 - val_mae: 2.5593\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.9290 - mae: 2.1368 - val_loss: 12.1538 - val_mae: 2.5445\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.9609 - mae: 2.1545 - val_loss: 12.3135 - val_mae: 2.5874\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.8570 - mae: 2.1286 - val_loss: 12.0637 - val_mae: 2.5287\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.8147 - mae: 2.1071 - val_loss: 11.9566 - val_mae: 2.5110\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.7541 - mae: 2.1071 - val_loss: 12.0798 - val_mae: 2.5515\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7347 - mae: 2.1134 - val_loss: 11.9814 - val_mae: 2.5375\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.6876 - mae: 2.1110 - val_loss: 12.1910 - val_mae: 2.5476\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.6765 - mae: 2.1057 - val_loss: 11.9992 - val_mae: 2.5240\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.6509 - mae: 2.1111 - val_loss: 12.0538 - val_mae: 2.5457\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.6176 - mae: 2.0986 - val_loss: 12.1287 - val_mae: 2.5232\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.5203 - mae: 2.0948 - val_loss: 12.1467 - val_mae: 2.5523\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.5079 - mae: 2.0983 - val_loss: 11.9690 - val_mae: 2.5283\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.4960 - mae: 2.0893 - val_loss: 11.7629 - val_mae: 2.5053\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.4449 - mae: 2.0785 - val_loss: 11.8933 - val_mae: 2.5106\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.4111 - mae: 2.0766 - val_loss: 11.9735 - val_mae: 2.5089\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.3778 - mae: 2.0752 - val_loss: 12.0046 - val_mae: 2.5312\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.3690 - mae: 2.0864 - val_loss: 12.0590 - val_mae: 2.5374\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.3471 - mae: 2.0680 - val_loss: 11.6591 - val_mae: 2.4765\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.2192 - mae: 2.0541 - val_loss: 11.9145 - val_mae: 2.5053\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.2587 - mae: 2.0654 - val_loss: 11.9161 - val_mae: 2.5099\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.1836 - mae: 2.0517 - val_loss: 11.6865 - val_mae: 2.5009\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.2369 - mae: 2.0692 - val_loss: 11.9410 - val_mae: 2.5215\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.0665 - mae: 2.0472 - val_loss: 11.6940 - val_mae: 2.4892\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0420 - mae: 2.0394 - val_loss: 11.8135 - val_mae: 2.4923\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0151 - mae: 2.0411 - val_loss: 11.8882 - val_mae: 2.5069\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.9854 - mae: 2.0379 - val_loss: 11.6927 - val_mae: 2.4678\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.9315 - mae: 2.0225 - val_loss: 11.7212 - val_mae: 2.4714\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8913 - mae: 2.0211 - val_loss: 11.8894 - val_mae: 2.5031\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.8679 - mae: 2.0191 - val_loss: 11.8758 - val_mae: 2.4814\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.8604 - mae: 2.0031 - val_loss: 11.7492 - val_mae: 2.4518\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.7520 - mae: 1.9961 - val_loss: 11.9064 - val_mae: 2.4965\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.7701 - mae: 2.0176 - val_loss: 11.9820 - val_mae: 2.5116\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7261 - mae: 2.0066 - val_loss: 11.7431 - val_mae: 2.4697\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6622 - mae: 2.0001 - val_loss: 11.7710 - val_mae: 2.4776\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.6397 - mae: 1.9860 - val_loss: 11.6401 - val_mae: 2.4446\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.6400 - mae: 1.9910 - val_loss: 11.7519 - val_mae: 2.4807\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.5169 - mae: 1.9786 - val_loss: 11.6669 - val_mae: 2.4449\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.5415 - mae: 1.9760 - val_loss: 11.7215 - val_mae: 2.4629\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.4985 - mae: 1.9811 - val_loss: 11.5493 - val_mae: 2.4322\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.4310 - mae: 1.9617 - val_loss: 11.6010 - val_mae: 2.4374\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.4083 - mae: 1.9546 - val_loss: 11.7190 - val_mae: 2.4433\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.3758 - mae: 1.9578 - val_loss: 11.7715 - val_mae: 2.4854\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.3523 - mae: 1.9732 - val_loss: 11.8026 - val_mae: 2.4751\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.3554 - mae: 1.9709 - val_loss: 11.9088 - val_mae: 2.4524\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3602 - mae: 1.9557 - val_loss: 11.3533 - val_mae: 2.3996\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2711 - mae: 1.9458 - val_loss: 11.7147 - val_mae: 2.4620\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2387 - mae: 1.9605 - val_loss: 11.9216 - val_mae: 2.4779\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1379 - mae: 1.9294 - val_loss: 11.7248 - val_mae: 2.4286\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2942 - mae: 1.9522 - val_loss: 12.0442 - val_mae: 2.4734\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0628 - mae: 1.9287 - val_loss: 11.7257 - val_mae: 2.4491\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1465 - mae: 1.9326 - val_loss: 11.4537 - val_mae: 2.4094\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.0744 - mae: 1.9277 - val_loss: 11.8280 - val_mae: 2.4423\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9870 - mae: 1.9230 - val_loss: 11.6458 - val_mae: 2.4454\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0029 - mae: 1.9089 - val_loss: 11.4748 - val_mae: 2.4038\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.9754 - mae: 1.9066 - val_loss: 11.7927 - val_mae: 2.4545\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9092 - mae: 1.8986 - val_loss: 11.5936 - val_mae: 2.4322\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9118 - mae: 1.8966 - val_loss: 11.4373 - val_mae: 2.4059\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8339 - mae: 1.9033 - val_loss: 11.9812 - val_mae: 2.4620\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8592 - mae: 1.9011 - val_loss: 11.6358 - val_mae: 2.4169\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8127 - mae: 1.9017 - val_loss: 12.2037 - val_mae: 2.4967\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7855 - mae: 1.9006 - val_loss: 11.8313 - val_mae: 2.4298\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6738 - mae: 1.8773 - val_loss: 11.6111 - val_mae: 2.4069\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7009 - mae: 1.8697 - val_loss: 11.6612 - val_mae: 2.4134\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6311 - mae: 1.8729 - val_loss: 11.6972 - val_mae: 2.4313\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5839 - mae: 1.8616 - val_loss: 11.6741 - val_mae: 2.4220\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6812 - mae: 1.8771 - val_loss: 11.8643 - val_mae: 2.4522\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5633 - mae: 1.8528 - val_loss: 11.6051 - val_mae: 2.3963\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5485 - mae: 1.8473 - val_loss: 11.4794 - val_mae: 2.3743\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4700 - mae: 1.8666 - val_loss: 12.0264 - val_mae: 2.4755\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5986 - mae: 1.8856 - val_loss: 12.1383 - val_mae: 2.4636\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4687 - mae: 1.8497 - val_loss: 11.7148 - val_mae: 2.4054\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3899 - mae: 1.8389 - val_loss: 11.9290 - val_mae: 2.4371\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4855 - mae: 1.8523 - val_loss: 11.6845 - val_mae: 2.4072\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2835 - mae: 1.8213 - val_loss: 12.0071 - val_mae: 2.4355\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3178 - mae: 1.8342 - val_loss: 12.0546 - val_mae: 2.4605\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2438 - mae: 1.8371 - val_loss: 11.7358 - val_mae: 2.4164\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.2348 - mae: 1.8297 - val_loss: 11.4874 - val_mae: 2.3659\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4154 - mae: 1.8256 - val_loss: 11.4536 - val_mae: 2.3768\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2905 - mae: 1.8365 - val_loss: 12.1767 - val_mae: 2.4661\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1697 - mae: 1.8172 - val_loss: 11.7288 - val_mae: 2.3960\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0744 - mae: 1.7868 - val_loss: 11.6913 - val_mae: 2.3898\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0917 - mae: 1.7944 - val_loss: 11.6866 - val_mae: 2.3916\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0096 - mae: 1.7945 - val_loss: 12.0588 - val_mae: 2.4314\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0273 - mae: 1.8000 - val_loss: 11.8497 - val_mae: 2.4120\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0492 - mae: 1.7879 - val_loss: 11.6154 - val_mae: 2.3670\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9499 - mae: 1.7797 - val_loss: 11.8738 - val_mae: 2.4290\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9077 - mae: 1.7792 - val_loss: 11.6928 - val_mae: 2.3890\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.8896 - mae: 1.7679 - val_loss: 11.7021 - val_mae: 2.3891\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9467 - mae: 1.7850 - val_loss: 11.6942 - val_mae: 2.4121\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9540 - mae: 1.7720 - val_loss: 11.7027 - val_mae: 2.3697\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7803 - mae: 1.7515 - val_loss: 11.6274 - val_mae: 2.3943\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.8340 - mae: 1.7589 - val_loss: 11.7624 - val_mae: 2.3819\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.7649 - mae: 1.7557 - val_loss: 11.8222 - val_mae: 2.4203\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5.7218 - mae: 1.7557 - val_loss: 11.7545 - val_mae: 2.3863\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7488 - mae: 1.7403 - val_loss: 11.5061 - val_mae: 2.3645\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.7258 - mae: 1.7624 - val_loss: 11.4765 - val_mae: 2.3706\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7284 - mae: 1.7482 - val_loss: 11.7438 - val_mae: 2.3868\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5.7558 - mae: 1.7518 - val_loss: 11.6909 - val_mae: 2.3917\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.6565 - mae: 1.7426 - val_loss: 11.7922 - val_mae: 2.3853\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.5676 - mae: 1.7212 - val_loss: 11.8858 - val_mae: 2.4156\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.5978 - mae: 1.7438 - val_loss: 12.0803 - val_mae: 2.4300\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.5622 - mae: 1.7216 - val_loss: 11.6561 - val_mae: 2.3584\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.4801 - mae: 1.6960 - val_loss: 11.8869 - val_mae: 2.3858\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 5.4505 - mae: 1.7022 - val_loss: 11.7652 - val_mae: 2.3839\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.4203 - mae: 1.7053 - val_loss: 11.7638 - val_mae: 2.3906\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.4662 - mae: 1.6839 - val_loss: 11.5285 - val_mae: 2.3523\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.3906 - mae: 1.6887 - val_loss: 11.6079 - val_mae: 2.3806\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5.3539 - mae: 1.6975 - val_loss: 11.6905 - val_mae: 2.3796\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.3658 - mae: 1.6805 - val_loss: 11.4602 - val_mae: 2.3531\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.3427 - mae: 1.6767 - val_loss: 11.8241 - val_mae: 2.3933\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5.3787 - mae: 1.7035 - val_loss: 11.5878 - val_mae: 2.3939\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.2811 - mae: 1.6818 - val_loss: 11.6687 - val_mae: 2.3700\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.2641 - mae: 1.6654 - val_loss: 11.4923 - val_mae: 2.3602\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.1973 - mae: 1.6620 - val_loss: 11.7772 - val_mae: 2.3866\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 5.1750 - mae: 1.6451 - val_loss: 11.6749 - val_mae: 2.3765\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.1936 - mae: 1.6556 - val_loss: 11.7102 - val_mae: 2.3866\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 5.1824 - mae: 1.6449 - val_loss: 11.4265 - val_mae: 2.3424\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.1710 - mae: 1.6519 - val_loss: 11.6710 - val_mae: 2.3887\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5.0817 - mae: 1.6491 - val_loss: 11.5346 - val_mae: 2.3562\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 5.1032 - mae: 1.6319 - val_loss: 11.6114 - val_mae: 2.3616\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0932 - mae: 1.6194 - val_loss: 11.3548 - val_mae: 2.3388\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.0980 - mae: 1.6450 - val_loss: 11.5943 - val_mae: 2.3829\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 5.0076 - mae: 1.6256 - val_loss: 11.3808 - val_mae: 2.3417\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.9940 - mae: 1.6119 - val_loss: 11.4603 - val_mae: 2.3593\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.9119 - mae: 1.6023 - val_loss: 11.6572 - val_mae: 2.3731\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9675 - mae: 1.6035 - val_loss: 11.6263 - val_mae: 2.3698\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8904 - mae: 1.6032 - val_loss: 11.5450 - val_mae: 2.3720\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.8773 - mae: 1.5996 - val_loss: 11.6085 - val_mae: 2.3562\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8717 - mae: 1.5920 - val_loss: 11.6149 - val_mae: 2.3704\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9264 - mae: 1.5900 - val_loss: 11.4116 - val_mae: 2.3501\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9069 - mae: 1.6095 - val_loss: 11.7076 - val_mae: 2.3993\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8581 - mae: 1.6010 - val_loss: 11.4346 - val_mae: 2.3471\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7996 - mae: 1.5710 - val_loss: 11.8130 - val_mae: 2.3801\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7399 - mae: 1.5701 - val_loss: 11.8073 - val_mae: 2.3966\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.7800 - mae: 1.5790 - val_loss: 11.5539 - val_mae: 2.3590\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6884 - mae: 1.5495 - val_loss: 11.6645 - val_mae: 2.3620\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.6487 - mae: 1.5387 - val_loss: 11.6399 - val_mae: 2.3634\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.6731 - mae: 1.5520 - val_loss: 11.6060 - val_mae: 2.3706\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7528 - mae: 1.5668 - val_loss: 11.8046 - val_mae: 2.4009\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.6215 - mae: 1.5462 - val_loss: 11.4371 - val_mae: 2.3477\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.6324 - mae: 1.5241 - val_loss: 11.5240 - val_mae: 2.3406\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5887 - mae: 1.5310 - val_loss: 11.7068 - val_mae: 2.3843\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.5751 - mae: 1.5307 - val_loss: 11.5278 - val_mae: 2.3605\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4974 - mae: 1.5323 - val_loss: 11.5981 - val_mae: 2.3650\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5638 - mae: 1.5490 - val_loss: 11.6016 - val_mae: 2.3678\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5293 - mae: 1.5114 - val_loss: 11.2931 - val_mae: 2.3063\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4577 - mae: 1.5027 - val_loss: 11.8693 - val_mae: 2.4086\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4760 - mae: 1.5369 - val_loss: 11.7316 - val_mae: 2.3757\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4405 - mae: 1.4930 - val_loss: 11.4589 - val_mae: 2.3361\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3632 - mae: 1.4842 - val_loss: 11.6466 - val_mae: 2.3715\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3667 - mae: 1.4904 - val_loss: 11.6858 - val_mae: 2.3730\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3419 - mae: 1.4891 - val_loss: 11.5858 - val_mae: 2.3642\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.3453 - mae: 1.4781 - val_loss: 11.5857 - val_mae: 2.3467\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3049 - mae: 1.4824 - val_loss: 11.5050 - val_mae: 2.3564\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2799 - mae: 1.4839 - val_loss: 11.2925 - val_mae: 2.3330\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2505 - mae: 1.4689 - val_loss: 11.4569 - val_mae: 2.3542\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.2192 - mae: 1.4635 - val_loss: 11.4589 - val_mae: 2.3370\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1827 - mae: 1.4492 - val_loss: 11.6867 - val_mae: 2.3723\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3678 - mae: 1.5053 - val_loss: 11.7605 - val_mae: 2.3937\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 9.1705 - mae: 2.1605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d9pwSgxR_zK",
        "outputId": "7186a751-0d64-4a92-bfa6-f560b875f8ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.06453537940979, 2.0441367626190186, 2.1604652404785156]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### k-fold 사용한 모델 성능평가"
      ],
      "metadata": {
        "id": "ZjEuQNuiSDk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'전체 결과: {mae_list}')\n",
        "print(f'평균낸 결과를 최종 결과로 사용합니다: {np.mean(mae_list)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfVwssrU9FlW",
        "outputId": "ed08d12f-c483-4fcc-826d-294c580804ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 결과: [2.06453537940979, 2.0441367626190186, 2.1604652404785156]\n",
            "평균낸 결과를 최종 결과로 사용합니다: 2.089712460835775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mae_list) #2.08 -> 실제 집값하고 2000달러 차이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JExoPJIW9Fiw",
        "outputId": "47419f0e-3f7a-49f5-9472-76981d61a89c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.089712460835775"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검증 데이터셋 사용하지 않고 학습한 모델 성능 평가"
      ],
      "metadata": {
        "id": "qoQVh0-WSdNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data                           # no tensorflow\n",
        "\n",
        "# 데이터를 다운받습니다.(훈련셋 80%, 테스트셋 20%)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2,\n",
        "                                                 seed=777)"
      ],
      "metadata": {
        "id": "gjw3zhg49Ffo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 데이터 표준화\n",
        "mean = np.mean(X_train, axis = 0)\n",
        "std = np.std(X_train, axis = 0)\n",
        "# 여기까진 전부 동일합니다.\n",
        "x_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std"
      ],
      "metadata": {
        "id": "l9kL0HICSjk7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# 3-fold 로 나눠서 검증데이터셋 사용하여 학습\n",
        "k =3\n",
        "\n",
        "kfold = KFold(n_splits=k)\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation='relu', input_shape=(13,)))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(1))   # activation = linear\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "  model.fit(X_train,y_train,epochs=300)\n",
        "\n",
        "  model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "rmQdk85y9FdG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMcYWASx9Faf",
        "outputId": "4b8abe6c-4c57-405e-a879-96176bc30b9f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 9.1705 - mae: 2.1605\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.17051887512207, 2.1604652404785156]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 교수님이 하라는거\n"
      ],
      "metadata": {
        "id": "WfCARdWFTtJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data                           # no tensorflow\n",
        "\n",
        "# 데이터를 다운받습니다.(훈련셋 80%, 테스트셋 20%)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2,\n",
        "                                                 seed=777)"
      ],
      "metadata": {
        "id": "oxmA9DtH9FXX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 데이터 표준화\n",
        "mean = np.mean(X_train, axis = 0)\n",
        "std = np.std(X_train, axis = 0)\n",
        "# 여기까진 전부 동일합니다.\n",
        "x_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std"
      ],
      "metadata": {
        "id": "EePQVPQ79FUy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# 3-fold 로 나눠서 검증데이터셋 사용하여 학습\n",
        "k =4\n",
        "\n",
        "kfold = KFold(n_splits=k)\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation='relu', input_shape=(13,)))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(1))   # activation = linear\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 각 모델의 평가 정보 담는 리스트 선언\n",
        "mae_list = []\n",
        "\n",
        "# k번 학습 및 평가\n",
        "# k번 진행합니다.\n",
        "for train_index, val_index in kfold.split(x_train):\n",
        "    # 해당 인덱스는 무작위로 생성됩니다.\n",
        "    # 무작위로 생성해주는 것은 과대적합을 피할 수 있는 좋은 방법입니다.\n",
        "    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBntBxMx9FR6",
        "outputId": "e09dc15d-7e96-4247-9749-0905f1c33c17"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "10/10 [==============================] - 2s 106ms/step - loss: 585.0000 - mae: 22.2740 - val_loss: 548.1459 - val_mae: 21.6711\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 559.1180 - mae: 21.7086 - val_loss: 526.9958 - val_mae: 21.1697\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 532.6047 - mae: 21.0961 - val_loss: 503.1765 - val_mae: 20.5854\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 502.1030 - mae: 20.3722 - val_loss: 473.8099 - val_mae: 19.8523\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 464.8607 - mae: 19.4715 - val_loss: 436.6185 - val_mae: 18.9240\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 417.8430 - mae: 18.2960 - val_loss: 390.8489 - val_mae: 17.7323\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 360.8412 - mae: 16.8446 - val_loss: 336.5778 - val_mae: 16.2184\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 297.7617 - mae: 15.0895 - val_loss: 274.3409 - val_mae: 14.3876\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 230.6427 - mae: 13.0105 - val_loss: 211.9787 - val_mae: 12.3726\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 168.3609 - mae: 10.8017 - val_loss: 158.3742 - val_mae: 10.4294\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 125.4166 - mae: 9.0984 - val_loss: 116.5979 - val_mae: 8.7933\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 94.3953 - mae: 7.7836 - val_loss: 90.6242 - val_mae: 7.6567\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 76.9039 - mae: 6.9231 - val_loss: 74.2659 - val_mae: 6.8548\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 65.5993 - mae: 6.3483 - val_loss: 61.7963 - val_mae: 6.1570\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 55.5683 - mae: 5.7961 - val_loss: 52.6108 - val_mae: 5.5461\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 48.0719 - mae: 5.3573 - val_loss: 45.7718 - val_mae: 5.0746\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 41.9383 - mae: 4.9824 - val_loss: 40.3726 - val_mae: 4.6613\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 36.9971 - mae: 4.6483 - val_loss: 36.2099 - val_mae: 4.3886\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 33.4296 - mae: 4.3554 - val_loss: 32.8373 - val_mae: 4.1457\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 30.1702 - mae: 4.0879 - val_loss: 30.7063 - val_mae: 3.9926\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.8657 - mae: 3.8928 - val_loss: 29.1515 - val_mae: 3.8996\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.0258 - mae: 3.7304 - val_loss: 27.9400 - val_mae: 3.8235\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.5563 - mae: 3.6066 - val_loss: 27.2647 - val_mae: 3.7887\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.3910 - mae: 3.5048 - val_loss: 26.8547 - val_mae: 3.7482\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.4052 - mae: 3.4189 - val_loss: 26.4248 - val_mae: 3.7246\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 21.5168 - mae: 3.3403 - val_loss: 26.1190 - val_mae: 3.7140\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 20.8493 - mae: 3.2837 - val_loss: 25.7962 - val_mae: 3.7074\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 20.1577 - mae: 3.2321 - val_loss: 25.5481 - val_mae: 3.6974\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 19.6042 - mae: 3.1810 - val_loss: 25.3081 - val_mae: 3.6793\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 19.0921 - mae: 3.1357 - val_loss: 24.9888 - val_mae: 3.6760\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 18.5885 - mae: 3.1024 - val_loss: 24.8176 - val_mae: 3.6592\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 18.1574 - mae: 3.0647 - val_loss: 24.6206 - val_mae: 3.6371\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 17.7161 - mae: 3.0171 - val_loss: 24.3538 - val_mae: 3.6107\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.3631 - mae: 2.9717 - val_loss: 24.0586 - val_mae: 3.5884\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.9657 - mae: 2.9315 - val_loss: 23.7790 - val_mae: 3.5682\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 16.6654 - mae: 2.9108 - val_loss: 23.5125 - val_mae: 3.5604\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.2890 - mae: 2.8786 - val_loss: 23.3801 - val_mae: 3.5382\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 15.9988 - mae: 2.8393 - val_loss: 23.1563 - val_mae: 3.5076\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 15.8527 - mae: 2.8183 - val_loss: 22.7716 - val_mae: 3.4974\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 15.4306 - mae: 2.7866 - val_loss: 22.6365 - val_mae: 3.4755\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 15.1419 - mae: 2.7534 - val_loss: 22.4255 - val_mae: 3.4527\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.9154 - mae: 2.7303 - val_loss: 22.2391 - val_mae: 3.4563\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.6862 - mae: 2.7110 - val_loss: 22.0068 - val_mae: 3.4404\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 14.4832 - mae: 2.6791 - val_loss: 21.8101 - val_mae: 3.4140\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 14.2677 - mae: 2.6845 - val_loss: 21.4923 - val_mae: 3.4213\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 14.0372 - mae: 2.6614 - val_loss: 21.3117 - val_mae: 3.3860\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 13.7911 - mae: 2.6161 - val_loss: 21.0228 - val_mae: 3.3595\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 13.5895 - mae: 2.5971 - val_loss: 20.9345 - val_mae: 3.3570\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.3672 - mae: 2.5823 - val_loss: 20.8057 - val_mae: 3.3541\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.1938 - mae: 2.5653 - val_loss: 20.5611 - val_mae: 3.3246\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 13.0148 - mae: 2.5523 - val_loss: 20.4412 - val_mae: 3.3205\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 12.8277 - mae: 2.5241 - val_loss: 20.2756 - val_mae: 3.2967\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.6499 - mae: 2.5042 - val_loss: 20.0511 - val_mae: 3.2789\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.5090 - mae: 2.4954 - val_loss: 19.9662 - val_mae: 3.2644\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 12.4151 - mae: 2.4912 - val_loss: 19.6523 - val_mae: 3.2388\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 12.1670 - mae: 2.4633 - val_loss: 19.5744 - val_mae: 3.2186\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 12.1674 - mae: 2.4479 - val_loss: 19.4800 - val_mae: 3.2102\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 12.0106 - mae: 2.4499 - val_loss: 19.2484 - val_mae: 3.2102\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 11.8295 - mae: 2.4302 - val_loss: 19.1068 - val_mae: 3.1919\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 11.6989 - mae: 2.4204 - val_loss: 18.9400 - val_mae: 3.1810\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.5995 - mae: 2.4066 - val_loss: 18.7834 - val_mae: 3.1559\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.4533 - mae: 2.3909 - val_loss: 18.7421 - val_mae: 3.1736\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.3548 - mae: 2.3932 - val_loss: 18.6807 - val_mae: 3.1589\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.2385 - mae: 2.3691 - val_loss: 18.4205 - val_mae: 3.1391\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 11.1260 - mae: 2.3645 - val_loss: 18.2995 - val_mae: 3.1398\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 11.0031 - mae: 2.3513 - val_loss: 18.2886 - val_mae: 3.1283\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.9313 - mae: 2.3400 - val_loss: 18.3012 - val_mae: 3.1210\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 10.8400 - mae: 2.3296 - val_loss: 18.0889 - val_mae: 3.1107\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.7344 - mae: 2.3226 - val_loss: 18.0075 - val_mae: 3.1097\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 10.6476 - mae: 2.3238 - val_loss: 17.8908 - val_mae: 3.1024\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 10.5952 - mae: 2.3216 - val_loss: 17.8361 - val_mae: 3.1020\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 10.5677 - mae: 2.3120 - val_loss: 17.7596 - val_mae: 3.0819\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 10.4268 - mae: 2.3078 - val_loss: 17.6081 - val_mae: 3.0936\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.3180 - mae: 2.2986 - val_loss: 17.5329 - val_mae: 3.0821\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.3057 - mae: 2.2882 - val_loss: 17.5187 - val_mae: 3.0784\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.2141 - mae: 2.2809 - val_loss: 17.4660 - val_mae: 3.0757\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.1318 - mae: 2.2827 - val_loss: 17.3365 - val_mae: 3.0735\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.0963 - mae: 2.2757 - val_loss: 17.1635 - val_mae: 3.0538\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.9643 - mae: 2.2596 - val_loss: 17.1943 - val_mae: 3.0589\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.9239 - mae: 2.2634 - val_loss: 17.1485 - val_mae: 3.0558\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.8494 - mae: 2.2462 - val_loss: 17.1082 - val_mae: 3.0430\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.7912 - mae: 2.2334 - val_loss: 17.0025 - val_mae: 3.0348\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.7887 - mae: 2.2411 - val_loss: 16.9951 - val_mae: 3.0411\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.6791 - mae: 2.2319 - val_loss: 16.9538 - val_mae: 3.0312\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.6436 - mae: 2.2297 - val_loss: 16.8221 - val_mae: 3.0295\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.5643 - mae: 2.2254 - val_loss: 16.7023 - val_mae: 3.0150\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.5074 - mae: 2.2134 - val_loss: 16.7088 - val_mae: 3.0161\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.4355 - mae: 2.2147 - val_loss: 16.6020 - val_mae: 3.0143\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.4188 - mae: 2.2237 - val_loss: 16.5580 - val_mae: 3.0139\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.3769 - mae: 2.2089 - val_loss: 16.4339 - val_mae: 2.9923\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.2967 - mae: 2.1851 - val_loss: 16.3757 - val_mae: 2.9864\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.2363 - mae: 2.1798 - val_loss: 16.3769 - val_mae: 2.9918\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.2081 - mae: 2.1909 - val_loss: 16.3388 - val_mae: 2.9852\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.1333 - mae: 2.1740 - val_loss: 16.3477 - val_mae: 2.9757\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1140 - mae: 2.1718 - val_loss: 16.3410 - val_mae: 2.9918\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.0578 - mae: 2.1739 - val_loss: 16.1941 - val_mae: 2.9728\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.0351 - mae: 2.1581 - val_loss: 16.2038 - val_mae: 2.9649\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.9206 - mae: 2.1457 - val_loss: 15.9221 - val_mae: 2.9581\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.9373 - mae: 2.1597 - val_loss: 15.9505 - val_mae: 2.9718\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.8890 - mae: 2.1627 - val_loss: 15.8122 - val_mae: 2.9495\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.8323 - mae: 2.1490 - val_loss: 15.9976 - val_mae: 2.9588\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.7582 - mae: 2.1475 - val_loss: 15.9677 - val_mae: 2.9612\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.7140 - mae: 2.1357 - val_loss: 15.8698 - val_mae: 2.9493\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.6340 - mae: 2.1187 - val_loss: 15.9369 - val_mae: 2.9456\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.7097 - mae: 2.1189 - val_loss: 15.9645 - val_mae: 2.9511\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.5912 - mae: 2.1106 - val_loss: 15.7662 - val_mae: 2.9383\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.7409 - mae: 2.1476 - val_loss: 15.5329 - val_mae: 2.9480\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.4657 - mae: 2.1145 - val_loss: 15.7830 - val_mae: 2.9408\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.4452 - mae: 2.0953 - val_loss: 15.7933 - val_mae: 2.9216\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.4146 - mae: 2.0866 - val_loss: 15.6086 - val_mae: 2.9114\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.3642 - mae: 2.0897 - val_loss: 15.4468 - val_mae: 2.9063\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.3203 - mae: 2.0930 - val_loss: 15.4805 - val_mae: 2.9132\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.3320 - mae: 2.0944 - val_loss: 15.5392 - val_mae: 2.9071\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.2630 - mae: 2.0718 - val_loss: 15.3574 - val_mae: 2.8888\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.1790 - mae: 2.0759 - val_loss: 15.3558 - val_mae: 2.9044\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.1480 - mae: 2.0759 - val_loss: 15.3267 - val_mae: 2.9007\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.1693 - mae: 2.0744 - val_loss: 15.4277 - val_mae: 2.9077\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.0970 - mae: 2.0662 - val_loss: 15.3454 - val_mae: 2.9013\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0207 - mae: 2.0556 - val_loss: 15.3639 - val_mae: 2.9046\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.9621 - mae: 2.0504 - val_loss: 15.2545 - val_mae: 2.8991\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.9543 - mae: 2.0415 - val_loss: 15.3225 - val_mae: 2.8980\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.9132 - mae: 2.0350 - val_loss: 15.2211 - val_mae: 2.8974\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.8603 - mae: 2.0318 - val_loss: 15.2283 - val_mae: 2.8911\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.8129 - mae: 2.0277 - val_loss: 15.1333 - val_mae: 2.8911\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.8041 - mae: 2.0296 - val_loss: 15.1253 - val_mae: 2.8868\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.7371 - mae: 2.0265 - val_loss: 15.0957 - val_mae: 2.8836\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.7322 - mae: 2.0271 - val_loss: 14.8994 - val_mae: 2.8651\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.6620 - mae: 2.0137 - val_loss: 14.9528 - val_mae: 2.8659\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.6593 - mae: 2.0188 - val_loss: 15.0551 - val_mae: 2.8998\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.6013 - mae: 2.0159 - val_loss: 14.7490 - val_mae: 2.8514\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.5504 - mae: 2.0028 - val_loss: 14.8143 - val_mae: 2.8567\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.5893 - mae: 1.9968 - val_loss: 15.0418 - val_mae: 2.8673\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5080 - mae: 1.9962 - val_loss: 14.7499 - val_mae: 2.8573\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.4860 - mae: 2.0084 - val_loss: 14.7854 - val_mae: 2.8616\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4121 - mae: 1.9763 - val_loss: 14.6034 - val_mae: 2.8237\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.3619 - mae: 1.9706 - val_loss: 14.5896 - val_mae: 2.8370\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.3199 - mae: 1.9699 - val_loss: 14.5840 - val_mae: 2.8326\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.2770 - mae: 1.9738 - val_loss: 14.7478 - val_mae: 2.8451\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2882 - mae: 1.9705 - val_loss: 14.5507 - val_mae: 2.8301\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.2460 - mae: 1.9593 - val_loss: 14.5659 - val_mae: 2.8240\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.1646 - mae: 1.9486 - val_loss: 14.4449 - val_mae: 2.8190\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.1393 - mae: 1.9599 - val_loss: 14.3801 - val_mae: 2.8257\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.1135 - mae: 1.9476 - val_loss: 14.3831 - val_mae: 2.8205\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.0642 - mae: 1.9401 - val_loss: 14.4681 - val_mae: 2.8312\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.1028 - mae: 1.9438 - val_loss: 14.4219 - val_mae: 2.8369\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9497 - mae: 1.9294 - val_loss: 14.5286 - val_mae: 2.8380\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0355 - mae: 1.9302 - val_loss: 14.4284 - val_mae: 2.7986\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9095 - mae: 1.9159 - val_loss: 14.3558 - val_mae: 2.8123\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.8828 - mae: 1.9258 - val_loss: 14.2895 - val_mae: 2.8187\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.8565 - mae: 1.9180 - val_loss: 14.3050 - val_mae: 2.8050\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.8176 - mae: 1.9042 - val_loss: 14.2209 - val_mae: 2.8014\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.9546 - mae: 1.9311 - val_loss: 14.0635 - val_mae: 2.8259\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.7602 - mae: 1.9137 - val_loss: 14.1648 - val_mae: 2.8026\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7150 - mae: 1.8960 - val_loss: 14.2922 - val_mae: 2.8095\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.7363 - mae: 1.8992 - val_loss: 14.1291 - val_mae: 2.7983\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6968 - mae: 1.8922 - val_loss: 14.2274 - val_mae: 2.7958\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.5199 - mae: 1.8812 - val_loss: 14.0496 - val_mae: 2.8008\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.5771 - mae: 1.8843 - val_loss: 14.0266 - val_mae: 2.7926\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.5282 - mae: 1.8706 - val_loss: 13.9533 - val_mae: 2.7800\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.5011 - mae: 1.8685 - val_loss: 14.0104 - val_mae: 2.8009\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.5443 - mae: 1.8887 - val_loss: 14.0084 - val_mae: 2.7926\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3777 - mae: 1.8494 - val_loss: 13.8651 - val_mae: 2.7605\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.4384 - mae: 1.8540 - val_loss: 13.9737 - val_mae: 2.7787\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 6.3764 - mae: 1.8546 - val_loss: 13.8756 - val_mae: 2.7735\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.3612 - mae: 1.8532 - val_loss: 13.9084 - val_mae: 2.7657\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.3273 - mae: 1.8493 - val_loss: 13.9155 - val_mae: 2.7866\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.2831 - mae: 1.8443 - val_loss: 13.7794 - val_mae: 2.7582\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.2358 - mae: 1.8302 - val_loss: 13.7217 - val_mae: 2.7416\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2521 - mae: 1.8375 - val_loss: 13.6473 - val_mae: 2.7521\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.3328 - mae: 1.8443 - val_loss: 13.7445 - val_mae: 2.7321\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2079 - mae: 1.8346 - val_loss: 13.5834 - val_mae: 2.7600\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.1971 - mae: 1.8530 - val_loss: 13.7147 - val_mae: 2.7586\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.1161 - mae: 1.8138 - val_loss: 13.5620 - val_mae: 2.7300\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1189 - mae: 1.8216 - val_loss: 13.6885 - val_mae: 2.7614\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0227 - mae: 1.8124 - val_loss: 13.4263 - val_mae: 2.7318\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0147 - mae: 1.8082 - val_loss: 13.4481 - val_mae: 2.7260\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.9651 - mae: 1.8018 - val_loss: 13.6176 - val_mae: 2.7516\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.9831 - mae: 1.8210 - val_loss: 13.4267 - val_mae: 2.7390\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.9192 - mae: 1.7885 - val_loss: 13.3599 - val_mae: 2.7094\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.9051 - mae: 1.7957 - val_loss: 13.4731 - val_mae: 2.7421\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.8715 - mae: 1.7918 - val_loss: 13.3544 - val_mae: 2.7166\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.8339 - mae: 1.7828 - val_loss: 13.3425 - val_mae: 2.7166\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8163 - mae: 1.7804 - val_loss: 13.2163 - val_mae: 2.7050\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8065 - mae: 1.7704 - val_loss: 13.2179 - val_mae: 2.6813\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.7413 - mae: 1.7780 - val_loss: 13.3182 - val_mae: 2.7322\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7808 - mae: 1.7870 - val_loss: 13.2688 - val_mae: 2.7106\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7070 - mae: 1.7614 - val_loss: 13.2890 - val_mae: 2.6961\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.7201 - mae: 1.7761 - val_loss: 13.1736 - val_mae: 2.7080\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.6857 - mae: 1.7538 - val_loss: 13.1575 - val_mae: 2.6785\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6460 - mae: 1.7481 - val_loss: 13.0439 - val_mae: 2.6874\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.6556 - mae: 1.7721 - val_loss: 13.1899 - val_mae: 2.7193\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.6099 - mae: 1.7558 - val_loss: 13.0554 - val_mae: 2.6814\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5301 - mae: 1.7359 - val_loss: 13.0626 - val_mae: 2.7027\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.5724 - mae: 1.7563 - val_loss: 13.0374 - val_mae: 2.7100\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.5370 - mae: 1.7374 - val_loss: 13.0011 - val_mae: 2.6748\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4887 - mae: 1.7303 - val_loss: 12.9866 - val_mae: 2.6821\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4217 - mae: 1.7189 - val_loss: 13.0525 - val_mae: 2.6830\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4375 - mae: 1.7260 - val_loss: 13.0047 - val_mae: 2.6913\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4372 - mae: 1.7225 - val_loss: 12.8710 - val_mae: 2.6760\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3493 - mae: 1.7041 - val_loss: 12.9648 - val_mae: 2.6700\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4061 - mae: 1.7098 - val_loss: 12.8698 - val_mae: 2.6778\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3580 - mae: 1.7134 - val_loss: 12.9684 - val_mae: 2.6854\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3125 - mae: 1.7001 - val_loss: 12.7866 - val_mae: 2.6592\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3152 - mae: 1.7074 - val_loss: 12.8250 - val_mae: 2.6812\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.3198 - mae: 1.7032 - val_loss: 12.8535 - val_mae: 2.6513\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2534 - mae: 1.6855 - val_loss: 12.8067 - val_mae: 2.6746\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.3133 - mae: 1.7010 - val_loss: 12.7609 - val_mae: 2.6738\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2144 - mae: 1.6755 - val_loss: 12.8108 - val_mae: 2.6532\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1890 - mae: 1.6786 - val_loss: 12.8452 - val_mae: 2.6835\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1853 - mae: 1.6813 - val_loss: 12.7427 - val_mae: 2.6554\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.1104 - mae: 1.6659 - val_loss: 12.7602 - val_mae: 2.6603\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.2389 - mae: 1.7149 - val_loss: 12.7935 - val_mae: 2.6768\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.1414 - mae: 1.6716 - val_loss: 12.5367 - val_mae: 2.6396\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0746 - mae: 1.6633 - val_loss: 12.7111 - val_mae: 2.6668\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.0679 - mae: 1.6612 - val_loss: 12.6272 - val_mae: 2.6437\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 5.0442 - mae: 1.6559 - val_loss: 12.6064 - val_mae: 2.6523\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 4.9944 - mae: 1.6453 - val_loss: 12.6469 - val_mae: 2.6358\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.0052 - mae: 1.6435 - val_loss: 12.4724 - val_mae: 2.6296\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 4.9534 - mae: 1.6444 - val_loss: 12.4515 - val_mae: 2.6307\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9573 - mae: 1.6357 - val_loss: 12.4487 - val_mae: 2.6276\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9127 - mae: 1.6320 - val_loss: 12.6187 - val_mae: 2.6510\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9138 - mae: 1.6358 - val_loss: 12.5845 - val_mae: 2.6584\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8601 - mae: 1.6187 - val_loss: 12.3508 - val_mae: 2.6189\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.8685 - mae: 1.6211 - val_loss: 12.2989 - val_mae: 2.6138\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.8851 - mae: 1.6200 - val_loss: 12.2222 - val_mae: 2.6076\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9061 - mae: 1.6139 - val_loss: 12.4028 - val_mae: 2.6163\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.9060 - mae: 1.6494 - val_loss: 12.4072 - val_mae: 2.6429\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0302 - mae: 1.6448 - val_loss: 12.2127 - val_mae: 2.6061\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7772 - mae: 1.6157 - val_loss: 12.4695 - val_mae: 2.6636\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7754 - mae: 1.6265 - val_loss: 12.3619 - val_mae: 2.6306\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7648 - mae: 1.5987 - val_loss: 12.3596 - val_mae: 2.6296\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.7121 - mae: 1.5899 - val_loss: 12.2437 - val_mae: 2.6166\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6897 - mae: 1.5855 - val_loss: 12.2797 - val_mae: 2.6304\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6998 - mae: 1.5967 - val_loss: 12.2939 - val_mae: 2.6164\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6769 - mae: 1.5912 - val_loss: 12.2819 - val_mae: 2.6245\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6310 - mae: 1.5841 - val_loss: 12.1604 - val_mae: 2.6066\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6125 - mae: 1.5640 - val_loss: 12.1831 - val_mae: 2.5946\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5812 - mae: 1.5653 - val_loss: 12.1746 - val_mae: 2.6034\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5988 - mae: 1.5781 - val_loss: 12.1757 - val_mae: 2.6005\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5722 - mae: 1.5741 - val_loss: 12.1137 - val_mae: 2.6094\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5405 - mae: 1.5605 - val_loss: 12.1039 - val_mae: 2.5924\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5436 - mae: 1.5521 - val_loss: 12.0880 - val_mae: 2.5974\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4900 - mae: 1.5549 - val_loss: 12.1646 - val_mae: 2.6159\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5306 - mae: 1.5561 - val_loss: 12.0494 - val_mae: 2.5994\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5371 - mae: 1.5466 - val_loss: 12.1602 - val_mae: 2.6006\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4904 - mae: 1.5482 - val_loss: 12.1204 - val_mae: 2.6090\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4626 - mae: 1.5423 - val_loss: 12.0459 - val_mae: 2.5852\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5322 - mae: 1.5656 - val_loss: 12.1020 - val_mae: 2.6013\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.4261 - mae: 1.5285 - val_loss: 12.0324 - val_mae: 2.5850\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3735 - mae: 1.5205 - val_loss: 12.0460 - val_mae: 2.5865\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3894 - mae: 1.5326 - val_loss: 11.9378 - val_mae: 2.5812\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3623 - mae: 1.5252 - val_loss: 11.9713 - val_mae: 2.5794\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3521 - mae: 1.5166 - val_loss: 12.0146 - val_mae: 2.5759\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3435 - mae: 1.5111 - val_loss: 11.9402 - val_mae: 2.5850\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2842 - mae: 1.5066 - val_loss: 12.0366 - val_mae: 2.5903\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3008 - mae: 1.5034 - val_loss: 11.8694 - val_mae: 2.5639\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3037 - mae: 1.5136 - val_loss: 11.8454 - val_mae: 2.5774\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.3109 - mae: 1.5197 - val_loss: 11.9125 - val_mae: 2.5824\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.3076 - mae: 1.5040 - val_loss: 11.7390 - val_mae: 2.5606\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2015 - mae: 1.4876 - val_loss: 11.9531 - val_mae: 2.5866\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2162 - mae: 1.5007 - val_loss: 11.8577 - val_mae: 2.5763\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2529 - mae: 1.4994 - val_loss: 11.6786 - val_mae: 2.5596\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2481 - mae: 1.4964 - val_loss: 11.9443 - val_mae: 2.5779\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.1704 - mae: 1.4742 - val_loss: 11.7041 - val_mae: 2.5611\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.1489 - mae: 1.4721 - val_loss: 11.7746 - val_mae: 2.5640\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 4.1545 - mae: 1.4719 - val_loss: 11.7682 - val_mae: 2.5550\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0951 - mae: 1.4661 - val_loss: 11.7809 - val_mae: 2.5703\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0946 - mae: 1.4722 - val_loss: 11.7309 - val_mae: 2.5622\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.1505 - mae: 1.4686 - val_loss: 11.8003 - val_mae: 2.5644\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 4.0397 - mae: 1.4564 - val_loss: 11.7127 - val_mae: 2.5664\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.0865 - mae: 1.4772 - val_loss: 11.7448 - val_mae: 2.5702\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0460 - mae: 1.4601 - val_loss: 11.7187 - val_mae: 2.5564\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0535 - mae: 1.4473 - val_loss: 11.7742 - val_mae: 2.5757\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.0286 - mae: 1.4518 - val_loss: 11.6892 - val_mae: 2.5612\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.0007 - mae: 1.4442 - val_loss: 11.5964 - val_mae: 2.5451\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.0283 - mae: 1.4422 - val_loss: 11.5932 - val_mae: 2.5447\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 3.9936 - mae: 1.4464 - val_loss: 11.6482 - val_mae: 2.5535\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 4.0146 - mae: 1.4381 - val_loss: 11.6956 - val_mae: 2.5506\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.0197 - mae: 1.4363 - val_loss: 11.5358 - val_mae: 2.5451\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.9637 - mae: 1.4458 - val_loss: 11.6556 - val_mae: 2.5504\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.9812 - mae: 1.4425 - val_loss: 11.6608 - val_mae: 2.5449\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3.9579 - mae: 1.4424 - val_loss: 11.7442 - val_mae: 2.5602\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 3.9414 - mae: 1.4360 - val_loss: 11.4941 - val_mae: 2.5325\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3.8870 - mae: 1.4309 - val_loss: 11.6059 - val_mae: 2.5408\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.9673 - mae: 1.4408 - val_loss: 11.5865 - val_mae: 2.5337\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.8586 - mae: 1.4218 - val_loss: 11.4257 - val_mae: 2.5320\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.8696 - mae: 1.4396 - val_loss: 11.4891 - val_mae: 2.5148\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.8556 - mae: 1.4088 - val_loss: 11.5205 - val_mae: 2.5441\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.8671 - mae: 1.4357 - val_loss: 11.6787 - val_mae: 2.5625\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8034 - mae: 1.4013 - val_loss: 11.4040 - val_mae: 2.5221\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7675 - mae: 1.3920 - val_loss: 11.5422 - val_mae: 2.5367\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8173 - mae: 1.4106 - val_loss: 11.4571 - val_mae: 2.5267\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8304 - mae: 1.4217 - val_loss: 11.5004 - val_mae: 2.5405\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7620 - mae: 1.4002 - val_loss: 11.5470 - val_mae: 2.5361\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7369 - mae: 1.3945 - val_loss: 11.5172 - val_mae: 2.5309\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7304 - mae: 1.3947 - val_loss: 11.4070 - val_mae: 2.5133\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7266 - mae: 1.3971 - val_loss: 11.5278 - val_mae: 2.5479\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.8173 - mae: 1.3956 - val_loss: 11.4682 - val_mae: 2.5125\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.8183 - mae: 1.4183 - val_loss: 11.3680 - val_mae: 2.5080\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.7423 - mae: 1.3825 - val_loss: 11.5200 - val_mae: 2.5209\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 8.9460 - mae: 2.0688\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 35ms/step - loss: 567.3481 - mae: 22.0405 - val_loss: 606.3347 - val_mae: 22.5704\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 541.1326 - mae: 21.4484 - val_loss: 576.0828 - val_mae: 21.9187\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 514.8715 - mae: 20.8305 - val_loss: 543.3982 - val_mae: 21.1827\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 485.0480 - mae: 20.1116 - val_loss: 504.2885 - val_mae: 20.2791\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 449.4025 - mae: 19.2128 - val_loss: 457.1891 - val_mae: 19.1528\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 406.4671 - mae: 18.1094 - val_loss: 401.7691 - val_mae: 17.7438\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 355.3665 - mae: 16.7616 - val_loss: 339.0124 - val_mae: 16.0797\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 298.9562 - mae: 15.1514 - val_loss: 271.2292 - val_mae: 14.1155\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 239.4189 - mae: 13.2979 - val_loss: 204.5754 - val_mae: 11.8882\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 181.3046 - mae: 11.3034 - val_loss: 146.8727 - val_mae: 9.7502\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 133.3950 - mae: 9.3698 - val_loss: 104.7286 - val_mae: 7.8458\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 97.0647 - mae: 7.8500 - val_loss: 79.5089 - val_mae: 6.6660\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 72.0457 - mae: 6.6620 - val_loss: 65.7129 - val_mae: 5.9898\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 56.9218 - mae: 5.8509 - val_loss: 56.8330 - val_mae: 5.5247\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 47.0809 - mae: 5.1638 - val_loss: 49.4320 - val_mae: 5.1018\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 39.1954 - mae: 4.6529 - val_loss: 43.6111 - val_mae: 4.7587\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 33.3713 - mae: 4.2386 - val_loss: 39.5948 - val_mae: 4.4852\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 29.5807 - mae: 3.9377 - val_loss: 36.8502 - val_mae: 4.2747\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 26.8891 - mae: 3.6965 - val_loss: 35.2208 - val_mae: 4.1197\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 25.0839 - mae: 3.5485 - val_loss: 33.8857 - val_mae: 4.0174\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.7680 - mae: 3.4468 - val_loss: 32.6012 - val_mae: 3.9254\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 22.4969 - mae: 3.3656 - val_loss: 31.7131 - val_mae: 3.8381\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 21.6169 - mae: 3.2981 - val_loss: 30.8944 - val_mae: 3.7877\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 20.7573 - mae: 3.2272 - val_loss: 30.3251 - val_mae: 3.7415\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 20.0552 - mae: 3.1614 - val_loss: 29.7317 - val_mae: 3.6949\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 19.4568 - mae: 3.1156 - val_loss: 29.1699 - val_mae: 3.6675\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 18.9149 - mae: 3.0625 - val_loss: 28.7132 - val_mae: 3.6269\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 18.4089 - mae: 3.0150 - val_loss: 28.2393 - val_mae: 3.5929\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 17.8835 - mae: 2.9687 - val_loss: 27.7743 - val_mae: 3.5659\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 17.5011 - mae: 2.9447 - val_loss: 27.2862 - val_mae: 3.5324\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 17.0612 - mae: 2.9194 - val_loss: 26.8575 - val_mae: 3.4932\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 16.6860 - mae: 2.8781 - val_loss: 26.5817 - val_mae: 3.4594\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.2586 - mae: 2.8413 - val_loss: 26.2155 - val_mae: 3.4300\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 16.0183 - mae: 2.8446 - val_loss: 25.7888 - val_mae: 3.4123\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 15.6591 - mae: 2.8057 - val_loss: 25.5792 - val_mae: 3.3736\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 15.3297 - mae: 2.7593 - val_loss: 25.2507 - val_mae: 3.3398\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 14.9527 - mae: 2.7421 - val_loss: 24.9044 - val_mae: 3.3176\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 14.6789 - mae: 2.7280 - val_loss: 24.6903 - val_mae: 3.2939\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 14.4181 - mae: 2.7122 - val_loss: 24.4102 - val_mae: 3.2753\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 14.1038 - mae: 2.6800 - val_loss: 24.1697 - val_mae: 3.2438\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 13.8930 - mae: 2.6583 - val_loss: 23.8869 - val_mae: 3.2170\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 13.6573 - mae: 2.6433 - val_loss: 23.6274 - val_mae: 3.1887\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 13.4841 - mae: 2.6427 - val_loss: 23.3522 - val_mae: 3.1811\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 13.2902 - mae: 2.6501 - val_loss: 23.1622 - val_mae: 3.1504\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 12.9641 - mae: 2.6028 - val_loss: 22.9037 - val_mae: 3.1236\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 12.7885 - mae: 2.5897 - val_loss: 22.6302 - val_mae: 3.1094\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 12.6150 - mae: 2.5852 - val_loss: 22.4941 - val_mae: 3.0938\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 12.4071 - mae: 2.5644 - val_loss: 22.3441 - val_mae: 3.0758\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 12.2514 - mae: 2.5454 - val_loss: 22.1814 - val_mae: 3.0418\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 12.1023 - mae: 2.5213 - val_loss: 22.0195 - val_mae: 3.0262\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 12.0052 - mae: 2.5405 - val_loss: 21.8878 - val_mae: 3.0378\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 11.8047 - mae: 2.5223 - val_loss: 21.7071 - val_mae: 3.0005\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 11.5991 - mae: 2.4954 - val_loss: 21.6203 - val_mae: 3.0000\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 11.5223 - mae: 2.5025 - val_loss: 21.5149 - val_mae: 2.9906\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 11.3703 - mae: 2.4866 - val_loss: 21.3205 - val_mae: 2.9697\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.2311 - mae: 2.4697 - val_loss: 21.1689 - val_mae: 2.9499\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 11.1437 - mae: 2.4465 - val_loss: 21.0504 - val_mae: 2.9282\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.1309 - mae: 2.4687 - val_loss: 21.0143 - val_mae: 2.9471\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.9416 - mae: 2.4388 - val_loss: 20.9220 - val_mae: 2.9098\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.8076 - mae: 2.4110 - val_loss: 20.7844 - val_mae: 2.9076\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.7113 - mae: 2.4131 - val_loss: 20.7190 - val_mae: 2.9126\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.6659 - mae: 2.4066 - val_loss: 20.6993 - val_mae: 2.9031\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.5759 - mae: 2.4171 - val_loss: 20.7243 - val_mae: 2.9305\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.5280 - mae: 2.4023 - val_loss: 20.5927 - val_mae: 2.8805\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.3391 - mae: 2.3758 - val_loss: 20.5655 - val_mae: 2.8945\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.2921 - mae: 2.3832 - val_loss: 20.4193 - val_mae: 2.8859\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.1887 - mae: 2.3740 - val_loss: 20.4841 - val_mae: 2.8910\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.1017 - mae: 2.3668 - val_loss: 20.4223 - val_mae: 2.8704\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.0687 - mae: 2.3427 - val_loss: 20.2749 - val_mae: 2.8539\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.9537 - mae: 2.3395 - val_loss: 20.1649 - val_mae: 2.8583\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.8787 - mae: 2.3456 - val_loss: 20.1598 - val_mae: 2.8710\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.8492 - mae: 2.3501 - val_loss: 20.0318 - val_mae: 2.8515\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.8772 - mae: 2.3264 - val_loss: 19.9503 - val_mae: 2.8258\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.6413 - mae: 2.3074 - val_loss: 19.9587 - val_mae: 2.8365\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.5857 - mae: 2.3138 - val_loss: 19.8699 - val_mae: 2.8428\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.5270 - mae: 2.2966 - val_loss: 19.8417 - val_mae: 2.8252\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.4604 - mae: 2.2815 - val_loss: 19.9002 - val_mae: 2.8092\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.3700 - mae: 2.2692 - val_loss: 19.9390 - val_mae: 2.8134\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.3488 - mae: 2.2645 - val_loss: 19.8446 - val_mae: 2.8119\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.2892 - mae: 2.2731 - val_loss: 19.9144 - val_mae: 2.8357\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1852 - mae: 2.2571 - val_loss: 19.8406 - val_mae: 2.8013\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1576 - mae: 2.2343 - val_loss: 19.7568 - val_mae: 2.7879\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.0883 - mae: 2.2260 - val_loss: 19.6979 - val_mae: 2.7921\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1443 - mae: 2.2369 - val_loss: 19.7428 - val_mae: 2.7730\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.9264 - mae: 2.2038 - val_loss: 19.6031 - val_mae: 2.7718\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.9716 - mae: 2.2021 - val_loss: 19.5213 - val_mae: 2.7857\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.8942 - mae: 2.2060 - val_loss: 19.5158 - val_mae: 2.7656\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.8677 - mae: 2.2226 - val_loss: 19.7740 - val_mae: 2.8086\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.8051 - mae: 2.2242 - val_loss: 19.7194 - val_mae: 2.8003\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.7420 - mae: 2.1817 - val_loss: 19.6733 - val_mae: 2.7625\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.6383 - mae: 2.1647 - val_loss: 19.5115 - val_mae: 2.7673\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.5702 - mae: 2.1709 - val_loss: 19.6193 - val_mae: 2.7832\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.5959 - mae: 2.1993 - val_loss: 19.8029 - val_mae: 2.8041\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.4976 - mae: 2.1791 - val_loss: 19.5724 - val_mae: 2.7700\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.4682 - mae: 2.1551 - val_loss: 19.5217 - val_mae: 2.7512\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.4010 - mae: 2.1365 - val_loss: 19.4913 - val_mae: 2.7753\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.3782 - mae: 2.1464 - val_loss: 19.3766 - val_mae: 2.7614\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.3644 - mae: 2.1425 - val_loss: 19.4405 - val_mae: 2.7768\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.2809 - mae: 2.1294 - val_loss: 19.3440 - val_mae: 2.7209\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.2164 - mae: 2.1132 - val_loss: 19.3224 - val_mae: 2.7387\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.1698 - mae: 2.1128 - val_loss: 19.3066 - val_mae: 2.7438\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.1390 - mae: 2.1036 - val_loss: 19.2021 - val_mae: 2.7420\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.1592 - mae: 2.1085 - val_loss: 19.3084 - val_mae: 2.7624\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0751 - mae: 2.1060 - val_loss: 19.1998 - val_mae: 2.7063\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.0445 - mae: 2.0775 - val_loss: 19.2462 - val_mae: 2.7252\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.9893 - mae: 2.0751 - val_loss: 19.2501 - val_mae: 2.7277\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.0260 - mae: 2.1060 - val_loss: 19.4721 - val_mae: 2.7806\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.9118 - mae: 2.0796 - val_loss: 19.3593 - val_mae: 2.7363\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.8690 - mae: 2.0590 - val_loss: 19.3116 - val_mae: 2.6924\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.8678 - mae: 2.0659 - val_loss: 19.2702 - val_mae: 2.7369\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.8695 - mae: 2.0850 - val_loss: 19.4545 - val_mae: 2.7768\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.7597 - mae: 2.0539 - val_loss: 19.2565 - val_mae: 2.6927\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 7.7299 - mae: 2.0379 - val_loss: 19.2442 - val_mae: 2.7197\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.6684 - mae: 2.0473 - val_loss: 19.1861 - val_mae: 2.7419\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.7038 - mae: 2.0534 - val_loss: 19.2375 - val_mae: 2.7568\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.5959 - mae: 2.0350 - val_loss: 19.1792 - val_mae: 2.7298\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.5725 - mae: 2.0261 - val_loss: 19.0433 - val_mae: 2.6798\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.5459 - mae: 2.0129 - val_loss: 19.2063 - val_mae: 2.7179\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.5970 - mae: 2.0219 - val_loss: 19.1825 - val_mae: 2.7439\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 7.5645 - mae: 2.0469 - val_loss: 19.3133 - val_mae: 2.7485\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.5052 - mae: 2.0321 - val_loss: 19.3127 - val_mae: 2.7204\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.3819 - mae: 2.0012 - val_loss: 19.2815 - val_mae: 2.7348\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.3738 - mae: 2.0034 - val_loss: 19.1119 - val_mae: 2.7268\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.3372 - mae: 1.9930 - val_loss: 19.0171 - val_mae: 2.6937\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.4027 - mae: 2.0106 - val_loss: 19.0008 - val_mae: 2.7274\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.3665 - mae: 1.9841 - val_loss: 18.8809 - val_mae: 2.6935\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.2744 - mae: 1.9750 - val_loss: 18.9211 - val_mae: 2.7000\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.2509 - mae: 1.9911 - val_loss: 19.1829 - val_mae: 2.7316\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.2540 - mae: 1.9668 - val_loss: 18.9890 - val_mae: 2.7055\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.1715 - mae: 1.9636 - val_loss: 18.9808 - val_mae: 2.7166\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.1085 - mae: 1.9756 - val_loss: 19.0651 - val_mae: 2.7186\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.0580 - mae: 1.9581 - val_loss: 19.1099 - val_mae: 2.7223\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.0427 - mae: 1.9469 - val_loss: 18.9555 - val_mae: 2.6820\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.9968 - mae: 1.9358 - val_loss: 19.0459 - val_mae: 2.6983\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.0779 - mae: 1.9569 - val_loss: 18.9537 - val_mae: 2.7103\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.9471 - mae: 1.9352 - val_loss: 19.0360 - val_mae: 2.6949\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.9446 - mae: 1.9336 - val_loss: 18.8622 - val_mae: 2.6845\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.9013 - mae: 1.9423 - val_loss: 19.0019 - val_mae: 2.7359\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.8923 - mae: 1.9201 - val_loss: 18.8912 - val_mae: 2.6816\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.9551 - mae: 1.9394 - val_loss: 18.9997 - val_mae: 2.6976\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.7977 - mae: 1.9047 - val_loss: 18.8363 - val_mae: 2.6963\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.8147 - mae: 1.9108 - val_loss: 18.8419 - val_mae: 2.7043\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.8064 - mae: 1.9222 - val_loss: 18.6779 - val_mae: 2.6803\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.7568 - mae: 1.8937 - val_loss: 18.6556 - val_mae: 2.6596\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.7231 - mae: 1.8834 - val_loss: 18.5490 - val_mae: 2.6782\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.6569 - mae: 1.8931 - val_loss: 18.8228 - val_mae: 2.6986\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.6080 - mae: 1.8899 - val_loss: 18.9954 - val_mae: 2.6836\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6423 - mae: 1.8767 - val_loss: 18.9146 - val_mae: 2.6661\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.6361 - mae: 1.8912 - val_loss: 18.9697 - val_mae: 2.7056\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.5412 - mae: 1.8740 - val_loss: 19.0022 - val_mae: 2.6884\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.5487 - mae: 1.8636 - val_loss: 18.7806 - val_mae: 2.6928\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.6508 - mae: 1.8874 - val_loss: 18.6018 - val_mae: 2.6725\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.4464 - mae: 1.8381 - val_loss: 18.8175 - val_mae: 2.6785\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.5407 - mae: 1.8610 - val_loss: 18.7951 - val_mae: 2.6876\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4746 - mae: 1.8401 - val_loss: 18.6112 - val_mae: 2.6505\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.4039 - mae: 1.8460 - val_loss: 19.0352 - val_mae: 2.7295\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4060 - mae: 1.8538 - val_loss: 18.9590 - val_mae: 2.6881\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3628 - mae: 1.8413 - val_loss: 18.8525 - val_mae: 2.7059\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.3335 - mae: 1.8394 - val_loss: 18.6615 - val_mae: 2.6907\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2708 - mae: 1.8217 - val_loss: 18.5391 - val_mae: 2.6703\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.2477 - mae: 1.8103 - val_loss: 18.4913 - val_mae: 2.6707\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2378 - mae: 1.8249 - val_loss: 18.7468 - val_mae: 2.6939\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.3318 - mae: 1.8408 - val_loss: 18.7607 - val_mae: 2.6923\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.1545 - mae: 1.8002 - val_loss: 18.7385 - val_mae: 2.6658\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1985 - mae: 1.7942 - val_loss: 18.6417 - val_mae: 2.6494\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1740 - mae: 1.8033 - val_loss: 18.6017 - val_mae: 2.6660\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.1238 - mae: 1.8088 - val_loss: 18.8613 - val_mae: 2.7012\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.0918 - mae: 1.7908 - val_loss: 18.8463 - val_mae: 2.6838\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0630 - mae: 1.7793 - val_loss: 18.6396 - val_mae: 2.6678\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.0901 - mae: 1.7679 - val_loss: 18.4558 - val_mae: 2.6635\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.1409 - mae: 1.8059 - val_loss: 18.8009 - val_mae: 2.7185\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 6.0184 - mae: 1.7745 - val_loss: 18.6338 - val_mae: 2.6639\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.1917 - mae: 1.7639 - val_loss: 18.3879 - val_mae: 2.6414\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.9521 - mae: 1.7677 - val_loss: 18.6387 - val_mae: 2.7107\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.0257 - mae: 1.7942 - val_loss: 18.6442 - val_mae: 2.6788\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8788 - mae: 1.7500 - val_loss: 18.8299 - val_mae: 2.6809\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.9068 - mae: 1.7638 - val_loss: 18.8050 - val_mae: 2.6955\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8594 - mae: 1.7564 - val_loss: 18.4858 - val_mae: 2.6747\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.9050 - mae: 1.7482 - val_loss: 18.4104 - val_mae: 2.6663\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.9778 - mae: 1.7534 - val_loss: 18.6002 - val_mae: 2.6927\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.8847 - mae: 1.7675 - val_loss: 18.5272 - val_mae: 2.6694\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.7985 - mae: 1.7346 - val_loss: 18.6192 - val_mae: 2.6577\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.7377 - mae: 1.7171 - val_loss: 18.6210 - val_mae: 2.6624\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7485 - mae: 1.7221 - val_loss: 18.6158 - val_mae: 2.6983\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6997 - mae: 1.7258 - val_loss: 18.6700 - val_mae: 2.6866\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6927 - mae: 1.7288 - val_loss: 18.6390 - val_mae: 2.6842\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7319 - mae: 1.7089 - val_loss: 18.4534 - val_mae: 2.6576\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.6522 - mae: 1.7083 - val_loss: 18.4557 - val_mae: 2.6973\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.6475 - mae: 1.7137 - val_loss: 18.4694 - val_mae: 2.6717\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.7028 - mae: 1.7154 - val_loss: 18.9795 - val_mae: 2.7196\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5626 - mae: 1.6997 - val_loss: 18.8139 - val_mae: 2.6824\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5762 - mae: 1.6857 - val_loss: 18.2304 - val_mae: 2.6505\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5936 - mae: 1.6866 - val_loss: 18.3766 - val_mae: 2.6805\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5342 - mae: 1.6920 - val_loss: 18.4741 - val_mae: 2.6806\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5642 - mae: 1.6806 - val_loss: 18.3232 - val_mae: 2.6612\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4922 - mae: 1.6679 - val_loss: 18.2872 - val_mae: 2.6771\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.4660 - mae: 1.6833 - val_loss: 18.5024 - val_mae: 2.6849\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.5003 - mae: 1.7021 - val_loss: 18.5092 - val_mae: 2.6855\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.4624 - mae: 1.6673 - val_loss: 18.5429 - val_mae: 2.6737\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.3775 - mae: 1.6676 - val_loss: 18.6429 - val_mae: 2.7110\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.4150 - mae: 1.6852 - val_loss: 18.4946 - val_mae: 2.7060\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4066 - mae: 1.6652 - val_loss: 18.5054 - val_mae: 2.6909\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3312 - mae: 1.6619 - val_loss: 18.3540 - val_mae: 2.6955\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3181 - mae: 1.6616 - val_loss: 18.3659 - val_mae: 2.6855\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2848 - mae: 1.6464 - val_loss: 18.5633 - val_mae: 2.6952\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2870 - mae: 1.6377 - val_loss: 18.3520 - val_mae: 2.6839\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2089 - mae: 1.6272 - val_loss: 18.1119 - val_mae: 2.6729\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.2147 - mae: 1.6287 - val_loss: 18.3408 - val_mae: 2.6965\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.2539 - mae: 1.6584 - val_loss: 18.6674 - val_mae: 2.7180\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1791 - mae: 1.6342 - val_loss: 18.3634 - val_mae: 2.6865\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1882 - mae: 1.6256 - val_loss: 18.4338 - val_mae: 2.7100\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2133 - mae: 1.6606 - val_loss: 18.3492 - val_mae: 2.6923\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0968 - mae: 1.6014 - val_loss: 18.2114 - val_mae: 2.6753\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.0951 - mae: 1.6158 - val_loss: 18.5907 - val_mae: 2.7307\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0859 - mae: 1.6152 - val_loss: 18.3107 - val_mae: 2.6900\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.0477 - mae: 1.5973 - val_loss: 18.2014 - val_mae: 2.6969\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.0013 - mae: 1.6063 - val_loss: 18.1418 - val_mae: 2.6971\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0084 - mae: 1.6073 - val_loss: 18.3897 - val_mae: 2.6988\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0510 - mae: 1.5964 - val_loss: 18.1631 - val_mae: 2.6900\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9627 - mae: 1.5872 - val_loss: 18.3523 - val_mae: 2.7069\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9304 - mae: 1.5796 - val_loss: 18.1734 - val_mae: 2.6941\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9559 - mae: 1.5824 - val_loss: 17.9837 - val_mae: 2.6748\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9054 - mae: 1.5851 - val_loss: 18.3436 - val_mae: 2.7041\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.9566 - mae: 1.5707 - val_loss: 18.3268 - val_mae: 2.6956\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.9048 - mae: 1.5865 - val_loss: 18.3999 - val_mae: 2.7172\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8218 - mae: 1.5667 - val_loss: 18.1022 - val_mae: 2.6801\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8567 - mae: 1.5736 - val_loss: 18.0035 - val_mae: 2.6939\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7813 - mae: 1.5483 - val_loss: 18.1872 - val_mae: 2.6818\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8244 - mae: 1.5768 - val_loss: 18.3777 - val_mae: 2.7233\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8820 - mae: 1.5704 - val_loss: 18.1384 - val_mae: 2.6978\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9183 - mae: 1.6048 - val_loss: 18.2606 - val_mae: 2.7131\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8614 - mae: 1.5969 - val_loss: 18.3809 - val_mae: 2.7200\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.6842 - mae: 1.5480 - val_loss: 18.1062 - val_mae: 2.7064\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7632 - mae: 1.5590 - val_loss: 18.2218 - val_mae: 2.7224\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.7102 - mae: 1.5339 - val_loss: 18.0788 - val_mae: 2.6940\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.6426 - mae: 1.5455 - val_loss: 18.2811 - val_mae: 2.7294\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.6653 - mae: 1.5406 - val_loss: 18.0611 - val_mae: 2.7009\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.6278 - mae: 1.5326 - val_loss: 18.3749 - val_mae: 2.7309\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5924 - mae: 1.5193 - val_loss: 18.2466 - val_mae: 2.7155\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5957 - mae: 1.5254 - val_loss: 18.0808 - val_mae: 2.6935\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5794 - mae: 1.5279 - val_loss: 18.2191 - val_mae: 2.7241\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5380 - mae: 1.5089 - val_loss: 18.1609 - val_mae: 2.6995\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5413 - mae: 1.5313 - val_loss: 18.2421 - val_mae: 2.7201\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.4936 - mae: 1.5213 - val_loss: 18.3473 - val_mae: 2.7264\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.4616 - mae: 1.5117 - val_loss: 18.4896 - val_mae: 2.7375\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4700 - mae: 1.5156 - val_loss: 18.1538 - val_mae: 2.7100\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.4325 - mae: 1.5114 - val_loss: 18.1530 - val_mae: 2.7140\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4295 - mae: 1.5034 - val_loss: 18.0225 - val_mae: 2.7109\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.4334 - mae: 1.4992 - val_loss: 18.1176 - val_mae: 2.7294\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3745 - mae: 1.5026 - val_loss: 18.1557 - val_mae: 2.7131\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4187 - mae: 1.5014 - val_loss: 18.3918 - val_mae: 2.7468\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3566 - mae: 1.5049 - val_loss: 18.2308 - val_mae: 2.7305\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2999 - mae: 1.4913 - val_loss: 18.2232 - val_mae: 2.7325\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3763 - mae: 1.5247 - val_loss: 18.0800 - val_mae: 2.7178\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3209 - mae: 1.4806 - val_loss: 18.1043 - val_mae: 2.7090\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2708 - mae: 1.4646 - val_loss: 17.9063 - val_mae: 2.7100\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2966 - mae: 1.4889 - val_loss: 17.9400 - val_mae: 2.7201\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2766 - mae: 1.4767 - val_loss: 18.0668 - val_mae: 2.7190\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2513 - mae: 1.4692 - val_loss: 18.1606 - val_mae: 2.7401\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3031 - mae: 1.4898 - val_loss: 17.7907 - val_mae: 2.7103\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2687 - mae: 1.4797 - val_loss: 17.9900 - val_mae: 2.7240\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.1681 - mae: 1.4651 - val_loss: 18.0294 - val_mae: 2.7150\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.1500 - mae: 1.4599 - val_loss: 18.0403 - val_mae: 2.7302\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.1341 - mae: 1.4591 - val_loss: 18.0259 - val_mae: 2.7219\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.1560 - mae: 1.4479 - val_loss: 17.9991 - val_mae: 2.7209\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.0968 - mae: 1.4517 - val_loss: 17.8933 - val_mae: 2.7303\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.0951 - mae: 1.4646 - val_loss: 18.0346 - val_mae: 2.7366\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 4.0854 - mae: 1.4477 - val_loss: 18.1753 - val_mae: 2.7425\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.1011 - mae: 1.4690 - val_loss: 17.8550 - val_mae: 2.7203\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 4.0913 - mae: 1.4263 - val_loss: 17.7844 - val_mae: 2.7117\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 4.1064 - mae: 1.4728 - val_loss: 18.2014 - val_mae: 2.7618\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.0498 - mae: 1.4274 - val_loss: 17.9263 - val_mae: 2.7196\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.0172 - mae: 1.4319 - val_loss: 18.0841 - val_mae: 2.7575\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.9632 - mae: 1.4435 - val_loss: 17.9525 - val_mae: 2.7256\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9559 - mae: 1.4227 - val_loss: 17.9359 - val_mae: 2.7411\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.9167 - mae: 1.4308 - val_loss: 17.8327 - val_mae: 2.7299\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.9549 - mae: 1.4259 - val_loss: 18.0844 - val_mae: 2.7430\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.9546 - mae: 1.4259 - val_loss: 17.7099 - val_mae: 2.7208\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.0118 - mae: 1.4306 - val_loss: 17.6780 - val_mae: 2.7283\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.8737 - mae: 1.4253 - val_loss: 18.2161 - val_mae: 2.7681\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.8736 - mae: 1.4146 - val_loss: 18.1427 - val_mae: 2.7480\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.8605 - mae: 1.4185 - val_loss: 18.1962 - val_mae: 2.7730\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.8137 - mae: 1.4030 - val_loss: 17.9633 - val_mae: 2.7255\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.8605 - mae: 1.3912 - val_loss: 17.7740 - val_mae: 2.7314\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.8086 - mae: 1.4208 - val_loss: 17.9466 - val_mae: 2.7373\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.8077 - mae: 1.3982 - val_loss: 17.9309 - val_mae: 2.7312\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.7917 - mae: 1.3949 - val_loss: 17.8330 - val_mae: 2.7305\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.7891 - mae: 1.4020 - val_loss: 17.9268 - val_mae: 2.7425\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.7948 - mae: 1.4117 - val_loss: 18.1730 - val_mae: 2.7533\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.7673 - mae: 1.3958 - val_loss: 17.9349 - val_mae: 2.7375\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7760 - mae: 1.4215 - val_loss: 17.9321 - val_mae: 2.7523\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7569 - mae: 1.3805 - val_loss: 18.0216 - val_mae: 2.7481\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6814 - mae: 1.4052 - val_loss: 18.0643 - val_mae: 2.7604\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7204 - mae: 1.3872 - val_loss: 17.9513 - val_mae: 2.7347\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7054 - mae: 1.3739 - val_loss: 17.9917 - val_mae: 2.7670\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7144 - mae: 1.4160 - val_loss: 17.8745 - val_mae: 2.7308\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.6649 - mae: 1.3676 - val_loss: 17.8583 - val_mae: 2.7278\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6398 - mae: 1.3788 - val_loss: 18.0292 - val_mae: 2.7528\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.6113 - mae: 1.3832 - val_loss: 18.1058 - val_mae: 2.7434\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5876 - mae: 1.3495 - val_loss: 18.1674 - val_mae: 2.7445\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.0418 - mae: 2.0407\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 23ms/step - loss: 542.7086 - mae: 21.3221 - val_loss: 586.7156 - val_mae: 22.1514\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 515.8413 - mae: 20.6002 - val_loss: 556.8184 - val_mae: 21.3902\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 485.6672 - mae: 19.7637 - val_loss: 522.9855 - val_mae: 20.5026\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 451.1733 - mae: 18.7519 - val_loss: 482.6671 - val_mae: 19.4477\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 410.9325 - mae: 17.5678 - val_loss: 435.3024 - val_mae: 18.1393\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 365.3928 - mae: 16.3197 - val_loss: 380.3499 - val_mae: 16.6571\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 312.4570 - mae: 14.9173 - val_loss: 320.5930 - val_mae: 15.2199\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 256.9886 - mae: 13.4009 - val_loss: 254.5865 - val_mae: 13.5322\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 198.0103 - mae: 11.6813 - val_loss: 188.4523 - val_mae: 11.5098\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 141.0264 - mae: 9.7382 - val_loss: 129.7368 - val_mae: 9.1395\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 94.7280 - mae: 7.8575 - val_loss: 87.7981 - val_mae: 7.0976\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 65.1882 - mae: 6.3577 - val_loss: 64.2401 - val_mae: 6.0634\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 50.2137 - mae: 5.5340 - val_loss: 51.9609 - val_mae: 5.3691\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 42.0870 - mae: 4.9772 - val_loss: 44.0457 - val_mae: 4.8396\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 36.5894 - mae: 4.5813 - val_loss: 38.0463 - val_mae: 4.4283\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 32.6302 - mae: 4.2788 - val_loss: 33.4622 - val_mae: 4.0758\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 29.5463 - mae: 4.0336 - val_loss: 30.3098 - val_mae: 3.8751\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 27.3793 - mae: 3.8596 - val_loss: 28.0342 - val_mae: 3.6922\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 25.9835 - mae: 3.7262 - val_loss: 26.0871 - val_mae: 3.5560\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.7789 - mae: 3.6194 - val_loss: 24.6922 - val_mae: 3.4377\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.9052 - mae: 3.5373 - val_loss: 23.5375 - val_mae: 3.3782\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 22.9982 - mae: 3.4680 - val_loss: 22.5799 - val_mae: 3.2871\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 22.3040 - mae: 3.4006 - val_loss: 21.7540 - val_mae: 3.2154\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 21.6689 - mae: 3.3422 - val_loss: 21.0223 - val_mae: 3.1458\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.0103 - mae: 3.2802 - val_loss: 20.3902 - val_mae: 3.0821\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 20.6047 - mae: 3.2507 - val_loss: 19.7923 - val_mae: 3.0736\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 20.0443 - mae: 3.1977 - val_loss: 19.0472 - val_mae: 2.9901\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 19.4851 - mae: 3.1427 - val_loss: 18.5177 - val_mae: 2.9455\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 19.0174 - mae: 3.0979 - val_loss: 18.1392 - val_mae: 2.8936\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 18.6526 - mae: 3.0584 - val_loss: 17.7489 - val_mae: 2.8431\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 18.1799 - mae: 3.0147 - val_loss: 17.4281 - val_mae: 2.8456\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 17.9016 - mae: 2.9966 - val_loss: 17.1204 - val_mae: 2.8609\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 17.4376 - mae: 2.9521 - val_loss: 16.7580 - val_mae: 2.8319\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 17.0360 - mae: 2.9014 - val_loss: 16.5419 - val_mae: 2.7691\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 16.7614 - mae: 2.8693 - val_loss: 16.3715 - val_mae: 2.7689\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 16.4061 - mae: 2.8318 - val_loss: 16.1227 - val_mae: 2.7686\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.0851 - mae: 2.8033 - val_loss: 15.8949 - val_mae: 2.7537\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.8285 - mae: 2.7725 - val_loss: 15.7281 - val_mae: 2.7365\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 15.6060 - mae: 2.7436 - val_loss: 15.5183 - val_mae: 2.7293\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 15.3357 - mae: 2.7252 - val_loss: 15.4028 - val_mae: 2.7233\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.0404 - mae: 2.6915 - val_loss: 15.2104 - val_mae: 2.7058\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.8545 - mae: 2.6736 - val_loss: 15.0133 - val_mae: 2.6897\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 14.6078 - mae: 2.6513 - val_loss: 14.8958 - val_mae: 2.6847\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.4244 - mae: 2.6428 - val_loss: 14.7812 - val_mae: 2.6826\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.2082 - mae: 2.6223 - val_loss: 14.6824 - val_mae: 2.6817\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.1000 - mae: 2.5999 - val_loss: 14.6848 - val_mae: 2.6702\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.8809 - mae: 2.5787 - val_loss: 14.6358 - val_mae: 2.6764\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.7447 - mae: 2.5805 - val_loss: 14.4679 - val_mae: 2.6705\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.5653 - mae: 2.5639 - val_loss: 14.2870 - val_mae: 2.6666\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.3119 - mae: 2.5419 - val_loss: 14.1917 - val_mae: 2.6501\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 13.3303 - mae: 2.5334 - val_loss: 14.1455 - val_mae: 2.6528\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.0241 - mae: 2.5073 - val_loss: 14.0429 - val_mae: 2.6464\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.0388 - mae: 2.4851 - val_loss: 14.0795 - val_mae: 2.6486\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.8439 - mae: 2.4878 - val_loss: 13.9407 - val_mae: 2.6559\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.6548 - mae: 2.4774 - val_loss: 13.8598 - val_mae: 2.6537\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.5668 - mae: 2.4719 - val_loss: 13.8063 - val_mae: 2.6451\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.4150 - mae: 2.4454 - val_loss: 13.7591 - val_mae: 2.6419\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.3142 - mae: 2.4380 - val_loss: 13.7933 - val_mae: 2.6647\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 12.1810 - mae: 2.4379 - val_loss: 13.6488 - val_mae: 2.6562\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.1407 - mae: 2.4302 - val_loss: 13.5383 - val_mae: 2.6519\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.9602 - mae: 2.3992 - val_loss: 13.5858 - val_mae: 2.6534\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.8911 - mae: 2.3824 - val_loss: 13.5800 - val_mae: 2.6544\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.8693 - mae: 2.3866 - val_loss: 13.5204 - val_mae: 2.6651\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.7297 - mae: 2.3721 - val_loss: 13.5023 - val_mae: 2.6569\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.7002 - mae: 2.3867 - val_loss: 13.4154 - val_mae: 2.6690\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.5660 - mae: 2.3651 - val_loss: 13.4020 - val_mae: 2.6564\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.5616 - mae: 2.3643 - val_loss: 13.2953 - val_mae: 2.6551\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.3652 - mae: 2.3345 - val_loss: 13.3991 - val_mae: 2.6556\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.3311 - mae: 2.3200 - val_loss: 13.3713 - val_mae: 2.6570\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.3658 - mae: 2.3533 - val_loss: 13.3099 - val_mae: 2.6766\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.2032 - mae: 2.3498 - val_loss: 13.1940 - val_mae: 2.6600\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.0389 - mae: 2.3045 - val_loss: 13.1680 - val_mae: 2.6590\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.0063 - mae: 2.2966 - val_loss: 13.1437 - val_mae: 2.6635\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.9169 - mae: 2.2855 - val_loss: 13.1239 - val_mae: 2.6607\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.8336 - mae: 2.2777 - val_loss: 13.2452 - val_mae: 2.6692\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.7930 - mae: 2.2756 - val_loss: 13.1714 - val_mae: 2.6639\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.7269 - mae: 2.2771 - val_loss: 13.1735 - val_mae: 2.6675\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.7458 - mae: 2.2538 - val_loss: 13.2717 - val_mae: 2.6630\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.6017 - mae: 2.2425 - val_loss: 13.0919 - val_mae: 2.6724\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.5791 - mae: 2.2646 - val_loss: 13.1639 - val_mae: 2.6820\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.5368 - mae: 2.2427 - val_loss: 13.0870 - val_mae: 2.6731\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.4410 - mae: 2.2314 - val_loss: 13.0320 - val_mae: 2.6748\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.4386 - mae: 2.2472 - val_loss: 12.9335 - val_mae: 2.6668\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.3067 - mae: 2.2242 - val_loss: 12.9937 - val_mae: 2.6673\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.2151 - mae: 2.2106 - val_loss: 12.9370 - val_mae: 2.6663\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.2111 - mae: 2.2189 - val_loss: 12.8108 - val_mae: 2.6625\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.0990 - mae: 2.2107 - val_loss: 12.8038 - val_mae: 2.6580\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.0754 - mae: 2.1975 - val_loss: 12.8068 - val_mae: 2.6514\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.0229 - mae: 2.1873 - val_loss: 12.7057 - val_mae: 2.6483\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.0249 - mae: 2.2014 - val_loss: 12.7487 - val_mae: 2.6476\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.9085 - mae: 2.1917 - val_loss: 12.7147 - val_mae: 2.6434\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.8417 - mae: 2.1764 - val_loss: 12.7101 - val_mae: 2.6358\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.7807 - mae: 2.1640 - val_loss: 12.7058 - val_mae: 2.6407\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.7496 - mae: 2.1664 - val_loss: 12.6711 - val_mae: 2.6514\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.7948 - mae: 2.1839 - val_loss: 12.6841 - val_mae: 2.6548\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.5886 - mae: 2.1505 - val_loss: 12.7392 - val_mae: 2.6476\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.6320 - mae: 2.1415 - val_loss: 12.6237 - val_mae: 2.6347\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.7424 - mae: 2.1728 - val_loss: 12.5866 - val_mae: 2.6560\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.5720 - mae: 2.1531 - val_loss: 12.6502 - val_mae: 2.6349\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.5031 - mae: 2.1389 - val_loss: 12.5661 - val_mae: 2.6386\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 9.3668 - mae: 2.1249 - val_loss: 12.4829 - val_mae: 2.6337\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.3849 - mae: 2.1288 - val_loss: 12.4484 - val_mae: 2.6294\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.2653 - mae: 2.1040 - val_loss: 12.4429 - val_mae: 2.6203\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.2520 - mae: 2.1148 - val_loss: 12.3370 - val_mae: 2.6204\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.2940 - mae: 2.1089 - val_loss: 12.4524 - val_mae: 2.6235\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.1304 - mae: 2.0950 - val_loss: 12.3844 - val_mae: 2.6322\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 9.1368 - mae: 2.1011 - val_loss: 12.3122 - val_mae: 2.6254\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 9.2326 - mae: 2.1033 - val_loss: 12.4024 - val_mae: 2.6083\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 9.1051 - mae: 2.0986 - val_loss: 12.2689 - val_mae: 2.6120\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.0018 - mae: 2.0949 - val_loss: 12.2993 - val_mae: 2.6202\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.9141 - mae: 2.0652 - val_loss: 12.3234 - val_mae: 2.6137\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.9340 - mae: 2.0595 - val_loss: 12.1031 - val_mae: 2.6045\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.7966 - mae: 2.0585 - val_loss: 12.0812 - val_mae: 2.5934\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.7683 - mae: 2.0510 - val_loss: 12.1644 - val_mae: 2.6047\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 8.8316 - mae: 2.0417 - val_loss: 12.1881 - val_mae: 2.5966\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 8.7638 - mae: 2.0599 - val_loss: 11.9816 - val_mae: 2.5927\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.7333 - mae: 2.0619 - val_loss: 12.0345 - val_mae: 2.5755\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 8.5715 - mae: 2.0296 - val_loss: 11.9815 - val_mae: 2.5796\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.6609 - mae: 2.0546 - val_loss: 11.9608 - val_mae: 2.5812\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 8.5962 - mae: 2.0357 - val_loss: 12.0887 - val_mae: 2.5826\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.4896 - mae: 2.0231 - val_loss: 11.9756 - val_mae: 2.5929\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 8.4446 - mae: 2.0139 - val_loss: 11.9754 - val_mae: 2.5827\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 8.3944 - mae: 2.0049 - val_loss: 11.8861 - val_mae: 2.5784\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.4285 - mae: 2.0349 - val_loss: 11.7916 - val_mae: 2.5664\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.4773 - mae: 2.0040 - val_loss: 11.8934 - val_mae: 2.5598\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.3934 - mae: 2.0175 - val_loss: 11.8131 - val_mae: 2.5720\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.2387 - mae: 1.9975 - val_loss: 11.8982 - val_mae: 2.5722\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.3391 - mae: 2.0027 - val_loss: 11.8109 - val_mae: 2.5652\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.1519 - mae: 1.9718 - val_loss: 11.8884 - val_mae: 2.5524\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.1412 - mae: 1.9781 - val_loss: 11.8173 - val_mae: 2.5532\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.1312 - mae: 1.9842 - val_loss: 11.6386 - val_mae: 2.5372\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.1021 - mae: 1.9974 - val_loss: 11.6236 - val_mae: 2.5397\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0561 - mae: 1.9761 - val_loss: 11.6983 - val_mae: 2.5310\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.9599 - mae: 1.9602 - val_loss: 11.6813 - val_mae: 2.5358\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.9348 - mae: 1.9677 - val_loss: 11.6348 - val_mae: 2.5365\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.9634 - mae: 1.9553 - val_loss: 11.5383 - val_mae: 2.5199\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.8739 - mae: 1.9542 - val_loss: 11.5279 - val_mae: 2.5142\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.8113 - mae: 1.9473 - val_loss: 11.4181 - val_mae: 2.5096\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.8196 - mae: 1.9549 - val_loss: 11.4206 - val_mae: 2.5116\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.7625 - mae: 1.9359 - val_loss: 11.4819 - val_mae: 2.5147\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.6892 - mae: 1.9233 - val_loss: 11.5579 - val_mae: 2.5200\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.7045 - mae: 1.9392 - val_loss: 11.4087 - val_mae: 2.5043\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.6159 - mae: 1.9159 - val_loss: 11.3709 - val_mae: 2.4977\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.6002 - mae: 1.9300 - val_loss: 11.3784 - val_mae: 2.5001\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.5957 - mae: 1.9048 - val_loss: 11.3775 - val_mae: 2.4903\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.5639 - mae: 1.9089 - val_loss: 11.3501 - val_mae: 2.4961\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.5015 - mae: 1.9105 - val_loss: 11.3483 - val_mae: 2.5016\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.4395 - mae: 1.9022 - val_loss: 11.3492 - val_mae: 2.4842\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.4639 - mae: 1.8876 - val_loss: 11.4914 - val_mae: 2.4882\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.3600 - mae: 1.8987 - val_loss: 11.3374 - val_mae: 2.4908\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.3964 - mae: 1.9090 - val_loss: 11.4045 - val_mae: 2.4988\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.3602 - mae: 1.8986 - val_loss: 11.4191 - val_mae: 2.5097\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.3185 - mae: 1.8941 - val_loss: 11.4062 - val_mae: 2.4958\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.3017 - mae: 1.9000 - val_loss: 11.3746 - val_mae: 2.5020\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.1757 - mae: 1.8823 - val_loss: 11.3054 - val_mae: 2.4924\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.1838 - mae: 1.8698 - val_loss: 11.2878 - val_mae: 2.4789\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.1987 - mae: 1.8690 - val_loss: 11.3029 - val_mae: 2.4913\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.1423 - mae: 1.8816 - val_loss: 11.1813 - val_mae: 2.4787\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.0792 - mae: 1.8503 - val_loss: 11.2757 - val_mae: 2.4822\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.0946 - mae: 1.8667 - val_loss: 11.3205 - val_mae: 2.4876\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.0067 - mae: 1.8565 - val_loss: 11.2598 - val_mae: 2.4829\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.0033 - mae: 1.8500 - val_loss: 11.1893 - val_mae: 2.4809\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.9382 - mae: 1.8571 - val_loss: 11.1411 - val_mae: 2.4778\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.9594 - mae: 1.8612 - val_loss: 11.0467 - val_mae: 2.4554\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.9469 - mae: 1.8481 - val_loss: 11.2216 - val_mae: 2.4815\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8965 - mae: 1.8432 - val_loss: 11.1524 - val_mae: 2.4672\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.8459 - mae: 1.8443 - val_loss: 11.1575 - val_mae: 2.4719\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.9586 - mae: 1.8325 - val_loss: 11.2513 - val_mae: 2.4819\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.7833 - mae: 1.8531 - val_loss: 11.1360 - val_mae: 2.4632\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7401 - mae: 1.8340 - val_loss: 11.1657 - val_mae: 2.4636\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.7260 - mae: 1.8242 - val_loss: 11.0754 - val_mae: 2.4552\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.6680 - mae: 1.8137 - val_loss: 11.0564 - val_mae: 2.4567\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.7109 - mae: 1.8395 - val_loss: 11.0716 - val_mae: 2.4575\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.7062 - mae: 1.8080 - val_loss: 11.1787 - val_mae: 2.4675\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.7060 - mae: 1.8352 - val_loss: 11.0212 - val_mae: 2.4437\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6298 - mae: 1.8179 - val_loss: 11.0488 - val_mae: 2.4578\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.5297 - mae: 1.8028 - val_loss: 11.1371 - val_mae: 2.4668\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.5642 - mae: 1.8056 - val_loss: 11.1594 - val_mae: 2.4658\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.5050 - mae: 1.7992 - val_loss: 11.0085 - val_mae: 2.4429\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4489 - mae: 1.7969 - val_loss: 11.0441 - val_mae: 2.4544\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4973 - mae: 1.7901 - val_loss: 11.0759 - val_mae: 2.4514\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.4775 - mae: 1.8021 - val_loss: 11.1181 - val_mae: 2.4549\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.5260 - mae: 1.8147 - val_loss: 11.1909 - val_mae: 2.4636\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.3902 - mae: 1.8021 - val_loss: 11.0705 - val_mae: 2.4389\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.3571 - mae: 1.7873 - val_loss: 10.9111 - val_mae: 2.4322\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.2734 - mae: 1.7721 - val_loss: 10.9221 - val_mae: 2.4271\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.2668 - mae: 1.7970 - val_loss: 11.0197 - val_mae: 2.4455\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.2446 - mae: 1.7890 - val_loss: 10.9132 - val_mae: 2.4282\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2263 - mae: 1.7709 - val_loss: 11.0232 - val_mae: 2.4436\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.1681 - mae: 1.7611 - val_loss: 10.9593 - val_mae: 2.4506\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2624 - mae: 1.7798 - val_loss: 10.9029 - val_mae: 2.4422\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2001 - mae: 1.7910 - val_loss: 11.0070 - val_mae: 2.4484\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1547 - mae: 1.7805 - val_loss: 10.9995 - val_mae: 2.4545\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1072 - mae: 1.7834 - val_loss: 10.9701 - val_mae: 2.4224\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0479 - mae: 1.7585 - val_loss: 10.9767 - val_mae: 2.4403\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.1578 - mae: 1.7609 - val_loss: 10.9657 - val_mae: 2.4300\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.9642 - mae: 1.7501 - val_loss: 10.9773 - val_mae: 2.4339\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.0162 - mae: 1.7591 - val_loss: 10.8468 - val_mae: 2.4125\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.9520 - mae: 1.7551 - val_loss: 10.9356 - val_mae: 2.4379\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.9037 - mae: 1.7213 - val_loss: 10.9250 - val_mae: 2.4335\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.9977 - mae: 1.7464 - val_loss: 10.8614 - val_mae: 2.4204\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8814 - mae: 1.7590 - val_loss: 10.8468 - val_mae: 2.4222\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.8652 - mae: 1.7293 - val_loss: 10.9956 - val_mae: 2.4522\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.9290 - mae: 1.7233 - val_loss: 10.9986 - val_mae: 2.4482\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.9294 - mae: 1.7764 - val_loss: 11.0501 - val_mae: 2.4458\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8519 - mae: 1.7226 - val_loss: 11.1483 - val_mae: 2.4536\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8029 - mae: 1.7284 - val_loss: 11.1355 - val_mae: 2.4469\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.6965 - mae: 1.7108 - val_loss: 10.9438 - val_mae: 2.4371\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.7023 - mae: 1.7274 - val_loss: 10.7868 - val_mae: 2.4010\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.6528 - mae: 1.7085 - val_loss: 11.0111 - val_mae: 2.4366\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.6226 - mae: 1.6983 - val_loss: 10.9164 - val_mae: 2.4212\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6085 - mae: 1.6991 - val_loss: 10.7896 - val_mae: 2.4139\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.5639 - mae: 1.6861 - val_loss: 10.9030 - val_mae: 2.4189\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.5382 - mae: 1.6910 - val_loss: 10.8864 - val_mae: 2.4096\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.5003 - mae: 1.6821 - val_loss: 10.9821 - val_mae: 2.4141\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.4657 - mae: 1.6719 - val_loss: 10.8995 - val_mae: 2.4220\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.4778 - mae: 1.6829 - val_loss: 10.8773 - val_mae: 2.4065\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.4579 - mae: 1.6867 - val_loss: 10.8922 - val_mae: 2.4135\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.4141 - mae: 1.6692 - val_loss: 10.9631 - val_mae: 2.4373\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3959 - mae: 1.6810 - val_loss: 11.0408 - val_mae: 2.4356\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.3701 - mae: 1.6674 - val_loss: 11.1126 - val_mae: 2.4457\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.4115 - mae: 1.6652 - val_loss: 11.1134 - val_mae: 2.4232\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3025 - mae: 1.6600 - val_loss: 10.9840 - val_mae: 2.4257\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3285 - mae: 1.6800 - val_loss: 10.9354 - val_mae: 2.4044\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3239 - mae: 1.6454 - val_loss: 10.9513 - val_mae: 2.4110\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.2151 - mae: 1.6504 - val_loss: 10.9341 - val_mae: 2.4051\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.2244 - mae: 1.6424 - val_loss: 10.9640 - val_mae: 2.4156\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2352 - mae: 1.6790 - val_loss: 10.9209 - val_mae: 2.3979\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.2068 - mae: 1.6288 - val_loss: 10.8658 - val_mae: 2.4137\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1515 - mae: 1.6281 - val_loss: 11.0439 - val_mae: 2.4146\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1803 - mae: 1.6725 - val_loss: 10.8220 - val_mae: 2.4006\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.2754 - mae: 1.6440 - val_loss: 10.9701 - val_mae: 2.4164\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0558 - mae: 1.6285 - val_loss: 10.9964 - val_mae: 2.4047\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0370 - mae: 1.6308 - val_loss: 10.8469 - val_mae: 2.4040\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0134 - mae: 1.6064 - val_loss: 10.9593 - val_mae: 2.4153\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.1036 - mae: 1.6610 - val_loss: 10.8181 - val_mae: 2.3938\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1240 - mae: 1.6239 - val_loss: 10.9602 - val_mae: 2.4141\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9593 - mae: 1.6108 - val_loss: 10.8995 - val_mae: 2.4002\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9349 - mae: 1.6037 - val_loss: 10.8997 - val_mae: 2.4050\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9391 - mae: 1.6088 - val_loss: 10.8893 - val_mae: 2.4030\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9091 - mae: 1.5940 - val_loss: 10.9712 - val_mae: 2.4068\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9687 - mae: 1.5836 - val_loss: 10.8638 - val_mae: 2.4031\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8848 - mae: 1.6134 - val_loss: 10.9545 - val_mae: 2.4123\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.8476 - mae: 1.6055 - val_loss: 10.9286 - val_mae: 2.4070\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.8264 - mae: 1.5739 - val_loss: 11.0880 - val_mae: 2.4128\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.7987 - mae: 1.5786 - val_loss: 11.0785 - val_mae: 2.4191\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.7302 - mae: 1.5656 - val_loss: 10.9120 - val_mae: 2.4021\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8656 - mae: 1.5836 - val_loss: 10.8807 - val_mae: 2.3996\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.8861 - mae: 1.6289 - val_loss: 11.1114 - val_mae: 2.4254\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.8219 - mae: 1.6141 - val_loss: 11.0681 - val_mae: 2.4079\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.7890 - mae: 1.5756 - val_loss: 10.9541 - val_mae: 2.3957\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.7124 - mae: 1.6028 - val_loss: 10.9806 - val_mae: 2.4130\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.7355 - mae: 1.5663 - val_loss: 11.0341 - val_mae: 2.4092\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.7303 - mae: 1.5764 - val_loss: 11.1002 - val_mae: 2.4196\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.6792 - mae: 1.5914 - val_loss: 10.9626 - val_mae: 2.4070\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.6344 - mae: 1.5550 - val_loss: 11.0684 - val_mae: 2.4132\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.6039 - mae: 1.5442 - val_loss: 11.1616 - val_mae: 2.4165\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.6052 - mae: 1.5726 - val_loss: 10.9988 - val_mae: 2.4036\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.5582 - mae: 1.5531 - val_loss: 11.0885 - val_mae: 2.4037\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.5259 - mae: 1.5370 - val_loss: 11.2584 - val_mae: 2.4307\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.5041 - mae: 1.5433 - val_loss: 11.2188 - val_mae: 2.4228\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.4998 - mae: 1.5298 - val_loss: 11.1000 - val_mae: 2.4036\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.5218 - mae: 1.5526 - val_loss: 10.9993 - val_mae: 2.4087\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.4732 - mae: 1.5247 - val_loss: 11.1067 - val_mae: 2.4180\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.4545 - mae: 1.5174 - val_loss: 11.1257 - val_mae: 2.4185\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.4159 - mae: 1.5329 - val_loss: 11.1295 - val_mae: 2.4252\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.4348 - mae: 1.5301 - val_loss: 11.0525 - val_mae: 2.4122\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 4.4088 - mae: 1.5276 - val_loss: 11.0666 - val_mae: 2.4113\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.3440 - mae: 1.5151 - val_loss: 11.1778 - val_mae: 2.4244\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3367 - mae: 1.5245 - val_loss: 11.1767 - val_mae: 2.4269\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3809 - mae: 1.5070 - val_loss: 11.1772 - val_mae: 2.4195\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.3114 - mae: 1.5146 - val_loss: 11.0864 - val_mae: 2.4181\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2695 - mae: 1.5069 - val_loss: 11.1642 - val_mae: 2.4198\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2551 - mae: 1.4899 - val_loss: 11.2013 - val_mae: 2.4238\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2646 - mae: 1.5144 - val_loss: 11.2353 - val_mae: 2.4256\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2355 - mae: 1.4840 - val_loss: 11.2035 - val_mae: 2.4190\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2408 - mae: 1.4969 - val_loss: 11.1643 - val_mae: 2.4221\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2282 - mae: 1.4805 - val_loss: 11.1626 - val_mae: 2.4204\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.1999 - mae: 1.4911 - val_loss: 11.2032 - val_mae: 2.4236\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.1420 - mae: 1.4706 - val_loss: 11.2857 - val_mae: 2.4284\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3197 - mae: 1.5504 - val_loss: 11.2895 - val_mae: 2.4333\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1331 - mae: 1.4754 - val_loss: 11.3099 - val_mae: 2.4399\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1027 - mae: 1.4805 - val_loss: 11.2336 - val_mae: 2.4255\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.1041 - mae: 1.4672 - val_loss: 11.1812 - val_mae: 2.4154\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1049 - mae: 1.4782 - val_loss: 11.2313 - val_mae: 2.4162\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1045 - mae: 1.4646 - val_loss: 11.2631 - val_mae: 2.4213\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.0377 - mae: 1.4549 - val_loss: 11.3065 - val_mae: 2.4371\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.0950 - mae: 1.4712 - val_loss: 11.3248 - val_mae: 2.4281\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0338 - mae: 1.4608 - val_loss: 11.4863 - val_mae: 2.4503\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9736 - mae: 1.4592 - val_loss: 11.3180 - val_mae: 2.4179\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9275 - mae: 1.4304 - val_loss: 11.2524 - val_mae: 2.4204\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9485 - mae: 1.4398 - val_loss: 11.3050 - val_mae: 2.4318\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9151 - mae: 1.4463 - val_loss: 11.3001 - val_mae: 2.4242\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9512 - mae: 1.4551 - val_loss: 11.2397 - val_mae: 2.4261\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.9104 - mae: 1.4342 - val_loss: 11.2882 - val_mae: 2.4329\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9018 - mae: 1.4458 - val_loss: 11.3267 - val_mae: 2.4365\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.8689 - mae: 1.4333 - val_loss: 11.4601 - val_mae: 2.4415\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8352 - mae: 1.4161 - val_loss: 11.3810 - val_mae: 2.4409\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8159 - mae: 1.4179 - val_loss: 11.3870 - val_mae: 2.4359\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8189 - mae: 1.4240 - val_loss: 11.3010 - val_mae: 2.4188\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.5693 - mae: 2.0810\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 28ms/step - loss: 604.0666 - mae: 22.7126 - val_loss: 494.9128 - val_mae: 20.5091\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 573.0274 - mae: 22.0447 - val_loss: 469.3896 - val_mae: 19.8728\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 545.4028 - mae: 21.4162 - val_loss: 442.7136 - val_mae: 19.2106\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 514.2977 - mae: 20.7003 - val_loss: 411.2408 - val_mae: 18.4254\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 475.4619 - mae: 19.8061 - val_loss: 373.8970 - val_mae: 17.4430\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 429.3491 - mae: 18.7054 - val_loss: 328.4550 - val_mae: 16.1998\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 372.3562 - mae: 17.2703 - val_loss: 277.2570 - val_mae: 14.7021\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 311.5591 - mae: 15.5891 - val_loss: 221.5335 - val_mae: 12.9838\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 244.7150 - mae: 13.5298 - val_loss: 167.6476 - val_mae: 11.1589\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 183.8334 - mae: 11.2689 - val_loss: 120.2531 - val_mae: 9.2873\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 131.1265 - mae: 9.1505 - val_loss: 86.6187 - val_mae: 7.8097\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 97.5443 - mae: 7.6479 - val_loss: 66.2498 - val_mae: 6.5937\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 77.1449 - mae: 6.5803 - val_loss: 54.7505 - val_mae: 5.8435\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 63.0654 - mae: 5.8174 - val_loss: 47.2237 - val_mae: 5.3811\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 53.3728 - mae: 5.2835 - val_loss: 41.2268 - val_mae: 5.0235\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 45.6744 - mae: 4.8465 - val_loss: 36.6124 - val_mae: 4.7102\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 40.3790 - mae: 4.5123 - val_loss: 33.0953 - val_mae: 4.4546\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 36.3053 - mae: 4.2584 - val_loss: 30.3747 - val_mae: 4.2248\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 32.9001 - mae: 4.0195 - val_loss: 28.1373 - val_mae: 4.0038\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 30.8239 - mae: 3.8775 - val_loss: 26.7471 - val_mae: 3.8688\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 28.9998 - mae: 3.7668 - val_loss: 26.0276 - val_mae: 3.8218\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 27.8265 - mae: 3.7043 - val_loss: 25.3891 - val_mae: 3.7702\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 26.4470 - mae: 3.6182 - val_loss: 24.5202 - val_mae: 3.6763\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 25.5571 - mae: 3.5450 - val_loss: 23.8166 - val_mae: 3.5923\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 24.7490 - mae: 3.4873 - val_loss: 23.4048 - val_mae: 3.5540\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.9401 - mae: 3.4390 - val_loss: 22.9164 - val_mae: 3.4898\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.2937 - mae: 3.3936 - val_loss: 22.6011 - val_mae: 3.4481\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 22.6158 - mae: 3.3586 - val_loss: 22.2423 - val_mae: 3.4066\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 22.0478 - mae: 3.3285 - val_loss: 21.9037 - val_mae: 3.3645\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 21.5129 - mae: 3.2954 - val_loss: 21.6723 - val_mae: 3.3376\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.0710 - mae: 3.2589 - val_loss: 21.1239 - val_mae: 3.2784\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 20.7797 - mae: 3.2015 - val_loss: 20.4654 - val_mae: 3.1841\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 20.0757 - mae: 3.1647 - val_loss: 20.5838 - val_mae: 3.2251\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 19.7291 - mae: 3.1464 - val_loss: 20.3219 - val_mae: 3.1983\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 19.3617 - mae: 3.1038 - val_loss: 19.9088 - val_mae: 3.1442\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 18.9650 - mae: 3.0640 - val_loss: 19.5003 - val_mae: 3.0872\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 18.6277 - mae: 3.0245 - val_loss: 19.3153 - val_mae: 3.0603\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 18.3083 - mae: 3.0131 - val_loss: 19.2970 - val_mae: 3.0800\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 17.9789 - mae: 2.9928 - val_loss: 19.0857 - val_mae: 3.0577\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 17.7411 - mae: 2.9564 - val_loss: 18.6843 - val_mae: 2.9918\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 17.5353 - mae: 2.9276 - val_loss: 18.4936 - val_mae: 2.9701\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 17.1302 - mae: 2.8992 - val_loss: 18.4115 - val_mae: 2.9587\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 16.9061 - mae: 2.8958 - val_loss: 18.4223 - val_mae: 2.9893\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.6453 - mae: 2.8808 - val_loss: 18.0622 - val_mae: 2.9402\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.4535 - mae: 2.8608 - val_loss: 18.0919 - val_mae: 2.9447\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.1826 - mae: 2.8272 - val_loss: 17.7066 - val_mae: 2.8838\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 16.0016 - mae: 2.8126 - val_loss: 17.5568 - val_mae: 2.8746\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.8096 - mae: 2.8179 - val_loss: 17.9515 - val_mae: 2.9310\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 15.5332 - mae: 2.7937 - val_loss: 17.5436 - val_mae: 2.8609\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.3212 - mae: 2.7616 - val_loss: 17.2908 - val_mae: 2.8357\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.1733 - mae: 2.7543 - val_loss: 17.3208 - val_mae: 2.8418\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 14.9483 - mae: 2.7381 - val_loss: 16.9817 - val_mae: 2.8040\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 14.8167 - mae: 2.7077 - val_loss: 16.8814 - val_mae: 2.7830\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.6186 - mae: 2.6958 - val_loss: 16.8634 - val_mae: 2.7801\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.4513 - mae: 2.6886 - val_loss: 16.7726 - val_mae: 2.7762\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.3236 - mae: 2.6768 - val_loss: 16.6343 - val_mae: 2.7698\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 14.1990 - mae: 2.6540 - val_loss: 16.3457 - val_mae: 2.7420\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 14.0253 - mae: 2.6405 - val_loss: 16.4516 - val_mae: 2.7418\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 13.9051 - mae: 2.6489 - val_loss: 16.5546 - val_mae: 2.7466\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 13.7793 - mae: 2.6465 - val_loss: 16.3346 - val_mae: 2.7492\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 13.7739 - mae: 2.6523 - val_loss: 16.3171 - val_mae: 2.7510\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 13.6365 - mae: 2.6148 - val_loss: 15.9203 - val_mae: 2.7035\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 13.3493 - mae: 2.5775 - val_loss: 15.9405 - val_mae: 2.7067\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 13.2609 - mae: 2.5784 - val_loss: 16.0645 - val_mae: 2.7216\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 13.1650 - mae: 2.5673 - val_loss: 15.8707 - val_mae: 2.7147\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 13.0259 - mae: 2.5623 - val_loss: 15.9079 - val_mae: 2.7232\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 12.9035 - mae: 2.5601 - val_loss: 15.8336 - val_mae: 2.7192\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 12.9738 - mae: 2.5411 - val_loss: 15.4525 - val_mae: 2.6800\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 12.7148 - mae: 2.5175 - val_loss: 15.5979 - val_mae: 2.7062\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 12.6391 - mae: 2.5400 - val_loss: 15.7572 - val_mae: 2.7225\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 12.5318 - mae: 2.5428 - val_loss: 15.6115 - val_mae: 2.7098\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 12.4607 - mae: 2.5099 - val_loss: 15.1718 - val_mae: 2.6719\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 12.4015 - mae: 2.4867 - val_loss: 14.9861 - val_mae: 2.6568\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 12.1697 - mae: 2.4796 - val_loss: 15.4882 - val_mae: 2.7136\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 12.0961 - mae: 2.5048 - val_loss: 15.4729 - val_mae: 2.7188\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 11.9922 - mae: 2.4881 - val_loss: 15.4125 - val_mae: 2.7117\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 11.9191 - mae: 2.4791 - val_loss: 15.2018 - val_mae: 2.6997\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 11.9308 - mae: 2.4831 - val_loss: 15.4232 - val_mae: 2.7098\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 11.7912 - mae: 2.4492 - val_loss: 14.9417 - val_mae: 2.6653\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 11.6673 - mae: 2.4417 - val_loss: 14.9588 - val_mae: 2.6836\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 11.5277 - mae: 2.4394 - val_loss: 14.9508 - val_mae: 2.6826\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 11.4739 - mae: 2.4226 - val_loss: 14.7042 - val_mae: 2.6598\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.4023 - mae: 2.4155 - val_loss: 14.6561 - val_mae: 2.6683\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.3550 - mae: 2.4009 - val_loss: 14.6129 - val_mae: 2.6606\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.2989 - mae: 2.4210 - val_loss: 14.7569 - val_mae: 2.6845\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.1657 - mae: 2.4053 - val_loss: 14.6600 - val_mae: 2.6646\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 11.0894 - mae: 2.4019 - val_loss: 14.4577 - val_mae: 2.6629\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.9549 - mae: 2.3677 - val_loss: 14.2966 - val_mae: 2.6289\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 10.9296 - mae: 2.3665 - val_loss: 14.5080 - val_mae: 2.6551\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.8933 - mae: 2.3714 - val_loss: 14.4146 - val_mae: 2.6535\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.9144 - mae: 2.3903 - val_loss: 14.7177 - val_mae: 2.6983\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.6354 - mae: 2.3550 - val_loss: 14.0365 - val_mae: 2.6388\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.6346 - mae: 2.3315 - val_loss: 13.8920 - val_mae: 2.6143\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.6191 - mae: 2.3412 - val_loss: 14.3003 - val_mae: 2.6529\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.4064 - mae: 2.3260 - val_loss: 14.2003 - val_mae: 2.6578\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.4351 - mae: 2.3263 - val_loss: 14.0792 - val_mae: 2.6450\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.3706 - mae: 2.3091 - val_loss: 13.9276 - val_mae: 2.6212\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.2624 - mae: 2.3020 - val_loss: 13.8601 - val_mae: 2.6297\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.2321 - mae: 2.3017 - val_loss: 14.0350 - val_mae: 2.6453\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.1239 - mae: 2.2877 - val_loss: 13.8124 - val_mae: 2.6129\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.0619 - mae: 2.2755 - val_loss: 13.7363 - val_mae: 2.6150\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.0249 - mae: 2.2681 - val_loss: 13.6644 - val_mae: 2.6071\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.8981 - mae: 2.2685 - val_loss: 13.8748 - val_mae: 2.6300\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.8850 - mae: 2.2813 - val_loss: 13.8660 - val_mae: 2.6375\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.8313 - mae: 2.2609 - val_loss: 13.6747 - val_mae: 2.6075\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.7422 - mae: 2.2587 - val_loss: 13.8241 - val_mae: 2.6433\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.7010 - mae: 2.2612 - val_loss: 13.7489 - val_mae: 2.6277\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.6416 - mae: 2.2525 - val_loss: 13.6483 - val_mae: 2.6149\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.6162 - mae: 2.2465 - val_loss: 13.5754 - val_mae: 2.6158\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.5217 - mae: 2.2299 - val_loss: 13.2263 - val_mae: 2.5706\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.4582 - mae: 2.2149 - val_loss: 13.3538 - val_mae: 2.6023\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.4690 - mae: 2.2443 - val_loss: 13.6068 - val_mae: 2.6342\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.3662 - mae: 2.2337 - val_loss: 13.6545 - val_mae: 2.6152\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.4028 - mae: 2.2171 - val_loss: 13.4442 - val_mae: 2.5975\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.3446 - mae: 2.2266 - val_loss: 13.5625 - val_mae: 2.6243\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.2262 - mae: 2.1985 - val_loss: 13.0572 - val_mae: 2.5779\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.1228 - mae: 2.1770 - val_loss: 13.0474 - val_mae: 2.5619\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.0740 - mae: 2.1825 - val_loss: 13.1693 - val_mae: 2.5767\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.0414 - mae: 2.1839 - val_loss: 13.2344 - val_mae: 2.5805\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.9508 - mae: 2.1783 - val_loss: 13.0193 - val_mae: 2.5755\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.9698 - mae: 2.1686 - val_loss: 13.1190 - val_mae: 2.5761\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.9151 - mae: 2.1792 - val_loss: 13.2708 - val_mae: 2.6024\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.8601 - mae: 2.1810 - val_loss: 13.2265 - val_mae: 2.5977\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.7123 - mae: 2.1538 - val_loss: 12.7007 - val_mae: 2.5470\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.7581 - mae: 2.1381 - val_loss: 12.7387 - val_mae: 2.5568\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.6867 - mae: 2.1373 - val_loss: 12.7948 - val_mae: 2.5588\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.5996 - mae: 2.1386 - val_loss: 13.0272 - val_mae: 2.5704\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.6081 - mae: 2.1553 - val_loss: 13.1078 - val_mae: 2.5913\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.5926 - mae: 2.1405 - val_loss: 12.8026 - val_mae: 2.5626\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.4735 - mae: 2.1265 - val_loss: 12.6398 - val_mae: 2.5439\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.4763 - mae: 2.1142 - val_loss: 12.4859 - val_mae: 2.5390\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.3812 - mae: 2.1234 - val_loss: 13.0131 - val_mae: 2.5972\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.3290 - mae: 2.1241 - val_loss: 12.8499 - val_mae: 2.5654\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.2896 - mae: 2.1114 - val_loss: 12.6674 - val_mae: 2.5466\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.3429 - mae: 2.1141 - val_loss: 12.4260 - val_mae: 2.5411\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.1565 - mae: 2.0880 - val_loss: 12.5553 - val_mae: 2.5349\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.1267 - mae: 2.0936 - val_loss: 12.6793 - val_mae: 2.5534\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.1236 - mae: 2.0951 - val_loss: 12.6399 - val_mae: 2.5504\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.0652 - mae: 2.0935 - val_loss: 12.7988 - val_mae: 2.5763\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.0430 - mae: 2.1016 - val_loss: 12.6273 - val_mae: 2.5481\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.9267 - mae: 2.0762 - val_loss: 12.3431 - val_mae: 2.5186\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.9239 - mae: 2.0598 - val_loss: 11.9369 - val_mae: 2.4912\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.8634 - mae: 2.0545 - val_loss: 12.2956 - val_mae: 2.5322\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.8007 - mae: 2.0580 - val_loss: 12.2861 - val_mae: 2.5210\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.8262 - mae: 2.0643 - val_loss: 12.2128 - val_mae: 2.5370\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.6790 - mae: 2.0468 - val_loss: 12.3447 - val_mae: 2.5311\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.6723 - mae: 2.0463 - val_loss: 12.1776 - val_mae: 2.5135\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.6375 - mae: 2.0363 - val_loss: 12.2589 - val_mae: 2.5191\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.5729 - mae: 2.0255 - val_loss: 12.0541 - val_mae: 2.4971\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.5197 - mae: 2.0222 - val_loss: 12.1743 - val_mae: 2.5142\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.4556 - mae: 2.0207 - val_loss: 12.1207 - val_mae: 2.5038\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.3955 - mae: 2.0192 - val_loss: 11.9964 - val_mae: 2.5010\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.3421 - mae: 2.0017 - val_loss: 11.7136 - val_mae: 2.4575\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.3773 - mae: 1.9952 - val_loss: 11.7658 - val_mae: 2.4660\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.2367 - mae: 2.0002 - val_loss: 12.0387 - val_mae: 2.5284\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.3285 - mae: 2.0239 - val_loss: 12.1844 - val_mae: 2.5404\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.1436 - mae: 1.9804 - val_loss: 11.5817 - val_mae: 2.4488\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.1339 - mae: 1.9744 - val_loss: 11.6280 - val_mae: 2.4544\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.0618 - mae: 1.9570 - val_loss: 11.4318 - val_mae: 2.4390\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.0605 - mae: 1.9658 - val_loss: 11.8517 - val_mae: 2.5037\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.0014 - mae: 1.9716 - val_loss: 11.7700 - val_mae: 2.4862\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.0419 - mae: 1.9652 - val_loss: 11.2595 - val_mae: 2.4252\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.9978 - mae: 1.9518 - val_loss: 11.6765 - val_mae: 2.4598\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.9496 - mae: 1.9634 - val_loss: 11.7227 - val_mae: 2.4961\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.9249 - mae: 1.9470 - val_loss: 11.3104 - val_mae: 2.4181\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8336 - mae: 1.9310 - val_loss: 11.7416 - val_mae: 2.4882\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.8415 - mae: 1.9572 - val_loss: 11.6853 - val_mae: 2.5098\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.7436 - mae: 1.9344 - val_loss: 11.3257 - val_mae: 2.4356\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.6813 - mae: 1.9210 - val_loss: 11.3269 - val_mae: 2.4501\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.6435 - mae: 1.9153 - val_loss: 11.4081 - val_mae: 2.4585\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.5662 - mae: 1.9003 - val_loss: 11.4985 - val_mae: 2.4681\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.5769 - mae: 1.9087 - val_loss: 11.5961 - val_mae: 2.4784\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.4621 - mae: 1.8989 - val_loss: 11.2637 - val_mae: 2.4484\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4589 - mae: 1.8922 - val_loss: 11.2315 - val_mae: 2.4420\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.4527 - mae: 1.8960 - val_loss: 11.3412 - val_mae: 2.4618\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.4053 - mae: 1.8932 - val_loss: 11.3978 - val_mae: 2.4755\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3929 - mae: 1.8792 - val_loss: 10.9894 - val_mae: 2.4061\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3035 - mae: 1.8667 - val_loss: 11.2004 - val_mae: 2.4403\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3404 - mae: 1.8754 - val_loss: 11.5435 - val_mae: 2.5038\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.2442 - mae: 1.8755 - val_loss: 11.2535 - val_mae: 2.4513\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.2173 - mae: 1.8568 - val_loss: 10.9556 - val_mae: 2.3959\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1892 - mae: 1.8509 - val_loss: 11.2877 - val_mae: 2.4625\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.1523 - mae: 1.8473 - val_loss: 11.1300 - val_mae: 2.4302\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1346 - mae: 1.8385 - val_loss: 11.0568 - val_mae: 2.4225\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.1028 - mae: 1.8501 - val_loss: 11.2455 - val_mae: 2.4575\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.1162 - mae: 1.8574 - val_loss: 11.0445 - val_mae: 2.4397\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.0131 - mae: 1.8236 - val_loss: 10.9348 - val_mae: 2.4106\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.9718 - mae: 1.8177 - val_loss: 10.9580 - val_mae: 2.4191\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.9276 - mae: 1.8136 - val_loss: 11.0052 - val_mae: 2.4286\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.9125 - mae: 1.8186 - val_loss: 10.9697 - val_mae: 2.4259\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.9165 - mae: 1.8118 - val_loss: 10.9777 - val_mae: 2.4234\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.8737 - mae: 1.8136 - val_loss: 11.1201 - val_mae: 2.4578\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.8715 - mae: 1.8131 - val_loss: 11.0173 - val_mae: 2.4256\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.8797 - mae: 1.8205 - val_loss: 11.3390 - val_mae: 2.4818\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.7358 - mae: 1.7980 - val_loss: 10.6955 - val_mae: 2.3695\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.8957 - mae: 1.8046 - val_loss: 10.7968 - val_mae: 2.3836\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.7295 - mae: 1.7956 - val_loss: 10.9771 - val_mae: 2.4349\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.7281 - mae: 1.7869 - val_loss: 10.6960 - val_mae: 2.3781\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 5.7723 - mae: 1.7963 - val_loss: 11.1261 - val_mae: 2.4532\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 5.6828 - mae: 1.7997 - val_loss: 10.6664 - val_mae: 2.3730\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 5.6459 - mae: 1.7781 - val_loss: 10.7487 - val_mae: 2.3794\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.6101 - mae: 1.7813 - val_loss: 10.9615 - val_mae: 2.4283\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 5.6289 - mae: 1.7924 - val_loss: 11.0034 - val_mae: 2.4266\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.5828 - mae: 1.7676 - val_loss: 10.8468 - val_mae: 2.3809\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.6029 - mae: 1.7737 - val_loss: 10.9268 - val_mae: 2.4208\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.5602 - mae: 1.7784 - val_loss: 11.0922 - val_mae: 2.4205\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.5124 - mae: 1.7659 - val_loss: 10.8047 - val_mae: 2.3900\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.4179 - mae: 1.7582 - val_loss: 10.8487 - val_mae: 2.4051\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.5079 - mae: 1.7560 - val_loss: 10.6268 - val_mae: 2.3537\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.4219 - mae: 1.7471 - val_loss: 11.3170 - val_mae: 2.4673\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.3893 - mae: 1.7598 - val_loss: 10.8389 - val_mae: 2.3780\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.3331 - mae: 1.7365 - val_loss: 10.9380 - val_mae: 2.4047\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.2863 - mae: 1.7323 - val_loss: 10.7831 - val_mae: 2.3803\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.3168 - mae: 1.7264 - val_loss: 10.7621 - val_mae: 2.3842\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.2312 - mae: 1.7220 - val_loss: 10.7278 - val_mae: 2.3745\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.1989 - mae: 1.7172 - val_loss: 10.9205 - val_mae: 2.3910\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.2150 - mae: 1.7197 - val_loss: 10.9901 - val_mae: 2.3912\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.1909 - mae: 1.7166 - val_loss: 10.6945 - val_mae: 2.3470\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 5.1778 - mae: 1.7189 - val_loss: 11.0765 - val_mae: 2.4136\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.1127 - mae: 1.7068 - val_loss: 10.7285 - val_mae: 2.3606\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.1413 - mae: 1.7015 - val_loss: 10.7852 - val_mae: 2.3692\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.1629 - mae: 1.7218 - val_loss: 11.1341 - val_mae: 2.4280\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.0511 - mae: 1.6888 - val_loss: 10.5074 - val_mae: 2.3147\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.0871 - mae: 1.6897 - val_loss: 10.6615 - val_mae: 2.3389\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.0676 - mae: 1.7015 - val_loss: 11.0413 - val_mae: 2.4070\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.0463 - mae: 1.7029 - val_loss: 10.8387 - val_mae: 2.3740\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9425 - mae: 1.6635 - val_loss: 10.5858 - val_mae: 2.3177\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9497 - mae: 1.6616 - val_loss: 10.8847 - val_mae: 2.3826\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.9331 - mae: 1.6758 - val_loss: 10.6839 - val_mae: 2.3468\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8924 - mae: 1.6609 - val_loss: 10.7219 - val_mae: 2.3532\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8596 - mae: 1.6637 - val_loss: 10.7391 - val_mae: 2.3619\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8284 - mae: 1.6648 - val_loss: 10.7851 - val_mae: 2.3514\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8447 - mae: 1.6692 - val_loss: 10.7311 - val_mae: 2.3479\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7926 - mae: 1.6555 - val_loss: 10.8738 - val_mae: 2.3451\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7926 - mae: 1.6451 - val_loss: 10.9288 - val_mae: 2.3666\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7450 - mae: 1.6341 - val_loss: 10.7617 - val_mae: 2.3367\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7293 - mae: 1.6266 - val_loss: 10.6754 - val_mae: 2.3461\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6808 - mae: 1.6402 - val_loss: 11.0413 - val_mae: 2.4092\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.6462 - mae: 1.6250 - val_loss: 10.7508 - val_mae: 2.3393\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7367 - mae: 1.6316 - val_loss: 10.7737 - val_mae: 2.3440\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.6447 - mae: 1.6151 - val_loss: 10.5550 - val_mae: 2.3162\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.6153 - mae: 1.6152 - val_loss: 10.9160 - val_mae: 2.3643\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6136 - mae: 1.6160 - val_loss: 10.8436 - val_mae: 2.3450\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.5419 - mae: 1.6103 - val_loss: 11.0305 - val_mae: 2.3807\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.6189 - mae: 1.6100 - val_loss: 10.5847 - val_mae: 2.3183\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.5211 - mae: 1.5932 - val_loss: 10.9004 - val_mae: 2.3594\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.5423 - mae: 1.6090 - val_loss: 10.5982 - val_mae: 2.3328\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4962 - mae: 1.6055 - val_loss: 10.9470 - val_mae: 2.3618\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.4610 - mae: 1.5828 - val_loss: 10.6159 - val_mae: 2.3155\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.4510 - mae: 1.5888 - val_loss: 10.9954 - val_mae: 2.3662\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.3946 - mae: 1.5783 - val_loss: 10.8859 - val_mae: 2.3423\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3864 - mae: 1.5668 - val_loss: 10.7955 - val_mae: 2.3325\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.3951 - mae: 1.5917 - val_loss: 10.9325 - val_mae: 2.3596\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3535 - mae: 1.5729 - val_loss: 10.8518 - val_mae: 2.3334\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3283 - mae: 1.5610 - val_loss: 10.9206 - val_mae: 2.3528\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3218 - mae: 1.5648 - val_loss: 10.6911 - val_mae: 2.3223\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2661 - mae: 1.5494 - val_loss: 10.8734 - val_mae: 2.3391\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2632 - mae: 1.5587 - val_loss: 10.9414 - val_mae: 2.3616\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2334 - mae: 1.5468 - val_loss: 10.7549 - val_mae: 2.3194\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2183 - mae: 1.5466 - val_loss: 10.9978 - val_mae: 2.3598\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.1971 - mae: 1.5471 - val_loss: 10.9278 - val_mae: 2.3545\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1543 - mae: 1.5283 - val_loss: 10.9150 - val_mae: 2.3586\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1978 - mae: 1.5566 - val_loss: 11.1698 - val_mae: 2.3894\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1819 - mae: 1.5337 - val_loss: 10.6186 - val_mae: 2.3037\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1069 - mae: 1.5249 - val_loss: 11.2078 - val_mae: 2.3725\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0962 - mae: 1.5246 - val_loss: 10.9296 - val_mae: 2.3506\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0833 - mae: 1.5341 - val_loss: 11.0306 - val_mae: 2.3687\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1451 - mae: 1.5455 - val_loss: 11.0538 - val_mae: 2.3595\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.0711 - mae: 1.5355 - val_loss: 10.9168 - val_mae: 2.3578\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.0803 - mae: 1.5448 - val_loss: 11.1091 - val_mae: 2.3636\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1370 - mae: 1.5124 - val_loss: 10.8889 - val_mae: 2.3364\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9613 - mae: 1.5073 - val_loss: 11.4070 - val_mae: 2.4122\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9374 - mae: 1.4964 - val_loss: 10.8042 - val_mae: 2.3231\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.9564 - mae: 1.4898 - val_loss: 11.2125 - val_mae: 2.3868\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.9037 - mae: 1.4908 - val_loss: 11.1733 - val_mae: 2.3675\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.9345 - mae: 1.5204 - val_loss: 11.2003 - val_mae: 2.3787\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3.8647 - mae: 1.4770 - val_loss: 11.0193 - val_mae: 2.3511\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.8639 - mae: 1.4822 - val_loss: 11.2229 - val_mae: 2.3780\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3.8129 - mae: 1.4806 - val_loss: 11.0916 - val_mae: 2.3562\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.8810 - mae: 1.4872 - val_loss: 11.1639 - val_mae: 2.3663\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.8596 - mae: 1.4809 - val_loss: 11.0608 - val_mae: 2.3665\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.8690 - mae: 1.5047 - val_loss: 11.4204 - val_mae: 2.4084\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3.8168 - mae: 1.4637 - val_loss: 11.0840 - val_mae: 2.3618\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.7772 - mae: 1.4604 - val_loss: 11.2108 - val_mae: 2.3694\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.7214 - mae: 1.4700 - val_loss: 11.1721 - val_mae: 2.3872\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.6947 - mae: 1.4573 - val_loss: 11.4642 - val_mae: 2.3864\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.7342 - mae: 1.4601 - val_loss: 11.3811 - val_mae: 2.3873\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.6340 - mae: 1.4459 - val_loss: 11.1433 - val_mae: 2.3699\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.6702 - mae: 1.4286 - val_loss: 11.3037 - val_mae: 2.3767\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.6450 - mae: 1.4531 - val_loss: 11.3716 - val_mae: 2.4013\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.6669 - mae: 1.4455 - val_loss: 11.0825 - val_mae: 2.3657\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.6709 - mae: 1.4616 - val_loss: 11.3486 - val_mae: 2.3933\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.5567 - mae: 1.4369 - val_loss: 11.0867 - val_mae: 2.3577\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.5796 - mae: 1.4206 - val_loss: 11.4927 - val_mae: 2.4196\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.5458 - mae: 1.4261 - val_loss: 11.0998 - val_mae: 2.3732\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.4732 - mae: 1.4041 - val_loss: 11.4617 - val_mae: 2.4052\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.4801 - mae: 1.4155 - val_loss: 11.1004 - val_mae: 2.3769\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.5129 - mae: 1.4144 - val_loss: 11.2865 - val_mae: 2.3937\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 3.4815 - mae: 1.4056 - val_loss: 11.2416 - val_mae: 2.3806\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.4471 - mae: 1.3892 - val_loss: 11.4580 - val_mae: 2.4073\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.9890 - mae: 2.2091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mae_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM4VhR_0UTgp",
        "outputId": "2d6bb7a5-2fb5-44fa-97b8-37a90b04b3b5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0999101996421814"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4fold 오차:2.09"
      ],
      "metadata": {
        "id": "lEJ8vDUqT_vz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJjMZ2zM9FPH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data                           # no tensorflow\n",
        "\n",
        "# 데이터를 다운받습니다.(훈련셋 80%, 테스트셋 20%)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2,\n",
        "                                                 seed=777)"
      ],
      "metadata": {
        "id": "HfpnPUqd9FMf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 데이터 표준화\n",
        "mean = np.mean(X_train, axis = 0)\n",
        "std = np.std(X_train, axis = 0)\n",
        "# 여기까진 전부 동일합니다.\n",
        "x_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std"
      ],
      "metadata": {
        "id": "nSG7s1NbVSy9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# 3-fold 로 나눠서 검증데이터셋 사용하여 학습\n",
        "k =5\n",
        "\n",
        "kfold = KFold(n_splits=k)\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation='relu', input_shape=(13,)))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(1))   # activation = linear\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 각 모델의 평가 정보 담는 리스트 선언\n",
        "mae_list = []\n",
        "\n",
        "# k번 학습 및 평가\n",
        "# k번 진행합니다.\n",
        "for train_index, val_index in kfold.split(x_train):\n",
        "    # 해당 인덱스는 무작위로 생성됩니다.\n",
        "    # 무작위로 생성해주는 것은 과대적합을 피할 수 있는 좋은 방법입니다.\n",
        "    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # 모델을 불러옵니다.\n",
        "    model = get_model()\n",
        "\n",
        "    model.fit(x_train_fold, y_train_fold, epochs = 300, validation_data = (x_val_fold, y_val_fold))\n",
        "\n",
        "    _, test_mae = model.evaluate(X_test, y_test)\n",
        "    mae_list.append(test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBbkG6449FHT",
        "outputId": "c0a329fa-3b58-4704-fdff-1efb5b0ae6a2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 20ms/step - loss: 586.8054 - mae: 22.2935 - val_loss: 529.1309 - val_mae: 21.3925\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 554.3134 - mae: 21.6075 - val_loss: 500.3708 - val_mae: 20.7387\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 520.0305 - mae: 20.8603 - val_loss: 466.7335 - val_mae: 19.9463\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 479.4054 - mae: 19.9381 - val_loss: 426.8930 - val_mae: 18.9499\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 430.6929 - mae: 18.7436 - val_loss: 377.3108 - val_mae: 17.6363\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 371.7789 - mae: 17.2156 - val_loss: 319.7280 - val_mae: 15.9865\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 304.7091 - mae: 15.3324 - val_loss: 257.5397 - val_mae: 13.9836\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 235.6427 - mae: 13.1053 - val_loss: 192.9210 - val_mae: 11.6250\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 169.4594 - mae: 10.6905 - val_loss: 140.0279 - val_mae: 9.5541\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 118.8411 - mae: 8.6503 - val_loss: 102.9254 - val_mae: 7.9281\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 87.7328 - mae: 7.3655 - val_loss: 82.0528 - val_mae: 6.9540\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 71.8930 - mae: 6.6311 - val_loss: 67.8652 - val_mae: 6.1479\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 58.0753 - mae: 5.9664 - val_loss: 58.1210 - val_mae: 5.5775\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 48.6738 - mae: 5.4235 - val_loss: 49.9348 - val_mae: 5.0961\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 41.1486 - mae: 4.9398 - val_loss: 43.8880 - val_mae: 4.7032\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 35.7484 - mae: 4.5738 - val_loss: 39.8283 - val_mae: 4.4577\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31.9112 - mae: 4.2482 - val_loss: 36.7254 - val_mae: 4.2608\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 29.1723 - mae: 4.0376 - val_loss: 34.5614 - val_mae: 4.1745\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 27.3391 - mae: 3.8986 - val_loss: 33.2980 - val_mae: 4.1169\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 26.0931 - mae: 3.7890 - val_loss: 32.4262 - val_mae: 4.0666\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 24.9966 - mae: 3.7089 - val_loss: 31.6986 - val_mae: 4.0520\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 24.0907 - mae: 3.6406 - val_loss: 31.1674 - val_mae: 4.0251\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 23.2719 - mae: 3.5586 - val_loss: 30.6462 - val_mae: 3.9766\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 22.5177 - mae: 3.4632 - val_loss: 30.3087 - val_mae: 3.9392\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 21.8196 - mae: 3.3957 - val_loss: 30.0483 - val_mae: 3.9439\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 21.2427 - mae: 3.3435 - val_loss: 29.5222 - val_mae: 3.9191\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 20.6394 - mae: 3.2875 - val_loss: 29.1762 - val_mae: 3.9042\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 20.1693 - mae: 3.2274 - val_loss: 29.0046 - val_mae: 3.8829\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 19.7408 - mae: 3.1703 - val_loss: 28.7831 - val_mae: 3.8751\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 19.3929 - mae: 3.1273 - val_loss: 28.4610 - val_mae: 3.8399\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 18.8791 - mae: 3.0940 - val_loss: 27.8872 - val_mae: 3.8242\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 18.3257 - mae: 3.0532 - val_loss: 27.8924 - val_mae: 3.8243\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 18.0110 - mae: 3.0193 - val_loss: 27.5972 - val_mae: 3.8073\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 17.5924 - mae: 2.9901 - val_loss: 27.3491 - val_mae: 3.7967\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 17.3081 - mae: 2.9628 - val_loss: 27.2567 - val_mae: 3.7957\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 16.9632 - mae: 2.9325 - val_loss: 26.9444 - val_mae: 3.7817\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 16.6404 - mae: 2.8906 - val_loss: 26.7652 - val_mae: 3.7439\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 16.3813 - mae: 2.8560 - val_loss: 26.6509 - val_mae: 3.7433\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 16.1085 - mae: 2.8324 - val_loss: 26.2032 - val_mae: 3.7255\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.7831 - mae: 2.8189 - val_loss: 25.9864 - val_mae: 3.7367\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.5250 - mae: 2.7984 - val_loss: 25.8355 - val_mae: 3.7109\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 15.2983 - mae: 2.7486 - val_loss: 25.5570 - val_mae: 3.6497\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.1566 - mae: 2.7324 - val_loss: 25.2994 - val_mae: 3.6580\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.9136 - mae: 2.7192 - val_loss: 25.0940 - val_mae: 3.6629\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.6097 - mae: 2.6984 - val_loss: 24.8753 - val_mae: 3.6457\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.4314 - mae: 2.6689 - val_loss: 24.9459 - val_mae: 3.6415\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.3319 - mae: 2.6613 - val_loss: 24.5053 - val_mae: 3.6231\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.9869 - mae: 2.6305 - val_loss: 24.4942 - val_mae: 3.6206\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.8978 - mae: 2.6311 - val_loss: 24.4516 - val_mae: 3.6281\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.6788 - mae: 2.6067 - val_loss: 24.0097 - val_mae: 3.5650\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.5464 - mae: 2.5754 - val_loss: 23.7527 - val_mae: 3.5348\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4092 - mae: 2.5529 - val_loss: 23.8258 - val_mae: 3.5507\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.1636 - mae: 2.5344 - val_loss: 23.3727 - val_mae: 3.5270\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9509 - mae: 2.5206 - val_loss: 23.0110 - val_mae: 3.5147\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.7819 - mae: 2.5139 - val_loss: 22.9738 - val_mae: 3.5099\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.7386 - mae: 2.4845 - val_loss: 23.2169 - val_mae: 3.5178\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.5775 - mae: 2.4865 - val_loss: 23.0060 - val_mae: 3.5311\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.3759 - mae: 2.4722 - val_loss: 22.5391 - val_mae: 3.4837\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2898 - mae: 2.4375 - val_loss: 22.5395 - val_mae: 3.4583\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0703 - mae: 2.4147 - val_loss: 22.4855 - val_mae: 3.4647\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.9595 - mae: 2.4233 - val_loss: 22.5704 - val_mae: 3.4847\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8468 - mae: 2.4197 - val_loss: 22.4300 - val_mae: 3.4717\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7121 - mae: 2.3963 - val_loss: 22.1871 - val_mae: 3.4448\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5541 - mae: 2.3889 - val_loss: 22.1304 - val_mae: 3.4569\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5944 - mae: 2.4238 - val_loss: 22.1165 - val_mae: 3.4716\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.4886 - mae: 2.4165 - val_loss: 21.4984 - val_mae: 3.4170\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.6000 - mae: 2.4446 - val_loss: 21.3779 - val_mae: 3.4173\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1925 - mae: 2.3732 - val_loss: 22.2297 - val_mae: 3.4396\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.6384 - mae: 2.3664 - val_loss: 22.4310 - val_mae: 3.4346\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.2872 - mae: 2.3314 - val_loss: 21.2950 - val_mae: 3.3838\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.0211 - mae: 2.3627 - val_loss: 20.9806 - val_mae: 3.3597\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8612 - mae: 2.3473 - val_loss: 20.7728 - val_mae: 3.3583\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.8853 - mae: 2.3595 - val_loss: 20.7572 - val_mae: 3.3798\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7767 - mae: 2.3419 - val_loss: 20.2169 - val_mae: 3.3275\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.6158 - mae: 2.3021 - val_loss: 20.2101 - val_mae: 3.3153\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5055 - mae: 2.2876 - val_loss: 20.4220 - val_mae: 3.3319\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.4151 - mae: 2.2815 - val_loss: 20.5090 - val_mae: 3.3283\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3194 - mae: 2.2669 - val_loss: 20.1573 - val_mae: 3.3006\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3214 - mae: 2.2820 - val_loss: 20.3611 - val_mae: 3.3331\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.3086 - mae: 2.2855 - val_loss: 19.9978 - val_mae: 3.2852\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.0934 - mae: 2.2568 - val_loss: 20.1051 - val_mae: 3.3149\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.1133 - mae: 2.2625 - val_loss: 19.9653 - val_mae: 3.3033\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.9842 - mae: 2.2475 - val_loss: 19.5523 - val_mae: 3.2709\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.9950 - mae: 2.2549 - val_loss: 19.4427 - val_mae: 3.2562\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.9451 - mae: 2.2212 - val_loss: 20.3019 - val_mae: 3.2694\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.0477 - mae: 2.2261 - val_loss: 20.3694 - val_mae: 3.3023\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.8824 - mae: 2.2269 - val_loss: 19.5480 - val_mae: 3.2558\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7173 - mae: 2.2148 - val_loss: 19.4323 - val_mae: 3.2518\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.6370 - mae: 2.1997 - val_loss: 19.4488 - val_mae: 3.2530\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.6175 - mae: 2.2109 - val_loss: 19.3132 - val_mae: 3.2672\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4744 - mae: 2.1914 - val_loss: 19.3953 - val_mae: 3.2458\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.4556 - mae: 2.1860 - val_loss: 19.3596 - val_mae: 3.2482\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4096 - mae: 2.1914 - val_loss: 19.0730 - val_mae: 3.2299\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3743 - mae: 2.1868 - val_loss: 19.2192 - val_mae: 3.2370\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3998 - mae: 2.1832 - val_loss: 18.9189 - val_mae: 3.2105\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3107 - mae: 2.1919 - val_loss: 19.1810 - val_mae: 3.2522\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.2353 - mae: 2.1893 - val_loss: 19.2283 - val_mae: 3.2314\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.3107 - mae: 2.1555 - val_loss: 18.8821 - val_mae: 3.1879\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.1182 - mae: 2.1414 - val_loss: 19.0830 - val_mae: 3.2278\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.1603 - mae: 2.1556 - val_loss: 19.2524 - val_mae: 3.2263\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1468 - mae: 2.1535 - val_loss: 18.5603 - val_mae: 3.1938\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.9705 - mae: 2.1298 - val_loss: 18.6454 - val_mae: 3.1738\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8739 - mae: 2.1183 - val_loss: 18.3911 - val_mae: 3.1747\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.1659 - mae: 2.1628 - val_loss: 17.8758 - val_mae: 3.1619\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8985 - mae: 2.1292 - val_loss: 18.2873 - val_mae: 3.1871\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7406 - mae: 2.1166 - val_loss: 18.5853 - val_mae: 3.1823\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.7526 - mae: 2.1085 - val_loss: 18.5230 - val_mae: 3.1696\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.6958 - mae: 2.1398 - val_loss: 18.2962 - val_mae: 3.1550\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6166 - mae: 2.1112 - val_loss: 18.1838 - val_mae: 3.1091\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5823 - mae: 2.1004 - val_loss: 18.3033 - val_mae: 3.1310\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5354 - mae: 2.1065 - val_loss: 18.0337 - val_mae: 3.1059\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.4278 - mae: 2.0890 - val_loss: 17.9108 - val_mae: 3.1064\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4289 - mae: 2.1105 - val_loss: 18.0714 - val_mae: 3.1499\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.3880 - mae: 2.0896 - val_loss: 17.7379 - val_mae: 3.1026\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3185 - mae: 2.0592 - val_loss: 17.7851 - val_mae: 3.1132\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2503 - mae: 2.0476 - val_loss: 17.7680 - val_mae: 3.0955\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1521 - mae: 2.0372 - val_loss: 18.1816 - val_mae: 3.1181\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.2440 - mae: 2.0734 - val_loss: 18.1640 - val_mae: 3.1178\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.0477 - mae: 2.0398 - val_loss: 17.8892 - val_mae: 3.0722\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1352 - mae: 2.0176 - val_loss: 18.0057 - val_mae: 3.0629\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9479 - mae: 2.0092 - val_loss: 17.7364 - val_mae: 3.0782\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1866 - mae: 2.0734 - val_loss: 17.7015 - val_mae: 3.1327\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2353 - mae: 2.0512 - val_loss: 17.7236 - val_mae: 3.0511\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9441 - mae: 2.0042 - val_loss: 17.3482 - val_mae: 3.0319\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8273 - mae: 2.0106 - val_loss: 17.4008 - val_mae: 3.0404\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7681 - mae: 1.9993 - val_loss: 17.4285 - val_mae: 3.0372\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7499 - mae: 1.9849 - val_loss: 17.4927 - val_mae: 3.0433\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6696 - mae: 1.9904 - val_loss: 17.5146 - val_mae: 3.0461\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5824 - mae: 1.9818 - val_loss: 17.2429 - val_mae: 3.0385\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.5376 - mae: 1.9709 - val_loss: 17.1786 - val_mae: 3.0248\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.4685 - mae: 1.9634 - val_loss: 17.2052 - val_mae: 3.0143\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.4307 - mae: 1.9689 - val_loss: 17.2941 - val_mae: 3.0137\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.4526 - mae: 1.9395 - val_loss: 17.0508 - val_mae: 2.9722\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3889 - mae: 1.9498 - val_loss: 17.1250 - val_mae: 3.0149\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.3416 - mae: 1.9545 - val_loss: 17.0614 - val_mae: 2.9842\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2231 - mae: 1.9266 - val_loss: 16.8279 - val_mae: 2.9704\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1551 - mae: 1.9205 - val_loss: 16.6466 - val_mae: 2.9598\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.1402 - mae: 1.9144 - val_loss: 16.8397 - val_mae: 2.9788\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1233 - mae: 1.9123 - val_loss: 17.0500 - val_mae: 2.9825\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0724 - mae: 1.8994 - val_loss: 16.9732 - val_mae: 2.9697\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.0889 - mae: 1.9046 - val_loss: 17.2100 - val_mae: 2.9574\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2815 - mae: 1.9142 - val_loss: 17.4951 - val_mae: 2.9517\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.1496 - mae: 1.9136 - val_loss: 16.6722 - val_mae: 2.9436\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.1193 - mae: 1.9332 - val_loss: 16.4379 - val_mae: 2.9478\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.9381 - mae: 1.8850 - val_loss: 17.0853 - val_mae: 2.9565\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9787 - mae: 1.8601 - val_loss: 16.6063 - val_mae: 2.9319\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2924 - mae: 1.9477 - val_loss: 16.1066 - val_mae: 2.9335\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1417 - mae: 1.9538 - val_loss: 16.3618 - val_mae: 2.9616\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9077 - mae: 1.9192 - val_loss: 16.6526 - val_mae: 2.9629\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6881 - mae: 1.8747 - val_loss: 16.3088 - val_mae: 2.9295\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6904 - mae: 1.8804 - val_loss: 16.4255 - val_mae: 2.9229\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6182 - mae: 1.8585 - val_loss: 16.3139 - val_mae: 2.9000\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5386 - mae: 1.8681 - val_loss: 16.1404 - val_mae: 2.9198\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4398 - mae: 1.8439 - val_loss: 16.3068 - val_mae: 2.8889\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4745 - mae: 1.8281 - val_loss: 16.0746 - val_mae: 2.8703\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3953 - mae: 1.8342 - val_loss: 16.2034 - val_mae: 2.8803\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3984 - mae: 1.8238 - val_loss: 16.1626 - val_mae: 2.8664\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.5343 - mae: 1.8575 - val_loss: 15.9912 - val_mae: 2.8703\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5038 - mae: 1.8759 - val_loss: 16.4535 - val_mae: 2.9036\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.4713 - mae: 1.8496 - val_loss: 17.0336 - val_mae: 2.9184\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.3793 - mae: 1.8376 - val_loss: 16.4662 - val_mae: 2.9215\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3325 - mae: 1.8388 - val_loss: 15.9567 - val_mae: 2.8790\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2151 - mae: 1.8163 - val_loss: 16.2844 - val_mae: 2.8870\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1600 - mae: 1.7912 - val_loss: 16.1846 - val_mae: 2.8697\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1342 - mae: 1.7948 - val_loss: 16.0079 - val_mae: 2.8627\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0918 - mae: 1.7961 - val_loss: 15.8222 - val_mae: 2.8392\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0016 - mae: 1.7858 - val_loss: 15.9659 - val_mae: 2.8529\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0198 - mae: 1.8049 - val_loss: 15.6843 - val_mae: 2.8474\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9840 - mae: 1.7773 - val_loss: 15.5520 - val_mae: 2.8053\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.9476 - mae: 1.7632 - val_loss: 15.5693 - val_mae: 2.8036\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.8858 - mae: 1.7714 - val_loss: 15.7159 - val_mae: 2.8178\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 5.8409 - mae: 1.7611 - val_loss: 15.4802 - val_mae: 2.7806\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.8203 - mae: 1.7567 - val_loss: 15.5626 - val_mae: 2.7990\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.8195 - mae: 1.7690 - val_loss: 15.5998 - val_mae: 2.7965\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.8375 - mae: 1.7747 - val_loss: 15.6096 - val_mae: 2.8344\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.7340 - mae: 1.7345 - val_loss: 15.6680 - val_mae: 2.7862\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.7763 - mae: 1.7671 - val_loss: 15.4787 - val_mae: 2.7988\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.6960 - mae: 1.7595 - val_loss: 15.7184 - val_mae: 2.7732\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.6443 - mae: 1.7319 - val_loss: 15.4219 - val_mae: 2.7699\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5721 - mae: 1.7189 - val_loss: 15.5691 - val_mae: 2.7848\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5621 - mae: 1.7240 - val_loss: 15.5575 - val_mae: 2.7753\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5327 - mae: 1.6981 - val_loss: 15.3969 - val_mae: 2.7629\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5627 - mae: 1.7527 - val_loss: 15.3698 - val_mae: 2.8007\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6075 - mae: 1.7454 - val_loss: 15.7507 - val_mae: 2.7824\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5422 - mae: 1.7176 - val_loss: 15.6723 - val_mae: 2.7753\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3997 - mae: 1.7121 - val_loss: 15.2519 - val_mae: 2.7618\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4156 - mae: 1.7125 - val_loss: 15.1004 - val_mae: 2.7418\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3847 - mae: 1.6970 - val_loss: 15.3897 - val_mae: 2.7544\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3104 - mae: 1.6976 - val_loss: 15.6017 - val_mae: 2.7834\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4060 - mae: 1.6994 - val_loss: 15.8364 - val_mae: 2.7994\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5708 - mae: 1.7842 - val_loss: 15.6305 - val_mae: 2.8332\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5887 - mae: 1.7685 - val_loss: 15.2360 - val_mae: 2.7854\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.2530 - mae: 1.6956 - val_loss: 15.8966 - val_mae: 2.8302\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5292 - mae: 1.7720 - val_loss: 15.6976 - val_mae: 2.7916\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3997 - mae: 1.6977 - val_loss: 14.7431 - val_mae: 2.7323\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3719 - mae: 1.7018 - val_loss: 15.5763 - val_mae: 2.7710\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1320 - mae: 1.6656 - val_loss: 15.3035 - val_mae: 2.7413\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1201 - mae: 1.6404 - val_loss: 15.3840 - val_mae: 2.7263\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0202 - mae: 1.6363 - val_loss: 15.0282 - val_mae: 2.7283\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0106 - mae: 1.6535 - val_loss: 15.1613 - val_mae: 2.7323\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0201 - mae: 1.6440 - val_loss: 15.0726 - val_mae: 2.7146\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9551 - mae: 1.6423 - val_loss: 15.4507 - val_mae: 2.7721\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9147 - mae: 1.6461 - val_loss: 15.3890 - val_mae: 2.7152\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9877 - mae: 1.6368 - val_loss: 15.5084 - val_mae: 2.7065\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0946 - mae: 1.6486 - val_loss: 16.0803 - val_mae: 2.7595\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0018 - mae: 1.6288 - val_loss: 14.9691 - val_mae: 2.6874\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8457 - mae: 1.5988 - val_loss: 15.2746 - val_mae: 2.7222\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8894 - mae: 1.6199 - val_loss: 15.1597 - val_mae: 2.6923\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8252 - mae: 1.5900 - val_loss: 14.6028 - val_mae: 2.6499\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7590 - mae: 1.5940 - val_loss: 14.8294 - val_mae: 2.6822\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6902 - mae: 1.5797 - val_loss: 14.8733 - val_mae: 2.6644\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6546 - mae: 1.5756 - val_loss: 14.9713 - val_mae: 2.6819\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7495 - mae: 1.6286 - val_loss: 15.1247 - val_mae: 2.7009\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6366 - mae: 1.5692 - val_loss: 14.8585 - val_mae: 2.6548\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6334 - mae: 1.5782 - val_loss: 14.9832 - val_mae: 2.7205\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6329 - mae: 1.5695 - val_loss: 14.8847 - val_mae: 2.6766\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5630 - mae: 1.5585 - val_loss: 14.9896 - val_mae: 2.6872\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5132 - mae: 1.5513 - val_loss: 15.2989 - val_mae: 2.6979\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4645 - mae: 1.5368 - val_loss: 14.9841 - val_mae: 2.6684\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.5060 - mae: 1.5744 - val_loss: 14.9418 - val_mae: 2.6939\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5111 - mae: 1.5736 - val_loss: 15.1975 - val_mae: 2.6706\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5122 - mae: 1.5685 - val_loss: 15.3241 - val_mae: 2.7068\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3968 - mae: 1.5306 - val_loss: 14.9389 - val_mae: 2.6679\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3936 - mae: 1.5377 - val_loss: 15.0363 - val_mae: 2.6875\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3168 - mae: 1.5247 - val_loss: 15.0184 - val_mae: 2.6703\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3093 - mae: 1.5145 - val_loss: 15.0891 - val_mae: 2.6898\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3399 - mae: 1.5234 - val_loss: 14.9789 - val_mae: 2.6908\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5867 - mae: 1.5617 - val_loss: 15.6858 - val_mae: 2.6902\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3198 - mae: 1.5062 - val_loss: 14.7943 - val_mae: 2.6447\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.2366 - mae: 1.4946 - val_loss: 15.2524 - val_mae: 2.6746\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.2574 - mae: 1.5004 - val_loss: 14.9746 - val_mae: 2.6585\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.2285 - mae: 1.4965 - val_loss: 14.8841 - val_mae: 2.6777\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2156 - mae: 1.5051 - val_loss: 14.9195 - val_mae: 2.6727\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1719 - mae: 1.4852 - val_loss: 14.9574 - val_mae: 2.6519\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1557 - mae: 1.4715 - val_loss: 14.8272 - val_mae: 2.6467\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1633 - mae: 1.4891 - val_loss: 15.0273 - val_mae: 2.6930\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.1328 - mae: 1.4899 - val_loss: 15.0436 - val_mae: 2.6649\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.1482 - mae: 1.4899 - val_loss: 14.7681 - val_mae: 2.6517\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.1350 - mae: 1.4765 - val_loss: 14.8811 - val_mae: 2.6428\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.1186 - mae: 1.4586 - val_loss: 14.9507 - val_mae: 2.6506\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0761 - mae: 1.4740 - val_loss: 14.5441 - val_mae: 2.6241\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.0687 - mae: 1.4824 - val_loss: 14.7099 - val_mae: 2.6245\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.0068 - mae: 1.4520 - val_loss: 14.8051 - val_mae: 2.6350\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0625 - mae: 1.4804 - val_loss: 14.8598 - val_mae: 2.6659\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.9696 - mae: 1.4368 - val_loss: 14.7169 - val_mae: 2.6054\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.9796 - mae: 1.4463 - val_loss: 14.7354 - val_mae: 2.6367\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.0151 - mae: 1.4673 - val_loss: 14.3943 - val_mae: 2.5967\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0356 - mae: 1.4519 - val_loss: 14.7948 - val_mae: 2.6007\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.0170 - mae: 1.4421 - val_loss: 14.6278 - val_mae: 2.5930\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8943 - mae: 1.4483 - val_loss: 14.3411 - val_mae: 2.5939\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.9955 - mae: 1.4379 - val_loss: 14.8669 - val_mae: 2.5903\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.8527 - mae: 1.4282 - val_loss: 14.4063 - val_mae: 2.5954\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.8868 - mae: 1.4300 - val_loss: 14.4174 - val_mae: 2.5816\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.8839 - mae: 1.4403 - val_loss: 14.2374 - val_mae: 2.5919\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.8574 - mae: 1.4296 - val_loss: 14.5818 - val_mae: 2.5947\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.8184 - mae: 1.4001 - val_loss: 14.8445 - val_mae: 2.5989\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8071 - mae: 1.4018 - val_loss: 14.4111 - val_mae: 2.5913\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7924 - mae: 1.4135 - val_loss: 14.5346 - val_mae: 2.5965\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7279 - mae: 1.4006 - val_loss: 14.6073 - val_mae: 2.6111\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7387 - mae: 1.3878 - val_loss: 14.8117 - val_mae: 2.6134\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8432 - mae: 1.4312 - val_loss: 14.9221 - val_mae: 2.6233\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.8616 - mae: 1.4355 - val_loss: 14.7135 - val_mae: 2.5936\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7320 - mae: 1.4071 - val_loss: 14.4855 - val_mae: 2.5807\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8316 - mae: 1.4291 - val_loss: 14.4291 - val_mae: 2.5987\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.9467 - mae: 1.4849 - val_loss: 14.3831 - val_mae: 2.6044\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.6748 - mae: 1.3767 - val_loss: 14.6549 - val_mae: 2.5916\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7002 - mae: 1.3880 - val_loss: 14.5972 - val_mae: 2.5966\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8378 - mae: 1.4054 - val_loss: 14.7768 - val_mae: 2.5828\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.7487 - mae: 1.4106 - val_loss: 14.5294 - val_mae: 2.6175\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.6718 - mae: 1.3902 - val_loss: 14.5404 - val_mae: 2.6025\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.6636 - mae: 1.4063 - val_loss: 14.4323 - val_mae: 2.6051\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.7313 - mae: 1.3990 - val_loss: 14.4651 - val_mae: 2.5772\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.7068 - mae: 1.4193 - val_loss: 14.7812 - val_mae: 2.6142\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5726 - mae: 1.3538 - val_loss: 14.5387 - val_mae: 2.5541\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.5450 - mae: 1.3589 - val_loss: 14.8306 - val_mae: 2.6022\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.5627 - mae: 1.3793 - val_loss: 14.4973 - val_mae: 2.5790\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5368 - mae: 1.3804 - val_loss: 14.5476 - val_mae: 2.5953\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.4910 - mae: 1.3494 - val_loss: 14.5113 - val_mae: 2.5620\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5063 - mae: 1.3496 - val_loss: 14.3254 - val_mae: 2.5417\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5599 - mae: 1.3555 - val_loss: 14.3651 - val_mae: 2.5413\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.5548 - mae: 1.3613 - val_loss: 14.5220 - val_mae: 2.5716\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.6021 - mae: 1.3538 - val_loss: 14.6852 - val_mae: 2.5609\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.5927 - mae: 1.3828 - val_loss: 14.2935 - val_mae: 2.5537\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.4572 - mae: 1.3386 - val_loss: 14.4706 - val_mae: 2.5492\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.3970 - mae: 1.3472 - val_loss: 13.9332 - val_mae: 2.5401\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.4290 - mae: 1.3574 - val_loss: 14.0184 - val_mae: 2.5429\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5254 - mae: 1.3634 - val_loss: 14.1131 - val_mae: 2.5353\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.4181 - mae: 1.3281 - val_loss: 14.3530 - val_mae: 2.5450\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.4326 - mae: 1.3521 - val_loss: 14.2008 - val_mae: 2.5356\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.4658 - mae: 1.3367 - val_loss: 14.5057 - val_mae: 2.5502\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.4010 - mae: 1.3633 - val_loss: 13.9955 - val_mae: 2.5238\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.4538 - mae: 1.3558 - val_loss: 14.1601 - val_mae: 2.5213\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.3574 - mae: 1.3333 - val_loss: 14.0216 - val_mae: 2.5471\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.8695 - mae: 1.4651 - val_loss: 13.4338 - val_mae: 2.5106\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5216 - mae: 1.3567 - val_loss: 14.7284 - val_mae: 2.5671\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5274 - mae: 1.3660 - val_loss: 14.2075 - val_mae: 2.5386\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.4076 - mae: 1.3507 - val_loss: 14.2970 - val_mae: 2.5541\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.2895 - mae: 1.3313 - val_loss: 14.5023 - val_mae: 2.5635\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.2640 - mae: 1.3066 - val_loss: 14.2464 - val_mae: 2.5310\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.2721 - mae: 1.2987 - val_loss: 14.3825 - val_mae: 2.5439\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.3273 - mae: 2.1640\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 26ms/step - loss: 556.8212 - mae: 21.9447 - val_loss: 629.9739 - val_mae: 23.0148\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 521.1972 - mae: 21.1414 - val_loss: 589.7232 - val_mae: 22.1767\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 485.7632 - mae: 20.3207 - val_loss: 546.9337 - val_mae: 21.2344\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 445.2887 - mae: 19.3384 - val_loss: 495.5296 - val_mae: 20.0500\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 395.5203 - mae: 18.0801 - val_loss: 432.9071 - val_mae: 18.5215\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 335.4101 - mae: 16.4295 - val_loss: 359.8821 - val_mae: 16.5548\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 268.3101 - mae: 14.4093 - val_loss: 281.7753 - val_mae: 14.2227\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 200.8273 - mae: 12.1085 - val_loss: 208.5748 - val_mae: 11.7485\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 142.4854 - mae: 9.6580 - val_loss: 147.4624 - val_mae: 9.3266\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 100.5087 - mae: 7.7911 - val_loss: 110.1984 - val_mae: 7.7364\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 77.2343 - mae: 6.7175 - val_loss: 86.8605 - val_mae: 6.8539\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 62.7362 - mae: 6.0257 - val_loss: 73.0354 - val_mae: 6.1989\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 53.7769 - mae: 5.5155 - val_loss: 62.2718 - val_mae: 5.6658\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 46.0695 - mae: 5.1106 - val_loss: 54.4812 - val_mae: 5.2360\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 40.0618 - mae: 4.7154 - val_loss: 48.5520 - val_mae: 4.8563\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35.6925 - mae: 4.4061 - val_loss: 44.7673 - val_mae: 4.6431\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.9188 - mae: 4.2079 - val_loss: 41.2321 - val_mae: 4.4350\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.2017 - mae: 4.0162 - val_loss: 39.0756 - val_mae: 4.2998\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 28.3863 - mae: 3.8733 - val_loss: 38.3278 - val_mae: 4.2211\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.8717 - mae: 3.7643 - val_loss: 37.0678 - val_mae: 4.1147\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 25.6929 - mae: 3.6829 - val_loss: 35.1707 - val_mae: 3.9965\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 24.8222 - mae: 3.6206 - val_loss: 33.5531 - val_mae: 3.8939\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 23.7080 - mae: 3.5424 - val_loss: 32.6502 - val_mae: 3.8267\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 22.8549 - mae: 3.5133 - val_loss: 31.4555 - val_mae: 3.8185\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 22.3084 - mae: 3.4696 - val_loss: 30.7010 - val_mae: 3.7564\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 21.3676 - mae: 3.3596 - val_loss: 30.8221 - val_mae: 3.7177\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 20.8699 - mae: 3.2524 - val_loss: 31.6514 - val_mae: 3.7474\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 20.4824 - mae: 3.2099 - val_loss: 30.6107 - val_mae: 3.6949\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 20.0482 - mae: 3.1823 - val_loss: 29.4030 - val_mae: 3.6229\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 19.5325 - mae: 3.1547 - val_loss: 29.1221 - val_mae: 3.5943\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 19.1208 - mae: 3.1294 - val_loss: 28.3045 - val_mae: 3.5458\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.8602 - mae: 3.1243 - val_loss: 27.4762 - val_mae: 3.5012\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 18.5797 - mae: 3.1263 - val_loss: 26.7713 - val_mae: 3.4497\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 18.3848 - mae: 3.1090 - val_loss: 27.1111 - val_mae: 3.4732\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.9258 - mae: 3.0407 - val_loss: 26.9439 - val_mae: 3.4538\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.6581 - mae: 3.0139 - val_loss: 26.3819 - val_mae: 3.4253\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 17.3480 - mae: 2.9856 - val_loss: 26.0841 - val_mae: 3.3900\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.0648 - mae: 2.9601 - val_loss: 25.6393 - val_mae: 3.3789\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.8736 - mae: 2.9706 - val_loss: 23.9675 - val_mae: 3.3395\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.7569 - mae: 2.9654 - val_loss: 23.8817 - val_mae: 3.3460\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.6257 - mae: 2.9118 - val_loss: 24.6742 - val_mae: 3.3807\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.2274 - mae: 2.8743 - val_loss: 24.1490 - val_mae: 3.3202\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.0242 - mae: 2.8697 - val_loss: 23.5311 - val_mae: 3.2612\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.8024 - mae: 2.8454 - val_loss: 23.6374 - val_mae: 3.2423\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.6270 - mae: 2.8337 - val_loss: 22.8476 - val_mae: 3.1664\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.7535 - mae: 2.8619 - val_loss: 21.5284 - val_mae: 3.1361\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.6060 - mae: 2.8476 - val_loss: 22.0627 - val_mae: 3.1806\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.3072 - mae: 2.8075 - val_loss: 21.6837 - val_mae: 3.1378\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.0655 - mae: 2.7619 - val_loss: 22.4266 - val_mae: 3.1582\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.8490 - mae: 2.7253 - val_loss: 22.4624 - val_mae: 3.1340\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.6794 - mae: 2.7446 - val_loss: 21.3700 - val_mae: 3.0573\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.5207 - mae: 2.7411 - val_loss: 21.5015 - val_mae: 3.0480\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.2968 - mae: 2.7007 - val_loss: 21.6992 - val_mae: 3.0474\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.1546 - mae: 2.6808 - val_loss: 21.6686 - val_mae: 3.0371\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0051 - mae: 2.6644 - val_loss: 21.0523 - val_mae: 3.0154\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.8607 - mae: 2.6404 - val_loss: 21.3016 - val_mae: 3.0205\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.7664 - mae: 2.6190 - val_loss: 21.4024 - val_mae: 3.0147\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.6802 - mae: 2.6049 - val_loss: 20.9502 - val_mae: 2.9885\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.4878 - mae: 2.5922 - val_loss: 21.1030 - val_mae: 2.9859\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5301 - mae: 2.6080 - val_loss: 20.8714 - val_mae: 2.9860\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.2914 - mae: 2.5951 - val_loss: 20.3623 - val_mae: 2.9560\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.1605 - mae: 2.5794 - val_loss: 20.3234 - val_mae: 2.9404\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.9623 - mae: 2.5498 - val_loss: 20.3732 - val_mae: 2.9419\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.9666 - mae: 2.5456 - val_loss: 20.3149 - val_mae: 2.9383\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.7948 - mae: 2.5258 - val_loss: 20.2462 - val_mae: 2.9272\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7430 - mae: 2.5256 - val_loss: 20.4109 - val_mae: 2.9117\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6154 - mae: 2.5303 - val_loss: 19.8797 - val_mae: 2.9084\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.4583 - mae: 2.5095 - val_loss: 19.9787 - val_mae: 2.8961\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4927 - mae: 2.5039 - val_loss: 20.1016 - val_mae: 2.8915\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2959 - mae: 2.4830 - val_loss: 19.4786 - val_mae: 2.8950\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3183 - mae: 2.4774 - val_loss: 19.6430 - val_mae: 2.8909\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1784 - mae: 2.4597 - val_loss: 19.4658 - val_mae: 2.8628\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.3049 - mae: 2.4774 - val_loss: 21.9102 - val_mae: 2.9209\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4176 - mae: 2.4920 - val_loss: 21.3296 - val_mae: 2.9092\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.1524 - mae: 2.4883 - val_loss: 20.8509 - val_mae: 2.9072\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.9873 - mae: 2.4836 - val_loss: 20.3038 - val_mae: 2.8888\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.9058 - mae: 2.4891 - val_loss: 20.0715 - val_mae: 2.8740\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7782 - mae: 2.4749 - val_loss: 19.7182 - val_mae: 2.8728\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.6996 - mae: 2.4502 - val_loss: 19.7597 - val_mae: 2.8718\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6355 - mae: 2.4167 - val_loss: 19.6983 - val_mae: 2.8491\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5997 - mae: 2.4097 - val_loss: 19.2564 - val_mae: 2.8291\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4094 - mae: 2.4132 - val_loss: 18.7864 - val_mae: 2.8147\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3959 - mae: 2.4195 - val_loss: 18.5087 - val_mae: 2.7945\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.2841 - mae: 2.3914 - val_loss: 18.8317 - val_mae: 2.7815\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3840 - mae: 2.3775 - val_loss: 19.2432 - val_mae: 2.8013\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.1686 - mae: 2.3401 - val_loss: 18.7585 - val_mae: 2.7818\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.0604 - mae: 2.3694 - val_loss: 18.3336 - val_mae: 2.8026\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.0521 - mae: 2.3947 - val_loss: 18.1566 - val_mae: 2.7867\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9709 - mae: 2.3822 - val_loss: 18.2748 - val_mae: 2.7669\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8853 - mae: 2.3509 - val_loss: 18.2731 - val_mae: 2.7642\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8171 - mae: 2.3385 - val_loss: 18.1761 - val_mae: 2.7575\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7873 - mae: 2.3377 - val_loss: 18.0262 - val_mae: 2.7548\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7547 - mae: 2.3355 - val_loss: 17.4576 - val_mae: 2.7287\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.7117 - mae: 2.3426 - val_loss: 17.5084 - val_mae: 2.7156\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6268 - mae: 2.3131 - val_loss: 17.5864 - val_mae: 2.7081\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5276 - mae: 2.2874 - val_loss: 17.7630 - val_mae: 2.7021\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5533 - mae: 2.2800 - val_loss: 17.7698 - val_mae: 2.6973\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5314 - mae: 2.3075 - val_loss: 17.2289 - val_mae: 2.6928\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.4159 - mae: 2.2979 - val_loss: 17.2854 - val_mae: 2.6882\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3656 - mae: 2.2794 - val_loss: 17.3835 - val_mae: 2.6943\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3304 - mae: 2.2526 - val_loss: 17.7147 - val_mae: 2.7142\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.2699 - mae: 2.2553 - val_loss: 17.2219 - val_mae: 2.6844\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.2002 - mae: 2.2652 - val_loss: 16.9708 - val_mae: 2.6648\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.1650 - mae: 2.2683 - val_loss: 16.6808 - val_mae: 2.6731\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.1704 - mae: 2.2464 - val_loss: 17.0592 - val_mae: 2.6504\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.0518 - mae: 2.2360 - val_loss: 16.8717 - val_mae: 2.6428\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.0337 - mae: 2.2355 - val_loss: 16.9411 - val_mae: 2.6424\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.0331 - mae: 2.2397 - val_loss: 16.6052 - val_mae: 2.6244\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.9467 - mae: 2.2073 - val_loss: 16.7810 - val_mae: 2.6605\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.9371 - mae: 2.2130 - val_loss: 16.1132 - val_mae: 2.6412\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.8573 - mae: 2.2291 - val_loss: 16.2129 - val_mae: 2.6557\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.8358 - mae: 2.2431 - val_loss: 16.1420 - val_mae: 2.6611\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.8090 - mae: 2.2280 - val_loss: 16.3364 - val_mae: 2.6759\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.7158 - mae: 2.1988 - val_loss: 16.6407 - val_mae: 2.6798\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6257 - mae: 2.1899 - val_loss: 16.2461 - val_mae: 2.6530\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.5829 - mae: 2.1932 - val_loss: 16.2658 - val_mae: 2.6388\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.5087 - mae: 2.1746 - val_loss: 16.1098 - val_mae: 2.6185\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.4725 - mae: 2.1646 - val_loss: 16.0327 - val_mae: 2.6117\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.2886 - mae: 2.1868 - val_loss: 15.6589 - val_mae: 2.6556\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.5089 - mae: 2.2118 - val_loss: 15.6931 - val_mae: 2.6358\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.3419 - mae: 2.1840 - val_loss: 15.5742 - val_mae: 2.6126\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.4857 - mae: 2.1930 - val_loss: 15.5518 - val_mae: 2.5881\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.3802 - mae: 2.1750 - val_loss: 15.6099 - val_mae: 2.6064\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.2600 - mae: 2.1821 - val_loss: 15.6924 - val_mae: 2.6373\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.1047 - mae: 2.1680 - val_loss: 15.8953 - val_mae: 2.6465\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.0766 - mae: 2.1476 - val_loss: 15.8022 - val_mae: 2.6569\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.1488 - mae: 2.1595 - val_loss: 15.5626 - val_mae: 2.6524\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.0603 - mae: 2.1454 - val_loss: 15.8869 - val_mae: 2.6288\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.9814 - mae: 2.1235 - val_loss: 15.9443 - val_mae: 2.6217\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.9402 - mae: 2.1107 - val_loss: 15.6645 - val_mae: 2.6134\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.9019 - mae: 2.1209 - val_loss: 15.4403 - val_mae: 2.6113\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.8837 - mae: 2.0954 - val_loss: 15.7255 - val_mae: 2.5845\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.8293 - mae: 2.1053 - val_loss: 15.3562 - val_mae: 2.5793\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.7912 - mae: 2.0951 - val_loss: 15.3008 - val_mae: 2.5680\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6920 - mae: 2.0883 - val_loss: 15.2626 - val_mae: 2.5963\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.6949 - mae: 2.0968 - val_loss: 15.2945 - val_mae: 2.5923\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.7324 - mae: 2.0903 - val_loss: 15.3772 - val_mae: 2.5747\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.7256 - mae: 2.0945 - val_loss: 15.3620 - val_mae: 2.5523\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.9357 - mae: 2.1378 - val_loss: 15.3533 - val_mae: 2.6727\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.8126 - mae: 2.1122 - val_loss: 15.2752 - val_mae: 2.5587\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5475 - mae: 2.0684 - val_loss: 15.2582 - val_mae: 2.5547\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.5128 - mae: 2.0760 - val_loss: 15.2099 - val_mae: 2.5833\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5264 - mae: 2.0713 - val_loss: 15.4767 - val_mae: 2.5787\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4646 - mae: 2.0540 - val_loss: 15.6102 - val_mae: 2.5452\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.4609 - mae: 2.0594 - val_loss: 15.3809 - val_mae: 2.5484\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.3981 - mae: 2.0595 - val_loss: 15.0627 - val_mae: 2.5700\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.3143 - mae: 2.0418 - val_loss: 15.3313 - val_mae: 2.5373\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3297 - mae: 2.0250 - val_loss: 15.5307 - val_mae: 2.5329\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2832 - mae: 2.0383 - val_loss: 15.2311 - val_mae: 2.5621\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.2210 - mae: 2.0397 - val_loss: 15.3843 - val_mae: 2.5635\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2108 - mae: 2.0228 - val_loss: 15.0007 - val_mae: 2.5375\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2091 - mae: 2.0359 - val_loss: 15.1558 - val_mae: 2.5376\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.0694 - mae: 2.0083 - val_loss: 15.2396 - val_mae: 2.5225\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.1324 - mae: 1.9950 - val_loss: 15.2900 - val_mae: 2.5309\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1383 - mae: 2.0094 - val_loss: 15.0474 - val_mae: 2.5444\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0704 - mae: 2.0266 - val_loss: 14.8933 - val_mae: 2.5335\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0801 - mae: 2.0298 - val_loss: 14.8020 - val_mae: 2.5482\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0239 - mae: 2.0208 - val_loss: 15.0377 - val_mae: 2.5294\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.1011 - mae: 2.0143 - val_loss: 14.5984 - val_mae: 2.5315\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.9537 - mae: 2.0181 - val_loss: 14.8155 - val_mae: 2.5332\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8796 - mae: 1.9836 - val_loss: 14.7964 - val_mae: 2.4712\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.8581 - mae: 1.9736 - val_loss: 15.3292 - val_mae: 2.4844\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.9415 - mae: 2.0051 - val_loss: 14.7949 - val_mae: 2.5051\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9287 - mae: 2.0055 - val_loss: 15.0224 - val_mae: 2.4686\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7892 - mae: 1.9801 - val_loss: 14.6313 - val_mae: 2.4642\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8325 - mae: 1.9981 - val_loss: 14.5202 - val_mae: 2.4664\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7065 - mae: 1.9478 - val_loss: 14.8185 - val_mae: 2.4464\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7754 - mae: 1.9333 - val_loss: 14.6795 - val_mae: 2.4744\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6457 - mae: 1.9422 - val_loss: 14.2369 - val_mae: 2.5098\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.6088 - mae: 1.9745 - val_loss: 14.2617 - val_mae: 2.5225\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6420 - mae: 1.9832 - val_loss: 13.8692 - val_mae: 2.4689\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4798 - mae: 1.9284 - val_loss: 14.1821 - val_mae: 2.4495\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5092 - mae: 1.9329 - val_loss: 14.0470 - val_mae: 2.4404\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3662 - mae: 1.9067 - val_loss: 14.1079 - val_mae: 2.4597\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5882 - mae: 1.9486 - val_loss: 14.1377 - val_mae: 2.5183\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.4206 - mae: 1.9312 - val_loss: 14.1866 - val_mae: 2.5089\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.3454 - mae: 1.9098 - val_loss: 14.0481 - val_mae: 2.4755\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3805 - mae: 1.9107 - val_loss: 13.9424 - val_mae: 2.5011\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.2555 - mae: 1.9000 - val_loss: 14.0036 - val_mae: 2.4471\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2149 - mae: 1.8862 - val_loss: 13.8184 - val_mae: 2.4429\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1699 - mae: 1.8805 - val_loss: 13.7579 - val_mae: 2.4331\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1860 - mae: 1.9030 - val_loss: 13.5110 - val_mae: 2.4502\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2430 - mae: 1.9171 - val_loss: 13.7386 - val_mae: 2.4212\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3188 - mae: 1.9052 - val_loss: 13.8809 - val_mae: 2.4469\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0821 - mae: 1.8850 - val_loss: 13.7310 - val_mae: 2.4466\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0484 - mae: 1.8952 - val_loss: 13.4994 - val_mae: 2.4423\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1135 - mae: 1.8891 - val_loss: 13.6254 - val_mae: 2.4152\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9993 - mae: 1.8635 - val_loss: 13.3456 - val_mae: 2.4093\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9675 - mae: 1.8487 - val_loss: 13.4228 - val_mae: 2.3993\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9326 - mae: 1.8682 - val_loss: 13.0617 - val_mae: 2.4129\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1231 - mae: 1.9237 - val_loss: 13.2369 - val_mae: 2.4393\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9457 - mae: 1.8560 - val_loss: 13.4483 - val_mae: 2.4395\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9160 - mae: 1.8689 - val_loss: 13.4121 - val_mae: 2.4459\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7535 - mae: 1.8432 - val_loss: 13.2302 - val_mae: 2.4163\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7488 - mae: 1.8422 - val_loss: 13.1850 - val_mae: 2.4241\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6882 - mae: 1.8338 - val_loss: 13.1983 - val_mae: 2.3963\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.6423 - mae: 1.8283 - val_loss: 13.4052 - val_mae: 2.4107\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7245 - mae: 1.8304 - val_loss: 13.2036 - val_mae: 2.4007\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6078 - mae: 1.9836 - val_loss: 13.6897 - val_mae: 2.5979\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.3310 - mae: 1.9498 - val_loss: 13.3461 - val_mae: 2.4801\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7875 - mae: 1.8623 - val_loss: 13.7393 - val_mae: 2.4475\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7798 - mae: 1.8591 - val_loss: 13.3427 - val_mae: 2.4294\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6557 - mae: 1.8639 - val_loss: 13.2691 - val_mae: 2.4405\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5184 - mae: 1.8394 - val_loss: 13.3543 - val_mae: 2.4063\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4858 - mae: 1.8070 - val_loss: 13.2970 - val_mae: 2.4021\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4806 - mae: 1.8081 - val_loss: 13.0742 - val_mae: 2.4067\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4742 - mae: 1.8312 - val_loss: 12.6613 - val_mae: 2.4161\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3420 - mae: 1.7992 - val_loss: 12.8286 - val_mae: 2.3955\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3618 - mae: 1.8072 - val_loss: 12.7339 - val_mae: 2.4309\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3130 - mae: 1.8061 - val_loss: 12.8747 - val_mae: 2.3922\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2545 - mae: 1.7886 - val_loss: 12.8922 - val_mae: 2.4008\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2212 - mae: 1.7751 - val_loss: 12.7697 - val_mae: 2.3825\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1933 - mae: 1.7549 - val_loss: 12.6197 - val_mae: 2.3675\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2742 - mae: 1.8092 - val_loss: 12.6686 - val_mae: 2.4259\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1455 - mae: 1.7851 - val_loss: 12.9121 - val_mae: 2.3969\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1880 - mae: 1.7919 - val_loss: 12.5849 - val_mae: 2.3997\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0762 - mae: 1.7551 - val_loss: 12.8659 - val_mae: 2.3724\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0190 - mae: 1.7427 - val_loss: 12.6758 - val_mae: 2.3946\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0773 - mae: 1.7801 - val_loss: 12.7513 - val_mae: 2.4197\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9851 - mae: 1.7446 - val_loss: 12.9896 - val_mae: 2.4017\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.9897 - mae: 1.7359 - val_loss: 12.5304 - val_mae: 2.3914\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0444 - mae: 1.7711 - val_loss: 12.7449 - val_mae: 2.3681\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9643 - mae: 1.7350 - val_loss: 12.7158 - val_mae: 2.3890\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8262 - mae: 1.7326 - val_loss: 12.7123 - val_mae: 2.3833\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8293 - mae: 1.7117 - val_loss: 12.7095 - val_mae: 2.3860\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7964 - mae: 1.7226 - val_loss: 12.5405 - val_mae: 2.3983\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7805 - mae: 1.7286 - val_loss: 12.5782 - val_mae: 2.3762\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.7760 - mae: 1.6982 - val_loss: 12.6327 - val_mae: 2.3793\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8456 - mae: 1.7090 - val_loss: 12.5943 - val_mae: 2.4411\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.7615 - mae: 1.7219 - val_loss: 12.5910 - val_mae: 2.4174\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7077 - mae: 1.6892 - val_loss: 12.6343 - val_mae: 2.4084\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2122 - mae: 1.8022 - val_loss: 13.0393 - val_mae: 2.5291\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8258 - mae: 1.7552 - val_loss: 12.6671 - val_mae: 2.4244\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6199 - mae: 1.7033 - val_loss: 12.4968 - val_mae: 2.3994\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5802 - mae: 1.6930 - val_loss: 12.4752 - val_mae: 2.4163\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5077 - mae: 1.6945 - val_loss: 12.4283 - val_mae: 2.4081\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6091 - mae: 1.7103 - val_loss: 12.3686 - val_mae: 2.4407\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5323 - mae: 1.6873 - val_loss: 12.4022 - val_mae: 2.4063\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6394 - mae: 1.6842 - val_loss: 12.4883 - val_mae: 2.3857\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5234 - mae: 1.6723 - val_loss: 12.3346 - val_mae: 2.4110\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3419 - mae: 1.6537 - val_loss: 12.4420 - val_mae: 2.3872\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5350 - mae: 1.6565 - val_loss: 12.7622 - val_mae: 2.3970\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3275 - mae: 1.6582 - val_loss: 12.6429 - val_mae: 2.4244\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3879 - mae: 1.6696 - val_loss: 12.5851 - val_mae: 2.4161\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4631 - mae: 1.7039 - val_loss: 12.2862 - val_mae: 2.3839\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2847 - mae: 1.6430 - val_loss: 12.3494 - val_mae: 2.3798\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1900 - mae: 1.6086 - val_loss: 12.0721 - val_mae: 2.3733\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1682 - mae: 1.6210 - val_loss: 12.1696 - val_mae: 2.3771\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1433 - mae: 1.6274 - val_loss: 12.2129 - val_mae: 2.3950\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1377 - mae: 1.6388 - val_loss: 12.0415 - val_mae: 2.3835\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0873 - mae: 1.6106 - val_loss: 12.2896 - val_mae: 2.3600\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0743 - mae: 1.5981 - val_loss: 12.0974 - val_mae: 2.3708\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0407 - mae: 1.6244 - val_loss: 12.1721 - val_mae: 2.4012\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0115 - mae: 1.6029 - val_loss: 12.2300 - val_mae: 2.3595\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9665 - mae: 1.6057 - val_loss: 12.0927 - val_mae: 2.3739\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9658 - mae: 1.6106 - val_loss: 11.9900 - val_mae: 2.3617\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.9994 - mae: 1.6169 - val_loss: 12.3030 - val_mae: 2.3944\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9185 - mae: 1.6095 - val_loss: 12.1993 - val_mae: 2.3990\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8484 - mae: 1.5889 - val_loss: 12.2168 - val_mae: 2.3769\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7982 - mae: 1.5700 - val_loss: 12.1329 - val_mae: 2.3833\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7939 - mae: 1.5926 - val_loss: 11.9326 - val_mae: 2.3725\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8861 - mae: 1.5662 - val_loss: 12.0453 - val_mae: 2.3605\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7411 - mae: 1.5850 - val_loss: 11.8369 - val_mae: 2.3634\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7615 - mae: 1.5673 - val_loss: 12.1845 - val_mae: 2.3662\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1021 - mae: 1.5922 - val_loss: 12.5747 - val_mae: 2.3390\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8830 - mae: 1.5741 - val_loss: 12.0362 - val_mae: 2.3266\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6829 - mae: 1.5519 - val_loss: 11.8498 - val_mae: 2.3236\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6698 - mae: 1.5595 - val_loss: 11.7743 - val_mae: 2.3399\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6606 - mae: 1.5382 - val_loss: 11.6111 - val_mae: 2.3004\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.5693 - mae: 1.5302 - val_loss: 11.5632 - val_mae: 2.3228\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5255 - mae: 1.5261 - val_loss: 11.7902 - val_mae: 2.3266\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4719 - mae: 1.5094 - val_loss: 11.6307 - val_mae: 2.3292\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.4869 - mae: 1.5266 - val_loss: 11.6267 - val_mae: 2.3353\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.4241 - mae: 1.4969 - val_loss: 11.7048 - val_mae: 2.3278\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.3901 - mae: 1.4956 - val_loss: 11.6235 - val_mae: 2.3199\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.3777 - mae: 1.5000 - val_loss: 11.6120 - val_mae: 2.3212\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.3328 - mae: 1.5006 - val_loss: 11.6729 - val_mae: 2.3182\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.4725 - mae: 1.4935 - val_loss: 11.7977 - val_mae: 2.3308\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.3390 - mae: 1.4992 - val_loss: 11.5174 - val_mae: 2.3352\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.2878 - mae: 1.4839 - val_loss: 11.6052 - val_mae: 2.3166\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.4033 - mae: 1.4742 - val_loss: 11.5810 - val_mae: 2.3073\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.2342 - mae: 1.4742 - val_loss: 11.4978 - val_mae: 2.3339\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.2646 - mae: 1.4847 - val_loss: 11.5294 - val_mae: 2.3048\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.2930 - mae: 1.4954 - val_loss: 11.4451 - val_mae: 2.3223\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.2078 - mae: 1.4627 - val_loss: 11.4283 - val_mae: 2.3096\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1452 - mae: 1.4486 - val_loss: 11.4775 - val_mae: 2.3145\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.1008 - mae: 1.4487 - val_loss: 11.7236 - val_mae: 2.3086\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1287 - mae: 1.4507 - val_loss: 11.6370 - val_mae: 2.3324\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.8749 - mae: 1.6123 - val_loss: 11.8605 - val_mae: 2.3986\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.5605 - mae: 1.5281 - val_loss: 11.8986 - val_mae: 2.3707\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.3370 - mae: 1.4693 - val_loss: 11.2527 - val_mae: 2.3240\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.2459 - mae: 1.4990 - val_loss: 11.1850 - val_mae: 2.3238\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.0085 - mae: 1.4338 - val_loss: 11.5629 - val_mae: 2.3175\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.8842 - mae: 1.3909 - val_loss: 11.3962 - val_mae: 2.3256\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.9052 - mae: 1.4260 - val_loss: 11.4107 - val_mae: 2.3207\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.8413 - mae: 1.4038 - val_loss: 11.4766 - val_mae: 2.3209\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.8583 - mae: 1.4100 - val_loss: 11.3084 - val_mae: 2.3249\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.8456 - mae: 1.4176 - val_loss: 11.4887 - val_mae: 2.3123\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.8550 - mae: 1.4108 - val_loss: 11.4826 - val_mae: 2.3044\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.7782 - mae: 1.4131 - val_loss: 11.4189 - val_mae: 2.3256\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.5044 - mae: 1.9354\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 21ms/step - loss: 589.4008 - mae: 22.3728 - val_loss: 629.3975 - val_mae: 22.8950\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 546.9819 - mae: 21.3792 - val_loss: 587.5801 - val_mae: 21.9250\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 509.6959 - mae: 20.4337 - val_loss: 548.9362 - val_mae: 20.9783\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 473.0175 - mae: 19.4610 - val_loss: 506.9590 - val_mae: 19.9299\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 433.1847 - mae: 18.3815 - val_loss: 459.8193 - val_mae: 18.7476\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 388.1537 - mae: 17.1753 - val_loss: 403.9416 - val_mae: 17.3605\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 335.2086 - mae: 15.7512 - val_loss: 336.5169 - val_mae: 15.6492\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 272.0845 - mae: 14.0467 - val_loss: 263.5125 - val_mae: 13.6721\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 206.6074 - mae: 12.1330 - val_loss: 191.1587 - val_mae: 11.4457\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 147.7862 - mae: 10.0269 - val_loss: 130.6430 - val_mae: 9.2390\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 97.9717 - mae: 8.0026 - val_loss: 92.7916 - val_mae: 7.4909\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 69.1990 - mae: 6.5085 - val_loss: 74.2153 - val_mae: 6.4534\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 53.7753 - mae: 5.6038 - val_loss: 65.1536 - val_mae: 5.9495\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 45.3788 - mae: 5.0699 - val_loss: 59.2093 - val_mae: 5.7015\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 39.4069 - mae: 4.6968 - val_loss: 54.7136 - val_mae: 5.4575\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 35.1262 - mae: 4.4422 - val_loss: 52.4550 - val_mae: 5.3286\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31.8377 - mae: 4.2279 - val_loss: 50.2843 - val_mae: 5.1750\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.8043 - mae: 4.0791 - val_loss: 48.7070 - val_mae: 5.0517\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 28.3376 - mae: 3.9584 - val_loss: 47.4023 - val_mae: 4.9201\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 27.2838 - mae: 3.8569 - val_loss: 45.8255 - val_mae: 4.8042\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.2129 - mae: 3.7513 - val_loss: 43.5129 - val_mae: 4.6777\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 25.4587 - mae: 3.6654 - val_loss: 42.2030 - val_mae: 4.5702\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 24.8241 - mae: 3.6092 - val_loss: 41.0417 - val_mae: 4.5032\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 24.2262 - mae: 3.5629 - val_loss: 40.6767 - val_mae: 4.4631\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 23.7121 - mae: 3.5471 - val_loss: 40.2407 - val_mae: 4.4359\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 23.0970 - mae: 3.5018 - val_loss: 39.4477 - val_mae: 4.3778\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 22.6937 - mae: 3.4745 - val_loss: 38.8408 - val_mae: 4.3349\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 22.1739 - mae: 3.4251 - val_loss: 38.0053 - val_mae: 4.2504\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 21.7283 - mae: 3.3830 - val_loss: 37.6819 - val_mae: 4.2065\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 21.2501 - mae: 3.3489 - val_loss: 37.1364 - val_mae: 4.1650\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 20.8006 - mae: 3.3158 - val_loss: 36.9383 - val_mae: 4.1408\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 20.4214 - mae: 3.2812 - val_loss: 35.8167 - val_mae: 4.0635\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.0296 - mae: 3.2416 - val_loss: 35.1567 - val_mae: 4.0200\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 19.6331 - mae: 3.2139 - val_loss: 34.9100 - val_mae: 3.9944\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 19.3177 - mae: 3.1615 - val_loss: 34.1406 - val_mae: 3.9030\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.9430 - mae: 3.1151 - val_loss: 33.6915 - val_mae: 3.8460\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 18.6016 - mae: 3.0921 - val_loss: 33.3301 - val_mae: 3.8192\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 18.1997 - mae: 3.0748 - val_loss: 32.8458 - val_mae: 3.7823\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.8579 - mae: 3.0362 - val_loss: 32.0240 - val_mae: 3.7166\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 17.4937 - mae: 3.0008 - val_loss: 31.0877 - val_mae: 3.6800\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.2819 - mae: 3.0004 - val_loss: 30.9799 - val_mae: 3.6798\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.8283 - mae: 2.9707 - val_loss: 30.3070 - val_mae: 3.6140\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.5917 - mae: 2.9242 - val_loss: 30.1553 - val_mae: 3.6141\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.1766 - mae: 2.8919 - val_loss: 29.5037 - val_mae: 3.5708\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.9135 - mae: 2.8835 - val_loss: 29.0160 - val_mae: 3.5143\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.6165 - mae: 2.8517 - val_loss: 28.7260 - val_mae: 3.4716\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.4043 - mae: 2.8193 - val_loss: 28.5191 - val_mae: 3.4416\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.2085 - mae: 2.8142 - val_loss: 28.2556 - val_mae: 3.4048\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.8846 - mae: 2.7857 - val_loss: 27.9085 - val_mae: 3.3634\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.6961 - mae: 2.7675 - val_loss: 27.3459 - val_mae: 3.3080\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.4531 - mae: 2.7477 - val_loss: 27.1929 - val_mae: 3.2947\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.2309 - mae: 2.7305 - val_loss: 27.2901 - val_mae: 3.3037\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0320 - mae: 2.7106 - val_loss: 27.3460 - val_mae: 3.3015\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.8990 - mae: 2.7062 - val_loss: 27.4846 - val_mae: 3.3084\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.6605 - mae: 2.6983 - val_loss: 27.2215 - val_mae: 3.2612\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.7693 - mae: 2.7245 - val_loss: 26.7929 - val_mae: 3.2330\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.4888 - mae: 2.6957 - val_loss: 26.8004 - val_mae: 3.2317\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.1399 - mae: 2.6639 - val_loss: 26.4256 - val_mae: 3.2179\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9309 - mae: 2.6244 - val_loss: 25.6418 - val_mae: 3.1439\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.8205 - mae: 2.6016 - val_loss: 25.6125 - val_mae: 3.1313\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.7339 - mae: 2.6022 - val_loss: 25.8151 - val_mae: 3.1423\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.5010 - mae: 2.5807 - val_loss: 25.5023 - val_mae: 3.0970\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3682 - mae: 2.5793 - val_loss: 25.6804 - val_mae: 3.1291\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3126 - mae: 2.5889 - val_loss: 25.6121 - val_mae: 3.1250\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0506 - mae: 2.5540 - val_loss: 25.3717 - val_mae: 3.0984\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.9674 - mae: 2.5294 - val_loss: 25.0932 - val_mae: 3.0651\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8515 - mae: 2.5110 - val_loss: 25.1252 - val_mae: 3.0700\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7667 - mae: 2.4993 - val_loss: 25.0551 - val_mae: 3.0712\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6109 - mae: 2.4900 - val_loss: 24.7672 - val_mae: 3.0336\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4888 - mae: 2.4856 - val_loss: 24.8461 - val_mae: 3.0266\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5059 - mae: 2.4667 - val_loss: 23.9250 - val_mae: 2.9593\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3578 - mae: 2.4553 - val_loss: 24.3093 - val_mae: 3.0020\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1918 - mae: 2.4562 - val_loss: 24.1796 - val_mae: 2.9805\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.0934 - mae: 2.4530 - val_loss: 24.4197 - val_mae: 3.0040\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.0630 - mae: 2.4574 - val_loss: 24.2807 - val_mae: 2.9745\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.9214 - mae: 2.4236 - val_loss: 24.3643 - val_mae: 2.9915\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8276 - mae: 2.3944 - val_loss: 24.2047 - val_mae: 2.9695\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.7135 - mae: 2.3898 - val_loss: 24.3131 - val_mae: 2.9785\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6682 - mae: 2.3935 - val_loss: 24.3521 - val_mae: 2.9761\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.6220 - mae: 2.3829 - val_loss: 24.1227 - val_mae: 2.9449\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5711 - mae: 2.3760 - val_loss: 24.3543 - val_mae: 2.9737\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.4555 - mae: 2.3424 - val_loss: 24.4704 - val_mae: 2.9991\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.4814 - mae: 2.3367 - val_loss: 24.2238 - val_mae: 2.9882\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3155 - mae: 2.3421 - val_loss: 23.9853 - val_mae: 2.9595\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.3092 - mae: 2.3355 - val_loss: 23.3211 - val_mae: 2.9237\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.2193 - mae: 2.3166 - val_loss: 23.6764 - val_mae: 2.9577\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.1277 - mae: 2.3019 - val_loss: 23.6706 - val_mae: 2.9555\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.1611 - mae: 2.3382 - val_loss: 23.6205 - val_mae: 2.9308\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.0916 - mae: 2.3310 - val_loss: 23.7233 - val_mae: 2.9377\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.0204 - mae: 2.2893 - val_loss: 23.8149 - val_mae: 2.9525\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.9260 - mae: 2.2946 - val_loss: 23.8923 - val_mae: 2.9574\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.8533 - mae: 2.2949 - val_loss: 23.4222 - val_mae: 2.9165\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.8014 - mae: 2.2636 - val_loss: 23.6710 - val_mae: 2.9346\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.7621 - mae: 2.2703 - val_loss: 23.1263 - val_mae: 2.8939\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6416 - mae: 2.2463 - val_loss: 23.6281 - val_mae: 2.9306\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6370 - mae: 2.2450 - val_loss: 24.0664 - val_mae: 2.9796\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.7389 - mae: 2.2440 - val_loss: 22.8562 - val_mae: 2.8554\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6535 - mae: 2.2229 - val_loss: 22.8777 - val_mae: 2.8909\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.5143 - mae: 2.2299 - val_loss: 24.1633 - val_mae: 3.0107\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.5570 - mae: 2.2367 - val_loss: 23.4053 - val_mae: 2.9223\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.4367 - mae: 2.1866 - val_loss: 22.7380 - val_mae: 2.8682\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.4241 - mae: 2.2106 - val_loss: 23.0180 - val_mae: 2.8793\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.3313 - mae: 2.2192 - val_loss: 23.4515 - val_mae: 2.9299\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.2258 - mae: 2.1968 - val_loss: 23.4839 - val_mae: 2.9534\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.2737 - mae: 2.1797 - val_loss: 22.2990 - val_mae: 2.8718\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.3330 - mae: 2.1630 - val_loss: 22.9306 - val_mae: 2.9511\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.0937 - mae: 2.1624 - val_loss: 22.8929 - val_mae: 2.9153\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.0815 - mae: 2.1722 - val_loss: 23.5399 - val_mae: 2.9426\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.0325 - mae: 2.1705 - val_loss: 23.4440 - val_mae: 2.9378\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8.8863 - mae: 2.1411 - val_loss: 22.5667 - val_mae: 2.8530\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.0152 - mae: 2.1374 - val_loss: 23.0393 - val_mae: 2.9503\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.8373 - mae: 2.1106 - val_loss: 23.0403 - val_mae: 2.9240\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 8.9232 - mae: 2.1577 - val_loss: 23.1081 - val_mae: 2.9265\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 8.9894 - mae: 2.1672 - val_loss: 22.2085 - val_mae: 2.8364\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.8415 - mae: 2.1393 - val_loss: 22.5007 - val_mae: 2.8915\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6940 - mae: 2.1087 - val_loss: 22.8558 - val_mae: 2.9134\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.6822 - mae: 2.0979 - val_loss: 22.2451 - val_mae: 2.8843\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6059 - mae: 2.0882 - val_loss: 22.4868 - val_mae: 2.8966\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.5646 - mae: 2.0889 - val_loss: 22.6836 - val_mae: 2.9156\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8.5260 - mae: 2.0818 - val_loss: 22.1197 - val_mae: 2.8604\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.5540 - mae: 2.0849 - val_loss: 21.9593 - val_mae: 2.8283\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.5050 - mae: 2.0842 - val_loss: 22.4812 - val_mae: 2.8762\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.4282 - mae: 2.0713 - val_loss: 22.9347 - val_mae: 2.9296\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.4892 - mae: 2.0620 - val_loss: 22.2638 - val_mae: 2.8895\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 8.3343 - mae: 2.0458 - val_loss: 22.4179 - val_mae: 2.8918\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 8.3162 - mae: 2.0761 - val_loss: 22.7431 - val_mae: 2.9096\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8.2917 - mae: 2.0540 - val_loss: 22.4672 - val_mae: 2.9169\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 8.3312 - mae: 2.0752 - val_loss: 23.4209 - val_mae: 2.9266\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 8.3597 - mae: 2.0816 - val_loss: 22.7182 - val_mae: 2.8499\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 8.3027 - mae: 2.0407 - val_loss: 22.6934 - val_mae: 2.9216\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 8.2615 - mae: 2.0372 - val_loss: 21.2466 - val_mae: 2.8428\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 8.1420 - mae: 2.0403 - val_loss: 20.8335 - val_mae: 2.7958\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8.1798 - mae: 2.0432 - val_loss: 21.4542 - val_mae: 2.8343\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 8.0656 - mae: 2.0212 - val_loss: 21.9519 - val_mae: 2.9271\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 8.0279 - mae: 2.0119 - val_loss: 22.0906 - val_mae: 2.8741\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 8.0562 - mae: 2.0466 - val_loss: 22.1176 - val_mae: 2.8344\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.0171 - mae: 2.0247 - val_loss: 21.3969 - val_mae: 2.8182\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 8.1516 - mae: 2.0149 - val_loss: 22.1242 - val_mae: 2.9382\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 7.9030 - mae: 1.9951 - val_loss: 22.0311 - val_mae: 2.8524\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.9114 - mae: 1.9922 - val_loss: 21.7356 - val_mae: 2.8319\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.8906 - mae: 1.9883 - val_loss: 22.3650 - val_mae: 2.8924\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.9197 - mae: 1.9761 - val_loss: 21.6728 - val_mae: 2.8450\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.8773 - mae: 1.9655 - val_loss: 21.5313 - val_mae: 2.8553\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8161 - mae: 1.9746 - val_loss: 21.3161 - val_mae: 2.8188\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.7861 - mae: 1.9661 - val_loss: 22.1171 - val_mae: 2.8576\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7504 - mae: 1.9864 - val_loss: 22.0920 - val_mae: 2.8463\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7491 - mae: 1.9939 - val_loss: 21.9076 - val_mae: 2.8929\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7672 - mae: 1.9927 - val_loss: 21.5334 - val_mae: 2.8087\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7057 - mae: 2.0060 - val_loss: 22.2819 - val_mae: 2.8831\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.6980 - mae: 1.9821 - val_loss: 21.5711 - val_mae: 2.8565\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5845 - mae: 1.9513 - val_loss: 21.0981 - val_mae: 2.8022\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7226 - mae: 1.9716 - val_loss: 21.3640 - val_mae: 2.7791\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.5884 - mae: 1.9757 - val_loss: 21.9372 - val_mae: 2.8626\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.5493 - mae: 1.9558 - val_loss: 21.7777 - val_mae: 2.8496\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7068 - mae: 2.0053 - val_loss: 25.9530 - val_mae: 3.0366\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.8501 - mae: 2.0054 - val_loss: 24.7980 - val_mae: 2.9887\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.6414 - mae: 1.9577 - val_loss: 23.2622 - val_mae: 2.9018\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.5235 - mae: 1.9360 - val_loss: 22.6575 - val_mae: 2.9284\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.6306 - mae: 1.9435 - val_loss: 22.4814 - val_mae: 2.9570\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.4859 - mae: 1.9330 - val_loss: 22.2836 - val_mae: 2.8915\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.4230 - mae: 1.9228 - val_loss: 21.9344 - val_mae: 2.8710\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.3264 - mae: 1.9220 - val_loss: 21.8982 - val_mae: 2.9009\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.3550 - mae: 1.9375 - val_loss: 21.9258 - val_mae: 2.9061\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.3396 - mae: 1.9394 - val_loss: 21.0877 - val_mae: 2.7871\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.4159 - mae: 1.9371 - val_loss: 21.2142 - val_mae: 2.8862\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.2812 - mae: 1.9261 - val_loss: 21.2013 - val_mae: 2.8307\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.2641 - mae: 1.9200 - val_loss: 21.2900 - val_mae: 2.8134\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.2025 - mae: 1.8890 - val_loss: 21.3849 - val_mae: 2.8666\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.1441 - mae: 1.9022 - val_loss: 21.7426 - val_mae: 2.8867\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.1412 - mae: 1.9156 - val_loss: 21.7737 - val_mae: 2.8565\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1273 - mae: 1.9088 - val_loss: 21.0118 - val_mae: 2.8047\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.0844 - mae: 1.8936 - val_loss: 21.4320 - val_mae: 2.8442\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.0048 - mae: 1.8711 - val_loss: 21.5639 - val_mae: 2.8981\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9751 - mae: 1.8548 - val_loss: 21.3729 - val_mae: 2.8452\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.9610 - mae: 1.8591 - val_loss: 21.6134 - val_mae: 2.8388\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.2116 - mae: 1.9096 - val_loss: 22.5371 - val_mae: 2.9242\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8295 - mae: 1.8562 - val_loss: 21.1087 - val_mae: 2.8071\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2586 - mae: 1.8781 - val_loss: 19.7663 - val_mae: 2.7302\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.8787 - mae: 1.8420 - val_loss: 20.8445 - val_mae: 2.8818\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.9684 - mae: 1.8875 - val_loss: 21.1940 - val_mae: 2.8465\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8549 - mae: 1.8745 - val_loss: 20.8327 - val_mae: 2.7666\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.8418 - mae: 1.8489 - val_loss: 20.6658 - val_mae: 2.8182\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8708 - mae: 1.8276 - val_loss: 21.7333 - val_mae: 2.9530\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.7987 - mae: 1.8402 - val_loss: 21.1659 - val_mae: 2.8387\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7265 - mae: 1.8500 - val_loss: 20.8441 - val_mae: 2.7792\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.6959 - mae: 1.8408 - val_loss: 21.0939 - val_mae: 2.8208\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.6885 - mae: 1.8227 - val_loss: 21.3731 - val_mae: 2.8330\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.7759 - mae: 1.8723 - val_loss: 20.8911 - val_mae: 2.8351\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.8968 - mae: 1.8286 - val_loss: 19.9272 - val_mae: 2.7665\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.9589 - mae: 1.8636 - val_loss: 21.6615 - val_mae: 2.9415\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.6186 - mae: 1.8456 - val_loss: 21.3051 - val_mae: 2.7639\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5659 - mae: 1.8222 - val_loss: 20.7236 - val_mae: 2.7998\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.5299 - mae: 1.7985 - val_loss: 20.1667 - val_mae: 2.7906\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.5946 - mae: 1.8039 - val_loss: 19.9392 - val_mae: 2.7448\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.5526 - mae: 1.8212 - val_loss: 21.0542 - val_mae: 2.8507\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.4938 - mae: 1.7858 - val_loss: 20.8567 - val_mae: 2.8069\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.4380 - mae: 1.7864 - val_loss: 21.2608 - val_mae: 2.8003\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3737 - mae: 1.7886 - val_loss: 20.4107 - val_mae: 2.8010\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3870 - mae: 1.8004 - val_loss: 20.5763 - val_mae: 2.7977\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3760 - mae: 1.7840 - val_loss: 20.6857 - val_mae: 2.8281\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.3833 - mae: 1.8118 - val_loss: 21.2893 - val_mae: 2.8194\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4220 - mae: 1.7941 - val_loss: 20.3180 - val_mae: 2.7631\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.2886 - mae: 1.7892 - val_loss: 20.6761 - val_mae: 2.7925\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2176 - mae: 1.7693 - val_loss: 20.4809 - val_mae: 2.7498\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3329 - mae: 1.7658 - val_loss: 20.6689 - val_mae: 2.7618\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2257 - mae: 1.7586 - val_loss: 21.6797 - val_mae: 2.8272\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3003 - mae: 1.8099 - val_loss: 20.6887 - val_mae: 2.7551\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1517 - mae: 1.7585 - val_loss: 20.6713 - val_mae: 2.8125\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.2006 - mae: 1.7865 - val_loss: 20.1238 - val_mae: 2.7341\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1029 - mae: 1.7375 - val_loss: 20.4454 - val_mae: 2.7979\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1585 - mae: 1.7405 - val_loss: 20.8593 - val_mae: 2.8016\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0629 - mae: 1.7388 - val_loss: 20.2312 - val_mae: 2.7516\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0759 - mae: 1.7438 - val_loss: 20.3102 - val_mae: 2.7597\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0953 - mae: 1.7655 - val_loss: 20.8177 - val_mae: 2.8124\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0447 - mae: 1.7316 - val_loss: 20.1589 - val_mae: 2.8142\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0010 - mae: 1.7294 - val_loss: 20.4460 - val_mae: 2.7893\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.9532 - mae: 1.7424 - val_loss: 20.8716 - val_mae: 2.7839\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0255 - mae: 1.7753 - val_loss: 20.1673 - val_mae: 2.7312\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9842 - mae: 1.7352 - val_loss: 20.0537 - val_mae: 2.7670\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9333 - mae: 1.7290 - val_loss: 20.2031 - val_mae: 2.7574\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9410 - mae: 1.7680 - val_loss: 20.9934 - val_mae: 2.7667\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9540 - mae: 1.7213 - val_loss: 19.9644 - val_mae: 2.7297\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8932 - mae: 1.7268 - val_loss: 20.0125 - val_mae: 2.7413\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8284 - mae: 1.6956 - val_loss: 20.0499 - val_mae: 2.7643\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7696 - mae: 1.6943 - val_loss: 20.2362 - val_mae: 2.7615\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7588 - mae: 1.6911 - val_loss: 20.4458 - val_mae: 2.7757\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7608 - mae: 1.7043 - val_loss: 20.0378 - val_mae: 2.7243\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7460 - mae: 1.6866 - val_loss: 20.1328 - val_mae: 2.7594\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.2112 - mae: 1.8319 - val_loss: 24.0803 - val_mae: 2.9640\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0315 - mae: 1.7835 - val_loss: 21.6182 - val_mae: 2.8053\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8650 - mae: 1.6894 - val_loss: 20.4504 - val_mae: 2.8192\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.7862 - mae: 1.7179 - val_loss: 20.5364 - val_mae: 2.8302\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.6885 - mae: 1.7082 - val_loss: 19.7517 - val_mae: 2.7201\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.7536 - mae: 1.6897 - val_loss: 19.5158 - val_mae: 2.6981\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5539 - mae: 1.6674 - val_loss: 20.8508 - val_mae: 2.8319\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6724 - mae: 1.7262 - val_loss: 20.4934 - val_mae: 2.7534\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6507 - mae: 1.7179 - val_loss: 19.4715 - val_mae: 2.7013\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6679 - mae: 1.6663 - val_loss: 19.4081 - val_mae: 2.7313\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6884 - mae: 1.7095 - val_loss: 19.4240 - val_mae: 2.6774\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4456 - mae: 1.6576 - val_loss: 19.2941 - val_mae: 2.6820\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6282 - mae: 1.7119 - val_loss: 19.3939 - val_mae: 2.6764\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.4515 - mae: 1.6706 - val_loss: 18.9707 - val_mae: 2.7126\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6803 - mae: 1.6500 - val_loss: 18.8391 - val_mae: 2.6514\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4742 - mae: 1.6497 - val_loss: 19.7055 - val_mae: 2.7815\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.4227 - mae: 1.6621 - val_loss: 19.0947 - val_mae: 2.7274\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4439 - mae: 1.6372 - val_loss: 19.3119 - val_mae: 2.7647\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3288 - mae: 1.6448 - val_loss: 19.8668 - val_mae: 2.7210\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3554 - mae: 1.6718 - val_loss: 20.2170 - val_mae: 2.7659\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5.2805 - mae: 1.6299 - val_loss: 19.6838 - val_mae: 2.7217\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.3526 - mae: 1.6746 - val_loss: 19.3478 - val_mae: 2.7135\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.4404 - mae: 1.6361 - val_loss: 18.9387 - val_mae: 2.6501\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2082 - mae: 1.6332 - val_loss: 19.5960 - val_mae: 2.7918\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3803 - mae: 1.6598 - val_loss: 18.9452 - val_mae: 2.7002\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1317 - mae: 1.5979 - val_loss: 18.9614 - val_mae: 2.6387\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2015 - mae: 1.6394 - val_loss: 19.0324 - val_mae: 2.7241\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1327 - mae: 1.6042 - val_loss: 18.3891 - val_mae: 2.6650\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.0733 - mae: 1.5952 - val_loss: 18.6035 - val_mae: 2.6643\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.0721 - mae: 1.6149 - val_loss: 18.6130 - val_mae: 2.6616\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.2201 - mae: 1.6420 - val_loss: 18.8286 - val_mae: 2.7404\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.0839 - mae: 1.5902 - val_loss: 18.0693 - val_mae: 2.5863\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0165 - mae: 1.5645 - val_loss: 18.6198 - val_mae: 2.6924\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.9583 - mae: 1.6104 - val_loss: 18.4542 - val_mae: 2.6581\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9601 - mae: 1.5990 - val_loss: 18.4746 - val_mae: 2.7334\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0366 - mae: 1.6100 - val_loss: 18.8212 - val_mae: 2.6774\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9568 - mae: 1.5929 - val_loss: 17.2921 - val_mae: 2.6372\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.1394 - mae: 1.6041 - val_loss: 17.7190 - val_mae: 2.5741\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.9765 - mae: 1.5932 - val_loss: 18.8083 - val_mae: 2.7724\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0036 - mae: 1.6059 - val_loss: 18.2438 - val_mae: 2.6703\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.0204 - mae: 1.5936 - val_loss: 17.7904 - val_mae: 2.5824\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.8951 - mae: 1.5464 - val_loss: 17.8509 - val_mae: 2.6399\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.9829 - mae: 1.5978 - val_loss: 18.5530 - val_mae: 2.7126\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.8319 - mae: 1.5561 - val_loss: 17.5923 - val_mae: 2.6244\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.7221 - mae: 1.5239 - val_loss: 18.5501 - val_mae: 2.7487\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.7738 - mae: 1.5749 - val_loss: 18.3128 - val_mae: 2.7020\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.7798 - mae: 1.5610 - val_loss: 17.7547 - val_mae: 2.6658\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.7524 - mae: 1.5226 - val_loss: 17.8145 - val_mae: 2.6457\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 4.6438 - mae: 1.5191 - val_loss: 18.0779 - val_mae: 2.6905\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 4.6553 - mae: 1.5643 - val_loss: 17.6905 - val_mae: 2.6447\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 4.6829 - mae: 1.5102 - val_loss: 17.3207 - val_mae: 2.6490\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 4.7321 - mae: 1.5693 - val_loss: 17.9629 - val_mae: 2.6959\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.6481 - mae: 1.5673 - val_loss: 19.9790 - val_mae: 2.7916\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 4.8809 - mae: 1.5494 - val_loss: 19.1225 - val_mae: 2.7234\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.7121 - mae: 1.5675 - val_loss: 17.8197 - val_mae: 2.6885\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 4.7150 - mae: 1.5609 - val_loss: 17.1120 - val_mae: 2.6563\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.5266 - mae: 1.5165 - val_loss: 17.4600 - val_mae: 2.6777\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 4.5711 - mae: 1.5225 - val_loss: 17.5258 - val_mae: 2.6376\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 4.6030 - mae: 1.5628 - val_loss: 17.6410 - val_mae: 2.7147\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 4.5649 - mae: 1.5055 - val_loss: 16.7171 - val_mae: 2.6118\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.4642 - mae: 1.5070 - val_loss: 17.5086 - val_mae: 2.6769\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.4052 - mae: 1.5117 - val_loss: 16.8823 - val_mae: 2.6332\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.4263 - mae: 1.4813 - val_loss: 16.9729 - val_mae: 2.6553\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.4001 - mae: 1.4981 - val_loss: 17.1682 - val_mae: 2.6739\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.3468 - mae: 1.5100 - val_loss: 16.7170 - val_mae: 2.6248\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.3667 - mae: 1.5034 - val_loss: 17.0392 - val_mae: 2.6494\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.3351 - mae: 1.5067 - val_loss: 17.1376 - val_mae: 2.5942\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.3417 - mae: 1.4874 - val_loss: 16.0026 - val_mae: 2.6200\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.3120 - mae: 1.4867 - val_loss: 15.9329 - val_mae: 2.6087\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.2764 - mae: 1.4864 - val_loss: 16.4704 - val_mae: 2.5991\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.2163 - mae: 1.4701 - val_loss: 16.7194 - val_mae: 2.6240\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.2055 - mae: 1.4508 - val_loss: 16.6072 - val_mae: 2.6261\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 8.1517 - mae: 2.1026\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 19ms/step - loss: 573.5588 - mae: 22.0821 - val_loss: 518.2653 - val_mae: 21.1315\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 544.5941 - mae: 21.4199 - val_loss: 486.6723 - val_mae: 20.3828\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 511.6929 - mae: 20.6589 - val_loss: 446.9764 - val_mae: 19.4357\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 466.7302 - mae: 19.6277 - val_loss: 394.3971 - val_mae: 18.1255\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 407.0387 - mae: 18.1875 - val_loss: 326.6001 - val_mae: 16.3161\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 330.9695 - mae: 16.1964 - val_loss: 250.7188 - val_mae: 14.0954\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 251.3732 - mae: 13.7481 - val_loss: 170.9358 - val_mae: 11.2817\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 168.6506 - mae: 10.7937 - val_loss: 108.4372 - val_mae: 8.3775\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 111.2599 - mae: 8.3659 - val_loss: 71.9577 - val_mae: 6.6377\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 78.8241 - mae: 6.8699 - val_loss: 56.9462 - val_mae: 5.8129\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 61.4650 - mae: 5.9479 - val_loss: 47.7086 - val_mae: 5.2757\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 49.9450 - mae: 5.2973 - val_loss: 41.6661 - val_mae: 5.0026\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 42.5265 - mae: 4.8488 - val_loss: 36.0935 - val_mae: 4.6559\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 36.7694 - mae: 4.4237 - val_loss: 30.6072 - val_mae: 4.2743\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 32.3386 - mae: 4.1167 - val_loss: 27.1992 - val_mae: 4.0060\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 29.1818 - mae: 3.8754 - val_loss: 24.7439 - val_mae: 3.8317\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 26.9618 - mae: 3.6809 - val_loss: 23.2200 - val_mae: 3.6905\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 25.4658 - mae: 3.5623 - val_loss: 22.1366 - val_mae: 3.6007\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 23.9870 - mae: 3.4556 - val_loss: 21.2907 - val_mae: 3.5311\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 22.7791 - mae: 3.3616 - val_loss: 20.3950 - val_mae: 3.4573\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 21.9002 - mae: 3.3055 - val_loss: 19.8548 - val_mae: 3.4185\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 21.2331 - mae: 3.2412 - val_loss: 18.9940 - val_mae: 3.3351\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 20.4928 - mae: 3.1838 - val_loss: 18.3446 - val_mae: 3.2708\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 19.8343 - mae: 3.1329 - val_loss: 17.9489 - val_mae: 3.2265\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 19.3603 - mae: 3.0847 - val_loss: 17.2793 - val_mae: 3.1411\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 18.8967 - mae: 3.0306 - val_loss: 16.5904 - val_mae: 3.0436\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 18.6314 - mae: 2.9943 - val_loss: 16.3456 - val_mae: 3.0222\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 18.0657 - mae: 2.9433 - val_loss: 16.3344 - val_mae: 3.0291\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 17.8867 - mae: 2.9322 - val_loss: 16.0962 - val_mae: 2.9955\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 17.4734 - mae: 2.8880 - val_loss: 15.7389 - val_mae: 2.9523\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 17.1252 - mae: 2.8370 - val_loss: 15.4032 - val_mae: 2.9071\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 16.8332 - mae: 2.8012 - val_loss: 15.1001 - val_mae: 2.8755\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 16.5460 - mae: 2.7705 - val_loss: 14.7078 - val_mae: 2.8070\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 16.4044 - mae: 2.7516 - val_loss: 14.4075 - val_mae: 2.8034\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 16.0626 - mae: 2.7144 - val_loss: 14.3495 - val_mae: 2.7876\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15.8032 - mae: 2.7002 - val_loss: 14.1761 - val_mae: 2.7715\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 15.5575 - mae: 2.6812 - val_loss: 14.0629 - val_mae: 2.7599\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.3097 - mae: 2.6734 - val_loss: 13.9426 - val_mae: 2.7650\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 15.0263 - mae: 2.6612 - val_loss: 13.6678 - val_mae: 2.7358\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.8527 - mae: 2.6380 - val_loss: 13.7498 - val_mae: 2.7173\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.8796 - mae: 2.6156 - val_loss: 13.7694 - val_mae: 2.7159\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.6068 - mae: 2.6125 - val_loss: 13.6576 - val_mae: 2.7345\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.3684 - mae: 2.6136 - val_loss: 13.4958 - val_mae: 2.7277\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.1592 - mae: 2.6043 - val_loss: 13.1579 - val_mae: 2.6916\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.1673 - mae: 2.5914 - val_loss: 12.8999 - val_mae: 2.6415\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.9627 - mae: 2.5629 - val_loss: 12.9111 - val_mae: 2.6333\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.0513 - mae: 2.5502 - val_loss: 13.1172 - val_mae: 2.6445\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.7803 - mae: 2.5172 - val_loss: 12.9048 - val_mae: 2.6456\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.5247 - mae: 2.5335 - val_loss: 12.9786 - val_mae: 2.6770\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.4533 - mae: 2.5447 - val_loss: 12.8096 - val_mae: 2.6701\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.2535 - mae: 2.5332 - val_loss: 12.9031 - val_mae: 2.6665\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.1464 - mae: 2.5000 - val_loss: 12.7202 - val_mae: 2.6360\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.0158 - mae: 2.4697 - val_loss: 12.7964 - val_mae: 2.6363\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.0010 - mae: 2.5476 - val_loss: 13.2412 - val_mae: 2.7425\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.1163 - mae: 2.5889 - val_loss: 12.6431 - val_mae: 2.6508\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.6459 - mae: 2.5106 - val_loss: 12.4486 - val_mae: 2.5975\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.4729 - mae: 2.4629 - val_loss: 12.2936 - val_mae: 2.5753\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.3996 - mae: 2.4497 - val_loss: 12.2385 - val_mae: 2.5818\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3090 - mae: 2.4351 - val_loss: 12.1329 - val_mae: 2.5630\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.1988 - mae: 2.4268 - val_loss: 12.0282 - val_mae: 2.5639\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.1318 - mae: 2.4346 - val_loss: 11.9677 - val_mae: 2.5602\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1363 - mae: 2.4446 - val_loss: 11.6821 - val_mae: 2.5260\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.1192 - mae: 2.4588 - val_loss: 11.8286 - val_mae: 2.5516\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.8436 - mae: 2.4269 - val_loss: 12.0386 - val_mae: 2.5726\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8002 - mae: 2.4097 - val_loss: 11.8627 - val_mae: 2.5556\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6726 - mae: 2.3938 - val_loss: 11.6274 - val_mae: 2.5523\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6333 - mae: 2.3947 - val_loss: 11.4509 - val_mae: 2.5249\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.5758 - mae: 2.3885 - val_loss: 11.6407 - val_mae: 2.5364\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.5196 - mae: 2.3742 - val_loss: 11.5316 - val_mae: 2.5253\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 11.5211 - mae: 2.3590 - val_loss: 11.3682 - val_mae: 2.5054\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.5414 - mae: 2.3692 - val_loss: 11.9851 - val_mae: 2.5793\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3217 - mae: 2.3614 - val_loss: 11.4945 - val_mae: 2.5186\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.1932 - mae: 2.3384 - val_loss: 11.3461 - val_mae: 2.4918\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.1116 - mae: 2.3243 - val_loss: 11.4824 - val_mae: 2.5141\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.9722 - mae: 2.3236 - val_loss: 11.1794 - val_mae: 2.4835\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.9292 - mae: 2.3391 - val_loss: 11.2641 - val_mae: 2.4889\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.8831 - mae: 2.3000 - val_loss: 11.3174 - val_mae: 2.4903\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.8492 - mae: 2.2944 - val_loss: 11.1872 - val_mae: 2.4834\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.7473 - mae: 2.3055 - val_loss: 11.2376 - val_mae: 2.4912\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.6713 - mae: 2.2522 - val_loss: 11.1330 - val_mae: 2.4640\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.5651 - mae: 2.2527 - val_loss: 11.0369 - val_mae: 2.4495\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.6681 - mae: 2.3052 - val_loss: 11.1874 - val_mae: 2.4759\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.5134 - mae: 2.2750 - val_loss: 11.1884 - val_mae: 2.4832\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.3766 - mae: 2.2442 - val_loss: 10.9952 - val_mae: 2.4589\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 10.4346 - mae: 2.2266 - val_loss: 10.9783 - val_mae: 2.4647\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 10.2825 - mae: 2.2213 - val_loss: 10.9517 - val_mae: 2.4678\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.2038 - mae: 2.2311 - val_loss: 10.8680 - val_mae: 2.4730\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.2381 - mae: 2.2646 - val_loss: 10.7600 - val_mae: 2.4577\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.1498 - mae: 2.2127 - val_loss: 11.2179 - val_mae: 2.4990\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.2953 - mae: 2.2234 - val_loss: 11.1853 - val_mae: 2.4948\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.0933 - mae: 2.2202 - val_loss: 10.9905 - val_mae: 2.4769\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.9620 - mae: 2.2269 - val_loss: 10.9145 - val_mae: 2.4737\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.9189 - mae: 2.2221 - val_loss: 11.0195 - val_mae: 2.4906\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.8297 - mae: 2.1933 - val_loss: 10.8995 - val_mae: 2.4730\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.8703 - mae: 2.2115 - val_loss: 10.9642 - val_mae: 2.4822\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.0346 - mae: 2.2234 - val_loss: 11.4428 - val_mae: 2.5430\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.7452 - mae: 2.1722 - val_loss: 11.0621 - val_mae: 2.4905\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.6357 - mae: 2.1858 - val_loss: 11.1787 - val_mae: 2.5078\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.5968 - mae: 2.1822 - val_loss: 10.9726 - val_mae: 2.4836\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.8076 - mae: 2.2109 - val_loss: 11.5746 - val_mae: 2.5717\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.6375 - mae: 2.1877 - val_loss: 10.9447 - val_mae: 2.4717\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.4298 - mae: 2.1535 - val_loss: 11.0147 - val_mae: 2.4893\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.3935 - mae: 2.1565 - val_loss: 10.9423 - val_mae: 2.4961\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.3503 - mae: 2.1546 - val_loss: 10.7630 - val_mae: 2.4713\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.4344 - mae: 2.1870 - val_loss: 10.7735 - val_mae: 2.4725\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.2797 - mae: 2.1472 - val_loss: 11.1350 - val_mae: 2.5224\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.2590 - mae: 2.1512 - val_loss: 11.0145 - val_mae: 2.5029\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.1392 - mae: 2.1333 - val_loss: 10.8645 - val_mae: 2.4807\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 9.0875 - mae: 2.1291 - val_loss: 10.7741 - val_mae: 2.4662\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.0346 - mae: 2.1255 - val_loss: 10.8628 - val_mae: 2.4765\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.0810 - mae: 2.1301 - val_loss: 11.1937 - val_mae: 2.5354\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.0349 - mae: 2.1311 - val_loss: 10.9180 - val_mae: 2.4883\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.9828 - mae: 2.1195 - val_loss: 10.6692 - val_mae: 2.4461\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.8959 - mae: 2.0878 - val_loss: 10.9204 - val_mae: 2.4864\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.8970 - mae: 2.0825 - val_loss: 10.7604 - val_mae: 2.4471\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.7397 - mae: 2.0703 - val_loss: 10.8584 - val_mae: 2.4675\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.7401 - mae: 2.0877 - val_loss: 10.7616 - val_mae: 2.4630\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.7099 - mae: 2.0750 - val_loss: 10.6556 - val_mae: 2.4548\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6647 - mae: 2.0933 - val_loss: 10.6097 - val_mae: 2.4505\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.6468 - mae: 2.0717 - val_loss: 10.5448 - val_mae: 2.4514\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5939 - mae: 2.0840 - val_loss: 10.7209 - val_mae: 2.4239\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5944 - mae: 2.1008 - val_loss: 10.6128 - val_mae: 2.4218\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.6024 - mae: 2.0820 - val_loss: 10.4195 - val_mae: 2.4189\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.4025 - mae: 2.0590 - val_loss: 10.6469 - val_mae: 2.4597\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.3827 - mae: 2.0705 - val_loss: 10.6320 - val_mae: 2.4630\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.3246 - mae: 2.0497 - val_loss: 10.5308 - val_mae: 2.4527\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.2915 - mae: 2.0515 - val_loss: 10.5750 - val_mae: 2.4605\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.1693 - mae: 2.0292 - val_loss: 10.3432 - val_mae: 2.4203\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.2410 - mae: 2.0321 - val_loss: 10.4386 - val_mae: 2.4453\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.1479 - mae: 2.0172 - val_loss: 10.4341 - val_mae: 2.4558\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.1488 - mae: 2.0312 - val_loss: 10.5044 - val_mae: 2.4653\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.1382 - mae: 2.0243 - val_loss: 10.4119 - val_mae: 2.4241\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.0205 - mae: 1.9952 - val_loss: 10.2903 - val_mae: 2.4099\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.9711 - mae: 2.0079 - val_loss: 10.2502 - val_mae: 2.4087\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.9294 - mae: 2.0070 - val_loss: 10.2859 - val_mae: 2.4268\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.9664 - mae: 2.0306 - val_loss: 10.4630 - val_mae: 2.4695\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.0449 - mae: 2.0039 - val_loss: 10.2543 - val_mae: 2.4305\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.9000 - mae: 2.0067 - val_loss: 10.0093 - val_mae: 2.3828\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.7283 - mae: 1.9829 - val_loss: 10.2636 - val_mae: 2.4245\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.8651 - mae: 2.0214 - val_loss: 10.5789 - val_mae: 2.4348\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6699 - mae: 1.9707 - val_loss: 10.1037 - val_mae: 2.3721\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7096 - mae: 1.9760 - val_loss: 10.1000 - val_mae: 2.3890\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.5458 - mae: 1.9539 - val_loss: 10.3529 - val_mae: 2.4491\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.6703 - mae: 1.9616 - val_loss: 10.2569 - val_mae: 2.4282\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.5954 - mae: 1.9469 - val_loss: 10.0731 - val_mae: 2.4141\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5411 - mae: 1.9634 - val_loss: 10.6429 - val_mae: 2.5285\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.6828 - mae: 1.9916 - val_loss: 10.2253 - val_mae: 2.4449\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.4482 - mae: 1.9410 - val_loss: 9.8417 - val_mae: 2.3608\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.5276 - mae: 1.9744 - val_loss: 9.9777 - val_mae: 2.3914\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6617 - mae: 1.9671 - val_loss: 9.9787 - val_mae: 2.3401\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.8197 - mae: 2.0567 - val_loss: 10.8288 - val_mae: 2.5029\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.3923 - mae: 1.9920 - val_loss: 10.2537 - val_mae: 2.3996\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2828 - mae: 1.9448 - val_loss: 10.6078 - val_mae: 2.4824\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.2100 - mae: 1.9190 - val_loss: 10.1383 - val_mae: 2.4090\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.3579 - mae: 1.9839 - val_loss: 10.3159 - val_mae: 2.4571\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.2472 - mae: 1.9400 - val_loss: 10.0662 - val_mae: 2.3868\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.3085 - mae: 1.9057 - val_loss: 9.6214 - val_mae: 2.3569\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2325 - mae: 1.9475 - val_loss: 9.9016 - val_mae: 2.3975\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.0378 - mae: 1.9033 - val_loss: 9.7787 - val_mae: 2.3552\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9523 - mae: 1.8778 - val_loss: 9.9400 - val_mae: 2.3877\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.0181 - mae: 1.9106 - val_loss: 10.0372 - val_mae: 2.3583\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9452 - mae: 1.8738 - val_loss: 10.0857 - val_mae: 2.3587\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.0161 - mae: 1.8880 - val_loss: 9.7274 - val_mae: 2.3204\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.8234 - mae: 1.8885 - val_loss: 10.2080 - val_mae: 2.4513\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8980 - mae: 1.8969 - val_loss: 10.1817 - val_mae: 2.3936\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9157 - mae: 1.8697 - val_loss: 10.5297 - val_mae: 2.4495\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8161 - mae: 1.8586 - val_loss: 10.4026 - val_mae: 2.4382\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.7623 - mae: 1.8666 - val_loss: 10.0057 - val_mae: 2.3734\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8295 - mae: 1.8394 - val_loss: 10.3108 - val_mae: 2.4029\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8378 - mae: 1.8580 - val_loss: 9.9416 - val_mae: 2.3901\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.6028 - mae: 1.8522 - val_loss: 9.8359 - val_mae: 2.3773\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5350 - mae: 1.8463 - val_loss: 9.8484 - val_mae: 2.3904\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4814 - mae: 1.8327 - val_loss: 9.5807 - val_mae: 2.3124\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4268 - mae: 1.8155 - val_loss: 9.6695 - val_mae: 2.3356\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3824 - mae: 1.8007 - val_loss: 9.7512 - val_mae: 2.3573\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3474 - mae: 1.8053 - val_loss: 9.7275 - val_mae: 2.3472\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.2995 - mae: 1.7984 - val_loss: 9.6753 - val_mae: 2.3307\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.3011 - mae: 1.7977 - val_loss: 9.6859 - val_mae: 2.3385\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3299 - mae: 1.7943 - val_loss: 9.6409 - val_mae: 2.3252\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.2177 - mae: 1.7878 - val_loss: 9.8521 - val_mae: 2.3787\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2740 - mae: 1.8049 - val_loss: 9.6710 - val_mae: 2.3144\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3139 - mae: 1.7916 - val_loss: 9.8699 - val_mae: 2.3686\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1823 - mae: 1.7833 - val_loss: 9.9170 - val_mae: 2.3847\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.2748 - mae: 1.7849 - val_loss: 9.9221 - val_mae: 2.3860\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1172 - mae: 1.7531 - val_loss: 9.6888 - val_mae: 2.3269\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.5258 - mae: 1.7874 - val_loss: 10.2373 - val_mae: 2.4421\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.2103 - mae: 1.7756 - val_loss: 10.0638 - val_mae: 2.4458\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.1293 - mae: 1.7636 - val_loss: 9.9915 - val_mae: 2.4054\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0082 - mae: 1.7469 - val_loss: 10.0573 - val_mae: 2.4322\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0818 - mae: 1.7896 - val_loss: 10.1885 - val_mae: 2.4575\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0212 - mae: 1.7624 - val_loss: 9.9203 - val_mae: 2.3882\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.9027 - mae: 1.7564 - val_loss: 10.2193 - val_mae: 2.4252\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.9869 - mae: 1.7723 - val_loss: 9.9820 - val_mae: 2.3896\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8603 - mae: 1.7299 - val_loss: 9.7933 - val_mae: 2.3514\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8494 - mae: 1.7336 - val_loss: 9.9400 - val_mae: 2.3942\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8099 - mae: 1.7565 - val_loss: 9.7783 - val_mae: 2.3584\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8410 - mae: 1.7328 - val_loss: 9.6961 - val_mae: 2.3133\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7025 - mae: 1.7062 - val_loss: 9.8920 - val_mae: 2.3693\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8371 - mae: 1.7701 - val_loss: 10.2296 - val_mae: 2.4451\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.7790 - mae: 1.7566 - val_loss: 9.9568 - val_mae: 2.3621\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.7775 - mae: 1.7472 - val_loss: 10.2742 - val_mae: 2.4071\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6643 - mae: 1.7041 - val_loss: 9.9390 - val_mae: 2.3402\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7309 - mae: 1.7234 - val_loss: 9.9333 - val_mae: 2.3536\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5669 - mae: 1.6962 - val_loss: 10.0517 - val_mae: 2.3929\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5541 - mae: 1.6894 - val_loss: 9.9922 - val_mae: 2.3862\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5139 - mae: 1.6710 - val_loss: 9.9040 - val_mae: 2.3563\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5159 - mae: 1.6844 - val_loss: 9.9859 - val_mae: 2.3631\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4637 - mae: 1.6995 - val_loss: 9.9416 - val_mae: 2.3514\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4174 - mae: 1.6672 - val_loss: 9.8372 - val_mae: 2.3262\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4436 - mae: 1.6713 - val_loss: 10.1510 - val_mae: 2.3766\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3913 - mae: 1.6602 - val_loss: 9.8754 - val_mae: 2.3231\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3210 - mae: 1.6459 - val_loss: 10.1326 - val_mae: 2.3696\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.8928 - mae: 1.9071 - val_loss: 11.1689 - val_mae: 2.4699\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.7535 - mae: 1.7542 - val_loss: 10.5955 - val_mae: 2.3864\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5069 - mae: 1.7081 - val_loss: 10.2294 - val_mae: 2.3137\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.3224 - mae: 1.6708 - val_loss: 10.3311 - val_mae: 2.3781\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2551 - mae: 1.6508 - val_loss: 10.1952 - val_mae: 2.3566\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.2081 - mae: 1.6490 - val_loss: 10.1625 - val_mae: 2.3576\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1934 - mae: 1.6482 - val_loss: 9.7805 - val_mae: 2.3074\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.2900 - mae: 1.6842 - val_loss: 10.1412 - val_mae: 2.4006\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5367 - mae: 1.6815 - val_loss: 10.0654 - val_mae: 2.3846\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.2107 - mae: 1.6518 - val_loss: 10.2949 - val_mae: 2.4353\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.0827 - mae: 1.6238 - val_loss: 9.9474 - val_mae: 2.3257\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0804 - mae: 1.6173 - val_loss: 10.0597 - val_mae: 2.3295\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0124 - mae: 1.6341 - val_loss: 10.2071 - val_mae: 2.3667\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1334 - mae: 1.6272 - val_loss: 10.0091 - val_mae: 2.3211\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.0518 - mae: 1.6103 - val_loss: 10.4646 - val_mae: 2.4492\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.0166 - mae: 1.6180 - val_loss: 9.8561 - val_mae: 2.3174\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.9270 - mae: 1.6068 - val_loss: 10.0232 - val_mae: 2.3706\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.8611 - mae: 1.5890 - val_loss: 9.9145 - val_mae: 2.3256\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8783 - mae: 1.5733 - val_loss: 9.8814 - val_mae: 2.3065\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8494 - mae: 1.5771 - val_loss: 9.9764 - val_mae: 2.3392\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8094 - mae: 1.5695 - val_loss: 9.9196 - val_mae: 2.3072\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4.7992 - mae: 1.5524 - val_loss: 9.9789 - val_mae: 2.3305\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7910 - mae: 1.5586 - val_loss: 10.2939 - val_mae: 2.3891\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8940 - mae: 1.5786 - val_loss: 10.3028 - val_mae: 2.3901\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.7895 - mae: 1.5546 - val_loss: 10.0928 - val_mae: 2.3485\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7628 - mae: 1.5747 - val_loss: 10.0397 - val_mae: 2.3300\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.8793 - mae: 1.5785 - val_loss: 9.9079 - val_mae: 2.3376\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.8396 - mae: 1.5693 - val_loss: 9.8852 - val_mae: 2.2987\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.7123 - mae: 1.5545 - val_loss: 9.9205 - val_mae: 2.3346\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7999 - mae: 1.5483 - val_loss: 9.6958 - val_mae: 2.2669\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.2325 - mae: 1.6765 - val_loss: 10.4007 - val_mae: 2.4358\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.7828 - mae: 1.5671 - val_loss: 9.8122 - val_mae: 2.2880\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.7324 - mae: 1.5611 - val_loss: 10.1308 - val_mae: 2.3802\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.6342 - mae: 1.5323 - val_loss: 9.9399 - val_mae: 2.3225\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.5988 - mae: 1.5314 - val_loss: 10.0273 - val_mae: 2.3353\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.9846 - mae: 1.5504 - val_loss: 10.0063 - val_mae: 2.3305\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.9148 - mae: 1.6077 - val_loss: 10.1888 - val_mae: 2.3551\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7105 - mae: 1.5597 - val_loss: 9.5827 - val_mae: 2.2572\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.6003 - mae: 1.5117 - val_loss: 9.7427 - val_mae: 2.3100\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.4883 - mae: 1.5052 - val_loss: 9.7102 - val_mae: 2.2848\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4551 - mae: 1.4969 - val_loss: 9.6780 - val_mae: 2.2833\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5409 - mae: 1.5408 - val_loss: 10.0016 - val_mae: 2.3675\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.4845 - mae: 1.5152 - val_loss: 9.8944 - val_mae: 2.3059\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.5163 - mae: 1.4916 - val_loss: 9.9331 - val_mae: 2.3177\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4349 - mae: 1.5264 - val_loss: 10.0143 - val_mae: 2.3279\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.3934 - mae: 1.4808 - val_loss: 9.9020 - val_mae: 2.2989\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.3250 - mae: 1.4639 - val_loss: 9.9283 - val_mae: 2.3171\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.3031 - mae: 1.4758 - val_loss: 10.1135 - val_mae: 2.3417\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.2630 - mae: 1.4543 - val_loss: 10.1332 - val_mae: 2.3291\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8780 - mae: 1.7911 - val_loss: 11.6956 - val_mae: 2.5035\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7659 - mae: 1.5861 - val_loss: 10.8566 - val_mae: 2.4027\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.6664 - mae: 1.5448 - val_loss: 10.5102 - val_mae: 2.3628\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.6811 - mae: 1.5849 - val_loss: 10.5300 - val_mae: 2.3653\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3634 - mae: 1.5151 - val_loss: 10.1320 - val_mae: 2.3401\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4040 - mae: 1.5053 - val_loss: 9.8739 - val_mae: 2.3081\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.4468 - mae: 1.5362 - val_loss: 10.0189 - val_mae: 2.3341\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.4706 - mae: 1.5659 - val_loss: 10.5871 - val_mae: 2.4652\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1942 - mae: 1.4492 - val_loss: 9.8260 - val_mae: 2.2852\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.2481 - mae: 1.4646 - val_loss: 10.1043 - val_mae: 2.3296\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.1212 - mae: 1.4676 - val_loss: 10.1943 - val_mae: 2.3827\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.1444 - mae: 1.4642 - val_loss: 9.8658 - val_mae: 2.2898\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0354 - mae: 1.4287 - val_loss: 10.2069 - val_mae: 2.3560\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.9939 - mae: 1.4116 - val_loss: 10.0996 - val_mae: 2.3460\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.2221 - mae: 1.4575 - val_loss: 10.1110 - val_mae: 2.3183\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.1184 - mae: 1.4614 - val_loss: 9.9512 - val_mae: 2.2696\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0707 - mae: 1.4317 - val_loss: 10.0432 - val_mae: 2.3228\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.9694 - mae: 1.4137 - val_loss: 10.2253 - val_mae: 2.3491\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.0442 - mae: 1.4494 - val_loss: 10.3158 - val_mae: 2.3770\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9199 - mae: 1.4003 - val_loss: 10.0658 - val_mae: 2.3279\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9728 - mae: 1.4132 - val_loss: 10.0118 - val_mae: 2.3069\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.8952 - mae: 1.4051 - val_loss: 10.1644 - val_mae: 2.3461\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.0571 - mae: 1.4628 - val_loss: 10.1053 - val_mae: 2.3407\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.9333 - mae: 1.4078 - val_loss: 10.0332 - val_mae: 2.3231\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9768 - mae: 1.4068 - val_loss: 10.0563 - val_mae: 2.3495\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.9323 - mae: 1.4314 - val_loss: 10.1880 - val_mae: 2.3582\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.8743 - mae: 1.3995 - val_loss: 9.9285 - val_mae: 2.3114\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.8819 - mae: 1.3879 - val_loss: 9.9562 - val_mae: 2.2867\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7902 - mae: 1.3643 - val_loss: 10.2396 - val_mae: 2.3541\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.8311 - mae: 1.3827 - val_loss: 10.1988 - val_mae: 2.3493\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.8138 - mae: 1.3893 - val_loss: 9.9167 - val_mae: 2.3021\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.8983 - mae: 1.3823 - val_loss: 9.7595 - val_mae: 2.3092\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.8608 - mae: 1.4048 - val_loss: 9.8038 - val_mae: 2.2866\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.7582 - mae: 1.3831 - val_loss: 10.0128 - val_mae: 2.3193\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7535 - mae: 1.3577 - val_loss: 10.0251 - val_mae: 2.3228\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7024 - mae: 1.3568 - val_loss: 10.0519 - val_mae: 2.2942\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.7811 - mae: 1.4092 - val_loss: 9.9264 - val_mae: 2.2748\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.7620 - mae: 1.3692 - val_loss: 9.8736 - val_mae: 2.2940\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7242 - mae: 1.3655 - val_loss: 10.0462 - val_mae: 2.3411\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.6972 - mae: 2.0328\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 26ms/step - loss: 596.3875 - mae: 22.5859 - val_loss: 494.6275 - val_mae: 20.5516\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 568.2237 - mae: 21.9512 - val_loss: 470.9678 - val_mae: 19.9734\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 538.0485 - mae: 21.2638 - val_loss: 441.8364 - val_mae: 19.2676\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 499.4326 - mae: 20.3808 - val_loss: 403.0516 - val_mae: 18.3029\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 447.2588 - mae: 19.1460 - val_loss: 350.9407 - val_mae: 16.9291\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 380.7992 - mae: 17.4566 - val_loss: 286.3472 - val_mae: 15.0956\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 302.2429 - mae: 15.2954 - val_loss: 216.4358 - val_mae: 12.9650\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 223.1224 - mae: 12.7448 - val_loss: 151.0175 - val_mae: 10.6912\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 152.6405 - mae: 10.1170 - val_loss: 100.2723 - val_mae: 8.5546\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 102.3321 - mae: 7.8979 - val_loss: 68.3597 - val_mae: 7.0531\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 72.0829 - mae: 6.4426 - val_loss: 54.3967 - val_mae: 6.1100\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 59.3564 - mae: 5.7621 - val_loss: 46.7591 - val_mae: 5.6551\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 52.4138 - mae: 5.4127 - val_loss: 40.8909 - val_mae: 5.2981\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 46.0332 - mae: 5.1079 - val_loss: 35.7678 - val_mae: 5.0025\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 41.4905 - mae: 4.8029 - val_loss: 31.0347 - val_mae: 4.6764\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 37.4631 - mae: 4.5111 - val_loss: 27.7993 - val_mae: 4.4288\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 34.4239 - mae: 4.2736 - val_loss: 25.2738 - val_mae: 4.1875\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 32.1586 - mae: 4.0682 - val_loss: 23.2556 - val_mae: 3.9715\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 30.3532 - mae: 3.9095 - val_loss: 21.7617 - val_mae: 3.7937\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 28.9666 - mae: 3.8001 - val_loss: 20.5658 - val_mae: 3.6514\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 27.5892 - mae: 3.7287 - val_loss: 19.8063 - val_mae: 3.5745\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 26.5832 - mae: 3.6893 - val_loss: 19.2361 - val_mae: 3.5130\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 25.6694 - mae: 3.6085 - val_loss: 18.2207 - val_mae: 3.3774\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 24.8210 - mae: 3.5237 - val_loss: 17.6945 - val_mae: 3.3118\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 24.2182 - mae: 3.5005 - val_loss: 17.3036 - val_mae: 3.2746\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 23.3315 - mae: 3.4360 - val_loss: 16.7302 - val_mae: 3.1979\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 22.7722 - mae: 3.3783 - val_loss: 16.0499 - val_mae: 3.1141\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 22.1232 - mae: 3.3443 - val_loss: 15.8259 - val_mae: 3.0854\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 21.5577 - mae: 3.3144 - val_loss: 15.7524 - val_mae: 3.0728\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 21.2953 - mae: 3.3176 - val_loss: 15.6080 - val_mae: 3.0524\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 20.7610 - mae: 3.2536 - val_loss: 14.4163 - val_mae: 2.9220\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 20.2606 - mae: 3.2243 - val_loss: 14.6081 - val_mae: 2.9365\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 19.8033 - mae: 3.1923 - val_loss: 14.3126 - val_mae: 2.9030\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 19.3070 - mae: 3.1567 - val_loss: 14.3051 - val_mae: 2.9075\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 18.8541 - mae: 3.1301 - val_loss: 13.9810 - val_mae: 2.8795\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 18.4211 - mae: 3.0767 - val_loss: 13.2178 - val_mae: 2.7837\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 18.1226 - mae: 3.0493 - val_loss: 13.0198 - val_mae: 2.7622\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 17.7333 - mae: 3.0195 - val_loss: 12.9199 - val_mae: 2.7434\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 17.4212 - mae: 2.9838 - val_loss: 12.6609 - val_mae: 2.7091\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 17.5034 - mae: 3.0458 - val_loss: 14.9126 - val_mae: 2.9234\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 17.1991 - mae: 3.0498 - val_loss: 13.6464 - val_mae: 2.8128\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 16.5545 - mae: 2.9405 - val_loss: 12.0126 - val_mae: 2.6353\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 16.1674 - mae: 2.8737 - val_loss: 11.6513 - val_mae: 2.5861\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.9587 - mae: 2.8437 - val_loss: 11.3500 - val_mae: 2.5377\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.6887 - mae: 2.8215 - val_loss: 11.5265 - val_mae: 2.5471\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.4758 - mae: 2.8152 - val_loss: 11.6936 - val_mae: 2.5533\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15.2270 - mae: 2.7723 - val_loss: 10.8053 - val_mae: 2.4495\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.0451 - mae: 2.7452 - val_loss: 10.8120 - val_mae: 2.4385\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.7879 - mae: 2.7325 - val_loss: 11.2705 - val_mae: 2.4732\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 14.4703 - mae: 2.7642 - val_loss: 12.2405 - val_mae: 2.6034\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.5504 - mae: 2.7861 - val_loss: 11.5525 - val_mae: 2.5202\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 14.3466 - mae: 2.7343 - val_loss: 10.7129 - val_mae: 2.4220\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.0354 - mae: 2.6830 - val_loss: 10.3726 - val_mae: 2.4006\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.9289 - mae: 2.6607 - val_loss: 10.3590 - val_mae: 2.4047\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 13.7396 - mae: 2.6561 - val_loss: 10.5458 - val_mae: 2.4281\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.6567 - mae: 2.6613 - val_loss: 10.6287 - val_mae: 2.4377\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.4282 - mae: 2.6383 - val_loss: 10.4246 - val_mae: 2.4193\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 13.2843 - mae: 2.6220 - val_loss: 10.3251 - val_mae: 2.4094\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.1637 - mae: 2.6066 - val_loss: 10.3168 - val_mae: 2.4182\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.0493 - mae: 2.6033 - val_loss: 10.4183 - val_mae: 2.4318\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.9868 - mae: 2.6056 - val_loss: 10.5609 - val_mae: 2.4494\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.7956 - mae: 2.5696 - val_loss: 10.3980 - val_mae: 2.4331\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 12.8249 - mae: 2.5687 - val_loss: 10.6737 - val_mae: 2.4680\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 12.6103 - mae: 2.5552 - val_loss: 10.3754 - val_mae: 2.4420\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 12.4636 - mae: 2.5398 - val_loss: 10.0919 - val_mae: 2.4099\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.3721 - mae: 2.5242 - val_loss: 10.0192 - val_mae: 2.3951\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.2635 - mae: 2.4997 - val_loss: 9.7619 - val_mae: 2.3601\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 12.2023 - mae: 2.4897 - val_loss: 10.0255 - val_mae: 2.3939\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.2904 - mae: 2.5354 - val_loss: 11.1761 - val_mae: 2.5516\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 12.1682 - mae: 2.5242 - val_loss: 9.6820 - val_mae: 2.3607\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 11.9138 - mae: 2.4728 - val_loss: 9.9067 - val_mae: 2.3848\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 11.8518 - mae: 2.4808 - val_loss: 10.1656 - val_mae: 2.4197\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 11.6965 - mae: 2.4534 - val_loss: 9.7217 - val_mae: 2.3562\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 11.8570 - mae: 2.4389 - val_loss: 9.3954 - val_mae: 2.3196\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 11.7215 - mae: 2.4394 - val_loss: 10.0687 - val_mae: 2.4185\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 11.4553 - mae: 2.4303 - val_loss: 10.0025 - val_mae: 2.4013\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 11.4691 - mae: 2.4283 - val_loss: 10.2910 - val_mae: 2.4358\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 11.3493 - mae: 2.4216 - val_loss: 9.6645 - val_mae: 2.3712\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 11.2646 - mae: 2.3942 - val_loss: 9.6763 - val_mae: 2.3617\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 11.2250 - mae: 2.3885 - val_loss: 10.0723 - val_mae: 2.4077\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.1415 - mae: 2.3825 - val_loss: 9.5980 - val_mae: 2.3704\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 11.1155 - mae: 2.3770 - val_loss: 9.8962 - val_mae: 2.4053\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.9269 - mae: 2.3722 - val_loss: 9.9521 - val_mae: 2.3990\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.9105 - mae: 2.3627 - val_loss: 9.7811 - val_mae: 2.3684\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.7428 - mae: 2.3516 - val_loss: 10.3340 - val_mae: 2.4652\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.7980 - mae: 2.3816 - val_loss: 10.6432 - val_mae: 2.5132\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.6868 - mae: 2.3546 - val_loss: 10.1399 - val_mae: 2.4230\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.6232 - mae: 2.3348 - val_loss: 9.6612 - val_mae: 2.3548\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.5372 - mae: 2.3169 - val_loss: 9.4263 - val_mae: 2.3333\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.5454 - mae: 2.3298 - val_loss: 9.9279 - val_mae: 2.4176\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.4546 - mae: 2.3328 - val_loss: 10.6008 - val_mae: 2.4896\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.3841 - mae: 2.3183 - val_loss: 9.8502 - val_mae: 2.3717\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.4130 - mae: 2.3108 - val_loss: 9.7653 - val_mae: 2.3472\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.2333 - mae: 2.2900 - val_loss: 9.5535 - val_mae: 2.3644\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.1953 - mae: 2.2891 - val_loss: 10.2503 - val_mae: 2.4516\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.2449 - mae: 2.3184 - val_loss: 11.3021 - val_mae: 2.5845\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.4335 - mae: 2.3467 - val_loss: 10.9633 - val_mae: 2.5262\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.2168 - mae: 2.2772 - val_loss: 9.0883 - val_mae: 2.2558\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.0439 - mae: 2.2520 - val_loss: 9.7529 - val_mae: 2.3819\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.9451 - mae: 2.2565 - val_loss: 9.9511 - val_mae: 2.4148\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.0838 - mae: 2.2738 - val_loss: 10.6804 - val_mae: 2.4873\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.9616 - mae: 2.2710 - val_loss: 9.2302 - val_mae: 2.2978\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.7378 - mae: 2.2381 - val_loss: 10.2309 - val_mae: 2.4438\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.7783 - mae: 2.2616 - val_loss: 10.1420 - val_mae: 2.4075\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.7466 - mae: 2.2387 - val_loss: 10.1814 - val_mae: 2.4323\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.0631 - mae: 2.3185 - val_loss: 12.4679 - val_mae: 2.6985\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.0209 - mae: 2.2947 - val_loss: 10.1220 - val_mae: 2.4125\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.5325 - mae: 2.2307 - val_loss: 9.6575 - val_mae: 2.3676\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.5246 - mae: 2.2211 - val_loss: 9.7201 - val_mae: 2.3611\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.3185 - mae: 2.2015 - val_loss: 10.3403 - val_mae: 2.4391\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.6941 - mae: 2.2472 - val_loss: 10.6025 - val_mae: 2.4697\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.4357 - mae: 2.2076 - val_loss: 9.0910 - val_mae: 2.2537\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.3763 - mae: 2.2061 - val_loss: 9.1284 - val_mae: 2.2846\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.1438 - mae: 2.1700 - val_loss: 9.3839 - val_mae: 2.3223\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.0640 - mae: 2.1759 - val_loss: 10.0316 - val_mae: 2.3941\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.1050 - mae: 2.1776 - val_loss: 9.5540 - val_mae: 2.3269\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.0107 - mae: 2.1597 - val_loss: 8.9713 - val_mae: 2.2695\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.9380 - mae: 2.1386 - val_loss: 9.4747 - val_mae: 2.3150\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.8465 - mae: 2.1424 - val_loss: 9.6125 - val_mae: 2.3439\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.7714 - mae: 2.1305 - val_loss: 9.3542 - val_mae: 2.3209\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.7819 - mae: 2.1376 - val_loss: 9.7444 - val_mae: 2.3588\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6891 - mae: 2.1323 - val_loss: 9.8139 - val_mae: 2.3742\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.7249 - mae: 2.1440 - val_loss: 9.3219 - val_mae: 2.3108\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.7172 - mae: 2.1248 - val_loss: 9.0633 - val_mae: 2.2633\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.6074 - mae: 2.1154 - val_loss: 9.4987 - val_mae: 2.3227\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 8.7164 - mae: 2.1488 - val_loss: 10.3795 - val_mae: 2.4379\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6039 - mae: 2.1365 - val_loss: 9.3140 - val_mae: 2.3055\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.5499 - mae: 2.1132 - val_loss: 8.7787 - val_mae: 2.2298\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8.4312 - mae: 2.0982 - val_loss: 9.3803 - val_mae: 2.3135\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.4415 - mae: 2.1020 - val_loss: 9.2654 - val_mae: 2.3082\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.4102 - mae: 2.1023 - val_loss: 9.3289 - val_mae: 2.3078\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.2852 - mae: 2.0857 - val_loss: 9.2041 - val_mae: 2.2657\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.2646 - mae: 2.0842 - val_loss: 9.5105 - val_mae: 2.3184\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.2472 - mae: 2.0784 - val_loss: 9.5636 - val_mae: 2.3421\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8.2425 - mae: 2.0913 - val_loss: 9.9246 - val_mae: 2.3928\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.3447 - mae: 2.1283 - val_loss: 10.1805 - val_mae: 2.4409\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.3086 - mae: 2.1032 - val_loss: 10.0225 - val_mae: 2.3743\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.2619 - mae: 2.0632 - val_loss: 8.6519 - val_mae: 2.1947\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.0681 - mae: 2.0421 - val_loss: 9.0400 - val_mae: 2.2598\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.9864 - mae: 2.0435 - val_loss: 9.3583 - val_mae: 2.3236\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.0079 - mae: 2.0588 - val_loss: 9.2382 - val_mae: 2.2837\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.9477 - mae: 2.0293 - val_loss: 8.7616 - val_mae: 2.2296\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.8519 - mae: 2.0213 - val_loss: 9.4963 - val_mae: 2.3156\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.8147 - mae: 2.0249 - val_loss: 9.4184 - val_mae: 2.3114\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7760 - mae: 2.0102 - val_loss: 9.0325 - val_mae: 2.2465\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7760 - mae: 2.0053 - val_loss: 9.1208 - val_mae: 2.2554\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6980 - mae: 2.0091 - val_loss: 9.4589 - val_mae: 2.3042\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.6831 - mae: 1.9933 - val_loss: 9.0813 - val_mae: 2.2472\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6121 - mae: 1.9825 - val_loss: 9.2539 - val_mae: 2.2745\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.6571 - mae: 2.0011 - val_loss: 9.5123 - val_mae: 2.3025\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5701 - mae: 1.9877 - val_loss: 9.0178 - val_mae: 2.2354\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6240 - mae: 1.9803 - val_loss: 8.4551 - val_mae: 2.1816\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5543 - mae: 1.9712 - val_loss: 9.7625 - val_mae: 2.3433\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.5362 - mae: 1.9894 - val_loss: 9.5434 - val_mae: 2.3215\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.4327 - mae: 1.9572 - val_loss: 9.1429 - val_mae: 2.2604\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.4666 - mae: 1.9959 - val_loss: 10.2293 - val_mae: 2.4184\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.4178 - mae: 1.9764 - val_loss: 8.9488 - val_mae: 2.2139\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.3235 - mae: 1.9497 - val_loss: 9.2156 - val_mae: 2.2689\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.2841 - mae: 1.9423 - val_loss: 8.9558 - val_mae: 2.2291\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.2199 - mae: 1.9375 - val_loss: 9.0987 - val_mae: 2.2494\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.3638 - mae: 1.9827 - val_loss: 9.3368 - val_mae: 2.2785\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2672 - mae: 1.9323 - val_loss: 8.5598 - val_mae: 2.1705\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1533 - mae: 1.9332 - val_loss: 9.5053 - val_mae: 2.3062\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.1401 - mae: 1.9435 - val_loss: 9.3168 - val_mae: 2.3038\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.2096 - mae: 1.9330 - val_loss: 8.2721 - val_mae: 2.1584\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2507 - mae: 1.9435 - val_loss: 9.3973 - val_mae: 2.2953\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.9968 - mae: 1.9213 - val_loss: 8.7999 - val_mae: 2.2114\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.0861 - mae: 1.9134 - val_loss: 8.9475 - val_mae: 2.2539\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2249 - mae: 1.9607 - val_loss: 9.7016 - val_mae: 2.3464\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.9538 - mae: 1.9221 - val_loss: 8.9828 - val_mae: 2.2417\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9493 - mae: 1.9080 - val_loss: 8.6928 - val_mae: 2.2059\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.9058 - mae: 1.9111 - val_loss: 9.4465 - val_mae: 2.2914\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.8614 - mae: 1.9082 - val_loss: 8.9480 - val_mae: 2.2177\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7844 - mae: 1.9103 - val_loss: 9.1504 - val_mae: 2.2491\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7681 - mae: 1.9027 - val_loss: 8.9311 - val_mae: 2.2150\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7386 - mae: 1.8891 - val_loss: 9.2068 - val_mae: 2.2449\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8360 - mae: 1.9194 - val_loss: 10.6151 - val_mae: 2.4294\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9764 - mae: 1.9183 - val_loss: 8.8336 - val_mae: 2.1979\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.9223 - mae: 1.9096 - val_loss: 8.5192 - val_mae: 2.1823\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6.7798 - mae: 1.9129 - val_loss: 10.3263 - val_mae: 2.4318\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.6847 - mae: 1.8887 - val_loss: 8.4119 - val_mae: 2.1448\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 6.6307 - mae: 1.8650 - val_loss: 8.7907 - val_mae: 2.2108\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 6.6160 - mae: 1.8654 - val_loss: 8.6464 - val_mae: 2.1858\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.5551 - mae: 1.8638 - val_loss: 9.1680 - val_mae: 2.2553\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.4858 - mae: 1.8703 - val_loss: 8.5354 - val_mae: 2.1653\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.5149 - mae: 1.8520 - val_loss: 8.5308 - val_mae: 2.1753\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4615 - mae: 1.8560 - val_loss: 8.6399 - val_mae: 2.1907\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.5237 - mae: 1.8741 - val_loss: 8.7177 - val_mae: 2.1949\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.3601 - mae: 1.8427 - val_loss: 8.4458 - val_mae: 2.1721\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6.4698 - mae: 1.8447 - val_loss: 8.4093 - val_mae: 2.1893\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4920 - mae: 1.8495 - val_loss: 8.5261 - val_mae: 2.2044\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.4129 - mae: 1.8697 - val_loss: 9.3032 - val_mae: 2.2983\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.3478 - mae: 1.8356 - val_loss: 8.8838 - val_mae: 2.2209\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.8419 - mae: 1.9461 - val_loss: 11.5679 - val_mae: 2.5540\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.4770 - mae: 1.8787 - val_loss: 8.4477 - val_mae: 2.1555\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.3483 - mae: 1.8373 - val_loss: 9.2489 - val_mae: 2.2627\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.2722 - mae: 1.8449 - val_loss: 9.3521 - val_mae: 2.2992\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.1206 - mae: 1.8224 - val_loss: 8.8576 - val_mae: 2.2306\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.1426 - mae: 1.8186 - val_loss: 9.0168 - val_mae: 2.2486\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.2379 - mae: 1.8355 - val_loss: 8.5139 - val_mae: 2.1783\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.1590 - mae: 1.8162 - val_loss: 8.9228 - val_mae: 2.2504\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.1625 - mae: 1.8217 - val_loss: 8.8867 - val_mae: 2.2387\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.0620 - mae: 1.8152 - val_loss: 8.6227 - val_mae: 2.2093\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.9880 - mae: 1.8131 - val_loss: 9.0690 - val_mae: 2.2760\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.9966 - mae: 1.8159 - val_loss: 8.9824 - val_mae: 2.2644\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 5.9679 - mae: 1.8182 - val_loss: 9.0113 - val_mae: 2.2816\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.9020 - mae: 1.7899 - val_loss: 8.4650 - val_mae: 2.2036\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.9594 - mae: 1.7994 - val_loss: 8.0550 - val_mae: 2.1318\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.9292 - mae: 1.7966 - val_loss: 8.6695 - val_mae: 2.2088\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0236 - mae: 1.7942 - val_loss: 8.0240 - val_mae: 2.1608\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8340 - mae: 1.7749 - val_loss: 8.7489 - val_mae: 2.2445\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8217 - mae: 1.7850 - val_loss: 8.3534 - val_mae: 2.1733\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8276 - mae: 1.7701 - val_loss: 8.2655 - val_mae: 2.1812\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.7713 - mae: 1.7465 - val_loss: 8.4991 - val_mae: 2.2088\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8513 - mae: 1.7767 - val_loss: 8.8185 - val_mae: 2.2425\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7321 - mae: 1.7641 - val_loss: 8.1659 - val_mae: 2.1552\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.7178 - mae: 1.7563 - val_loss: 8.4411 - val_mae: 2.1995\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7093 - mae: 1.7665 - val_loss: 8.6639 - val_mae: 2.2348\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6171 - mae: 1.7361 - val_loss: 8.0483 - val_mae: 2.1431\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7135 - mae: 1.7493 - val_loss: 8.3430 - val_mae: 2.1822\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6115 - mae: 1.7520 - val_loss: 8.4228 - val_mae: 2.1863\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6688 - mae: 1.7620 - val_loss: 8.1507 - val_mae: 2.1429\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.8219 - mae: 1.7943 - val_loss: 8.8926 - val_mae: 2.2555\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.7370 - mae: 1.7500 - val_loss: 7.2556 - val_mae: 2.0611\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.5806 - mae: 1.7417 - val_loss: 8.7078 - val_mae: 2.2785\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6262 - mae: 1.7570 - val_loss: 7.5974 - val_mae: 2.0847\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6554 - mae: 1.7666 - val_loss: 7.8874 - val_mae: 2.1273\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5.5915 - mae: 1.7401 - val_loss: 8.3199 - val_mae: 2.1691\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4718 - mae: 1.7258 - val_loss: 8.3587 - val_mae: 2.2006\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4531 - mae: 1.7295 - val_loss: 8.1130 - val_mae: 2.1598\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.4186 - mae: 1.6981 - val_loss: 7.4041 - val_mae: 2.0607\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5603 - mae: 1.7097 - val_loss: 7.7871 - val_mae: 2.1071\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3906 - mae: 1.7130 - val_loss: 8.0728 - val_mae: 2.1640\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3396 - mae: 1.6943 - val_loss: 8.0225 - val_mae: 2.1495\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4343 - mae: 1.7358 - val_loss: 8.6766 - val_mae: 2.2461\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2690 - mae: 1.7046 - val_loss: 7.3724 - val_mae: 2.0611\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.5071 - mae: 1.7187 - val_loss: 7.7377 - val_mae: 2.1211\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4502 - mae: 1.7449 - val_loss: 8.5091 - val_mae: 2.2297\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3409 - mae: 1.6945 - val_loss: 7.2931 - val_mae: 2.0544\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.1978 - mae: 1.6714 - val_loss: 8.1229 - val_mae: 2.1646\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.2796 - mae: 1.7083 - val_loss: 7.8794 - val_mae: 2.1252\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2285 - mae: 1.6669 - val_loss: 7.3807 - val_mae: 2.0623\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1336 - mae: 1.6704 - val_loss: 8.1632 - val_mae: 2.1767\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.1879 - mae: 1.6869 - val_loss: 7.6252 - val_mae: 2.0895\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3498 - mae: 1.6909 - val_loss: 7.3389 - val_mae: 2.0706\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.2966 - mae: 1.7048 - val_loss: 8.3940 - val_mae: 2.2263\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1241 - mae: 1.6537 - val_loss: 7.1328 - val_mae: 2.0448\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1367 - mae: 1.6666 - val_loss: 7.7510 - val_mae: 2.1183\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0912 - mae: 1.6602 - val_loss: 7.8323 - val_mae: 2.1218\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.9800 - mae: 1.6356 - val_loss: 7.4984 - val_mae: 2.0860\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0122 - mae: 1.6318 - val_loss: 8.1068 - val_mae: 2.1760\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1954 - mae: 1.6883 - val_loss: 8.1999 - val_mae: 2.1719\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0454 - mae: 1.6323 - val_loss: 7.4878 - val_mae: 2.0661\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0505 - mae: 1.6647 - val_loss: 7.9786 - val_mae: 2.1475\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9503 - mae: 1.6189 - val_loss: 7.5840 - val_mae: 2.0973\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0440 - mae: 1.6607 - val_loss: 8.0061 - val_mae: 2.1471\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9853 - mae: 1.6645 - val_loss: 7.7580 - val_mae: 2.1167\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0341 - mae: 1.6704 - val_loss: 8.0171 - val_mae: 2.1305\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9695 - mae: 1.6642 - val_loss: 8.0551 - val_mae: 2.1778\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8779 - mae: 1.6438 - val_loss: 7.4530 - val_mae: 2.0976\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8528 - mae: 1.6239 - val_loss: 7.5479 - val_mae: 2.0818\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.8097 - mae: 1.6211 - val_loss: 7.9977 - val_mae: 2.1530\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8029 - mae: 1.6179 - val_loss: 7.4925 - val_mae: 2.0860\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7384 - mae: 1.5996 - val_loss: 7.7522 - val_mae: 2.1296\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7369 - mae: 1.5968 - val_loss: 7.6374 - val_mae: 2.1133\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7626 - mae: 1.5902 - val_loss: 7.5824 - val_mae: 2.1007\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7293 - mae: 1.6013 - val_loss: 7.7835 - val_mae: 2.1393\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7319 - mae: 1.5901 - val_loss: 7.3210 - val_mae: 2.0693\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.6946 - mae: 1.6108 - val_loss: 7.9554 - val_mae: 2.1404\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7239 - mae: 1.5817 - val_loss: 7.3284 - val_mae: 2.0553\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.5618 - mae: 1.5634 - val_loss: 8.1439 - val_mae: 2.1867\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.6289 - mae: 1.5890 - val_loss: 7.6147 - val_mae: 2.1048\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.6140 - mae: 1.5722 - val_loss: 7.1920 - val_mae: 2.0449\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.5781 - mae: 1.5712 - val_loss: 8.0287 - val_mae: 2.1746\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.6129 - mae: 1.5841 - val_loss: 7.8573 - val_mae: 2.1347\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.5107 - mae: 1.5567 - val_loss: 7.2032 - val_mae: 2.0376\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.5688 - mae: 1.5526 - val_loss: 7.3016 - val_mae: 2.0528\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7728 - mae: 1.6371 - val_loss: 7.4942 - val_mae: 2.0789\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5051 - mae: 1.5697 - val_loss: 6.9280 - val_mae: 1.9950\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7096 - mae: 1.5630 - val_loss: 7.2478 - val_mae: 2.0666\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7040 - mae: 1.6335 - val_loss: 8.1423 - val_mae: 2.2104\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.4531 - mae: 1.5655 - val_loss: 7.1659 - val_mae: 2.0246\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5095 - mae: 1.5757 - val_loss: 7.2853 - val_mae: 2.0414\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.3924 - mae: 1.5391 - val_loss: 7.5081 - val_mae: 2.1105\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4415 - mae: 1.5444 - val_loss: 7.3600 - val_mae: 2.0650\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4094 - mae: 1.5437 - val_loss: 7.5629 - val_mae: 2.1048\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.3568 - mae: 1.5275 - val_loss: 7.2561 - val_mae: 2.0432\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3211 - mae: 1.5239 - val_loss: 7.5404 - val_mae: 2.0925\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.3563 - mae: 1.5241 - val_loss: 7.5299 - val_mae: 2.0761\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.2779 - mae: 1.5132 - val_loss: 7.2877 - val_mae: 2.0564\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.2977 - mae: 1.5126 - val_loss: 7.4689 - val_mae: 2.0822\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2761 - mae: 1.5242 - val_loss: 6.9898 - val_mae: 2.0171\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.2906 - mae: 1.5283 - val_loss: 7.5533 - val_mae: 2.0747\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1886 - mae: 1.5027 - val_loss: 7.4360 - val_mae: 2.0719\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1817 - mae: 1.4852 - val_loss: 7.1994 - val_mae: 2.0340\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1602 - mae: 1.4940 - val_loss: 7.6102 - val_mae: 2.0986\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.1495 - mae: 1.5054 - val_loss: 7.4422 - val_mae: 2.0622\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1169 - mae: 1.4948 - val_loss: 7.2777 - val_mae: 2.0623\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1403 - mae: 1.4922 - val_loss: 7.3240 - val_mae: 2.0893\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.0639 - mae: 1.4818 - val_loss: 7.5738 - val_mae: 2.1120\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.9950 - mae: 2.1257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QdMAnIcQsSG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5fold 결과:"
      ],
      "metadata": {
        "id": "glRGvqPIUD9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mae_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hBcQMYRUDwn",
        "outputId": "b972cbfd-12c8-4eeb-ef6c-58bfd3a594d0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.072092294692993"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZidDhJrUFre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZJqfZRL9FE4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ymwOQSP9FCT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUiUIhJl9E_r"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ypkGpe7W9E88"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OD4phuyu9E6x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zYjpAYNZ9E4H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C1tn7zKI9E1g"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekYDAG6-9Ey9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCLXqxbn9EwR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLqDo57x9Et3"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}